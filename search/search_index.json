{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What is StartLeft? StartLeft is an automation tool for generating Threat Models written in the Open Threat Model (OTM) format from a variety of different sources such as IaC files, diagrams or projects exported from Threat Modeling tools. Why StartLeft? Automation and integration are the core goals of StartLeft. It was born as an internal project of IriusRisk , whose leading threat modelling tool allows the users to build a complete Threat Model of an application only by depicting its architecture in a diagram. However, there is a bunch of formats in which the architecture (or directly the TM) can be defined. This led IriusRisk to create and share with the community two key resources: Open Threat Model (OTM) , a standardized and vendor-agnostic way to represent Threat Models to make them easily portable between platforms. StartLeft , a tool for automating the conversion from different sources into OTM. In some cases, StartLeft acts only as a format translator, like in case of diagrams or Threat Model sources, but it has also specific and configurable logic for generating Threat Models (TMs) from Infrastructure as Code (IaC) files, which brings a great advantage reducing the necessary knowledge and manual work required for translating infrastructure into TM, as well as enabling the users to make amazing things like integrating the generation of the TM in a CI/CD pipeline of the actual IaC file. StartLeft is currently an Open Source application powered by IriusRisk , that is already using it as an intermediate service for all the imports of new projects from external sources. What input sources are supported? Split by type, the currently supported input formats are: Infrastructure as Code (IaC) : CloudFormation (CFT) . Terraform (TF) . Diagram : Microsoft Visio (including diagrams exported from Lucidchart). Threat Model : Microsoft Threat Modeling Tool (MTMT). How can I try it? Simply install the tool and play with its Command Line Interface. You can also set up a REST API with a single command and consume it with any REST client such as Postman. Anyway, the best way to start is by following the Quickstart guide for beginners . How can I integrate it? One of the most interesting aspects of StartLeft is that it is easily integrable within processes that may need to generate Threat Models. The different ways of integrating StartLeft are described in the Quickstart guide for integrations . How can I contribute? StartLeft is an Open Source application whose modularized architecture based on processors is specially focused on simplifying the collaboration for any developer. If you want to contribute, check out the Quickstart guide for developers and the CONTRIBUTING.md file .","title":"Home"},{"location":"#what-is-startleft","text":"StartLeft is an automation tool for generating Threat Models written in the Open Threat Model (OTM) format from a variety of different sources such as IaC files, diagrams or projects exported from Threat Modeling tools.","title":"What is StartLeft?"},{"location":"#why-startleft","text":"Automation and integration are the core goals of StartLeft. It was born as an internal project of IriusRisk , whose leading threat modelling tool allows the users to build a complete Threat Model of an application only by depicting its architecture in a diagram. However, there is a bunch of formats in which the architecture (or directly the TM) can be defined. This led IriusRisk to create and share with the community two key resources: Open Threat Model (OTM) , a standardized and vendor-agnostic way to represent Threat Models to make them easily portable between platforms. StartLeft , a tool for automating the conversion from different sources into OTM. In some cases, StartLeft acts only as a format translator, like in case of diagrams or Threat Model sources, but it has also specific and configurable logic for generating Threat Models (TMs) from Infrastructure as Code (IaC) files, which brings a great advantage reducing the necessary knowledge and manual work required for translating infrastructure into TM, as well as enabling the users to make amazing things like integrating the generation of the TM in a CI/CD pipeline of the actual IaC file. StartLeft is currently an Open Source application powered by IriusRisk , that is already using it as an intermediate service for all the imports of new projects from external sources.","title":"Why StartLeft?"},{"location":"#what-input-sources-are-supported","text":"Split by type, the currently supported input formats are: Infrastructure as Code (IaC) : CloudFormation (CFT) . Terraform (TF) . Diagram : Microsoft Visio (including diagrams exported from Lucidchart). Threat Model : Microsoft Threat Modeling Tool (MTMT).","title":"What input sources are supported?"},{"location":"#how-can-i-try-it","text":"Simply install the tool and play with its Command Line Interface. You can also set up a REST API with a single command and consume it with any REST client such as Postman. Anyway, the best way to start is by following the Quickstart guide for beginners .","title":"How can I try it?"},{"location":"#how-can-i-integrate-it","text":"One of the most interesting aspects of StartLeft is that it is easily integrable within processes that may need to generate Threat Models. The different ways of integrating StartLeft are described in the Quickstart guide for integrations .","title":"How can I integrate it?"},{"location":"#how-can-i-contribute","text":"StartLeft is an Open Source application whose modularized architecture based on processors is specially focused on simplifying the collaboration for any developer. If you want to contribute, check out the Quickstart guide for developers and the CONTRIBUTING.md file .","title":"How can I contribute?"},{"location":"About/","text":"About this documentation Maintenance This documentation is maintained by the IriusRisk engineering team. If you find an error, or need any clarification, please raise an issue in the StartLeft GitHub repository . Documentation per branch The documentation shown here applies to the latest stable version of StartLeft . If you want to check the documentation of a previous version or for an ongoing development, you can do it by checking out the desired branch and deploying its documentation. To do that, first we need to select the right branch: main is the branch for the latest stable version. release/{release-number} (i.e: release/1.7.0 ) are the branches for each version. dev is the branch that contains the developments that will be delivered in the next version. feature/{feature-number} (i.e: feature/600 ) are the branches for specific developments. So, suppose for example you want to check the documentation for the developments delivered in the next version. You will need to clone the dev branch: git clone -b dev https://github.com/iriusrisk/startleft.git And then launch the StartLeft documentation Launch StartLeft documentation by Dockerfile Deploy the documentation using the provided docker-compose.yml file inside the deployment folder: With docker installed from debian/ubuntu packages (docker.io) and the docker-compose plugin cd deployment docker-compose up -d docs With docker installed from docker.com packages cd deployment docker compose up -d docs Now you can access the docs in http://localhost:8000 . Launch by Dockerfile is recommended in case none modification will be done to the docs Launch StartLeft documentation by mkdocs serve Run into StartLeft root folder pip install -e \".[doc]\" mkdocs serve Browse to http://localhost:8000 to access the documentation. Launch by mkdocs serve is recommended if the docs will be modified, as the changes are reloaded automatically","title":"About this documentation"},{"location":"About/#about-this-documentation","text":"","title":"About this documentation"},{"location":"About/#maintenance","text":"This documentation is maintained by the IriusRisk engineering team. If you find an error, or need any clarification, please raise an issue in the StartLeft GitHub repository .","title":"Maintenance"},{"location":"About/#documentation-per-branch","text":"The documentation shown here applies to the latest stable version of StartLeft . If you want to check the documentation of a previous version or for an ongoing development, you can do it by checking out the desired branch and deploying its documentation. To do that, first we need to select the right branch: main is the branch for the latest stable version. release/{release-number} (i.e: release/1.7.0 ) are the branches for each version. dev is the branch that contains the developments that will be delivered in the next version. feature/{feature-number} (i.e: feature/600 ) are the branches for specific developments. So, suppose for example you want to check the documentation for the developments delivered in the next version. You will need to clone the dev branch: git clone -b dev https://github.com/iriusrisk/startleft.git And then launch the StartLeft documentation","title":"Documentation per branch"},{"location":"About/#launch-startleft-documentation-by-dockerfile","text":"Deploy the documentation using the provided docker-compose.yml file inside the deployment folder: With docker installed from debian/ubuntu packages (docker.io) and the docker-compose plugin cd deployment docker-compose up -d docs With docker installed from docker.com packages cd deployment docker compose up -d docs Now you can access the docs in http://localhost:8000 . Launch by Dockerfile is recommended in case none modification will be done to the docs","title":"Launch StartLeft documentation by Dockerfile"},{"location":"About/#launch-startleft-documentation-by-mkdocs-serve","text":"Run into StartLeft root folder pip install -e \".[doc]\" mkdocs serve Browse to http://localhost:8000 to access the documentation. Launch by mkdocs serve is recommended if the docs will be modified, as the changes are reloaded automatically","title":"Launch StartLeft documentation by mkdocs serve"},{"location":"Open-Threat-Model-%28OTM%29/","text":"Open Threat Model standard The Open Threat Modeling Format (OTM) defines a platform independent way to define the threat model of any system. It\u2019s a simple and tool agnostic YAML (or JSON ) format that describes the essential elements and properties of a threat model and which allows to understand what are the components of a system, how are they distributed, the security risks that could be exposed to attackers and the mitigations that could be implemented to avoid those vulnerabilities (see https://www.iriusrisk.com/resources-blog/introduction-to-the-open-threat-model-standard ). A detailed description about the standard is included in the OTM Project . Format An OTM document is itself a JSON object, which may be represented either in JSON or YAML format. All field names in the specification are case-sensitive. This includes all fields that are used as keys in a map. The specification follows the same approach to JSON formats as the OpenAPI specification. See the Swagger specification for more information. Manual OTM example otmVersion: 0.1.0 project: name: Manual ThreatModel id: manual-threatmodel trustZones: - id: f0ba7722-39b6-4c81-8290-a30a248bb8d9 name: Internet risk: trustRating: 1 - id: 6376d53e-6461-412b-8e04-7b3fe2b397de name: Public risk: trustRating: 1 - id: 2ab4effa-40b7-4cd2-ba81-8247d29a6f2d name: Private Secured risk: trustRating: 100 components: - id: user name: User type: generic-client parent: trustZone: f0ba7722-39b6-4c81-8290-a30a248bb8d9 - id: web-server name: Web server type: web-application-server-side parent: trustZone: 6376d53e-6461-412b-8e04-7b3fe2b397de - id: database name: Database type: postgresql parent: trustZone: 2ab4effa-40b7-4cd2-ba81-8247d29a6f2d dataflows: - id: client-connection name: Client connection source: user destination: web-server - id: database-connection name: Database connection source: web-server destination: database Schema The OTM object schema is as follows: Field Type Description otmVersion String REQUIRED This field states the OTM version used in the current file. It is an important field in order to ensure backwards compatibility. project Project object REQUIRED The project node represents the entity within all the other elements are grouped. It's the unit of work. representations Representations object Representations define different ways in which the project may be represented. Representation is an abstract concept and there might be several implementations. assets Assets object Assets are the different kinds of sensible information that take part in our threat model. components Components object Components are the different pieces of software / hardware that make up our project. dataflows DataFlows object Data flows are the elements that describe the movement of relevant information (assets) across our architecture. trustZones TrustZones object Trust zones are the different areas within which components are located. They define how trustworthy an area is, based on how accessible it is: the more accessible, the less trustworthy. threats Threats object Threats are the undesirable outcomes that can occur in our system and that we want to prevent. mitigations Mitigations object Mitigations are the actions that we can take (or controls that we can put in place) in order to prevent a threat from taking place. Open Threat Model examples Some examples of otm files are shown below, along with the project that each one generates. Cloudformation project example OTM file Generated project { \"otmVersion\": \"0.1.0\", \"project\": { \"name\": \"cft_multiple_files_project\", \"id\": \"cft_multiple_files_project_id\" }, \"representations\": [ { \"name\": \"CloudFormation\", \"id\": \"CloudFormation\", \"type\": \"code\" } ], \"trustZones\": [ { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\", \"name\": \"Public Cloud\", \"risk\": { \"trustRating\": 10 } }, { \"id\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9\", \"name\": \"Internet\", \"risk\": { \"trustRating\": 10 } } ], \"components\": [ { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\", \"name\": \"CustomVPC\", \"type\": \"vpc\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"tags\": [ \"AWS::EC2::VPC\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1\", \"name\": \"PrivateSubnet1\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\" }, \"tags\": [ \"AWS::EC2::Subnet\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2\", \"name\": \"PrivateSubnet2\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\" }, \"tags\": [ \"AWS::EC2::Subnet\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet1\", \"name\": \"PublicSubnet1\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\" }, \"tags\": [ \"AWS::EC2::Subnet\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet2\", \"name\": \"PublicSubnet2\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\" }, \"tags\": [ \"AWS::EC2::Subnet\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.vpcssm\", \"name\": \"VPCssm\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1\" }, \"tags\": [ \"AWS::EC2::VPCEndpoint\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.vpcssm\", \"name\": \"VPCssm\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2\" }, \"tags\": [ \"AWS::EC2::VPCEndpoint\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.vpcssmmessages\", \"name\": \"VPCssmmessages\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1\" }, \"tags\": [ \"AWS::EC2::VPCEndpoint\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.vpcssmmessages\", \"name\": \"VPCssmmessages\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2\" }, \"tags\": [ \"AWS::EC2::VPCEndpoint\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.vpcmonitoring\", \"name\": \"VPCmonitoring\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1\" }, \"tags\": [ \"AWS::EC2::VPCEndpoint\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.vpcmonitoring\", \"name\": \"VPCmonitoring\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2\" }, \"tags\": [ \"AWS::EC2::VPCEndpoint\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.service\", \"name\": \"Service\", \"type\": \"elastic-container-service\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1\" }, \"tags\": [ \"AWS::ECS::Service\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.service\", \"name\": \"Service\", \"type\": \"elastic-container-service\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2\" }, \"tags\": [ \"AWS::ECS::Service\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.service.servicetaskdefinition\", \"name\": \"ServiceTaskDefinition\", \"type\": \"docker-container\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.service\" }, \"tags\": [ \"AWS::ECS::TaskDefinition\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.service.servicetaskdefinition\", \"name\": \"ServiceTaskDefinition\", \"type\": \"docker-container\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.service\" }, \"tags\": [ \"AWS::ECS::TaskDefinition\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.servicelb\", \"name\": \"ServiceLB\", \"type\": \"load-balancer\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1\" }, \"tags\": [ \"AWS::ElasticLoadBalancingV2::LoadBalancer\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.servicelb\", \"name\": \"ServiceLB\", \"type\": \"load-balancer\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2\" }, \"tags\": [ \"AWS::ElasticLoadBalancingV2::LoadBalancer\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet1.canary\", \"name\": \"Canary\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet1\" }, \"tags\": [ \"AWS::Synthetics::Canary\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet2.canary\", \"name\": \"Canary\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet2\" }, \"tags\": [ \"AWS::Synthetics::Canary\" ] }, { \"id\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.vpcssmsecuritygroup.0_0_0_0_0\", \"name\": \"0.0.0.0/0\", \"type\": \"generic-client\", \"parent\": { \"trustZone\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9\" }, \"tags\": [ \"Outbound connection destination IP\" ] }, { \"id\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.outboundsecuritygroup.255_255_255_255_32\", \"name\": \"255.255.255.255/32\", \"type\": \"generic-client\", \"parent\": { \"trustZone\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9\" }, \"tags\": [ \"Outbound connection destination IP\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.vpcssm-altsource\", \"name\": \"Systems Manager from VPCEndpoint (grouped)\", \"type\": \"CD-SYSTEMS-MANAGER\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"tags\": [ \"VPCssm (AWS::EC2::VPCEndpoint)\", \"VPCssmmessages (AWS::EC2::VPCEndpoint)\" ] } ], \"dataflows\": [ { \"id\": \"f50bd3e2-40cd-4e6a-a794-774bb2f213c2\", \"name\": \"VPCssmSecurityGroup -> VPCssm\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.vpcssm\", \"tags\": [ \"tcp\", \"443\", \"443\" ] }, { \"id\": \"04e8573e-d0aa-4964-ba5a-3492c705f111\", \"name\": \"VPCssm -> VPCssmSecurityGroup\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.vpcssm\", \"destination\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.vpcssmsecuritygroup.0_0_0_0_0\", \"tags\": [ \"Allow all outbound traffic by default\", \"-1\", \"0.0.0.0/0\" ] }, { \"id\": \"617dee3d-8a20-4153-8c70-9c32fc7ecde3\", \"name\": \"VPCssmSecurityGroup -> VPCssm\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.vpcssm\", \"tags\": [ \"tcp\", \"443\", \"443\" ] }, { \"id\": \"dae9fa64-9828-4710-a3e6-bf618b6a47e6\", \"name\": \"VPCssm -> VPCssmSecurityGroup\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.vpcssm\", \"destination\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.vpcssmsecuritygroup.0_0_0_0_0\", \"tags\": [ \"Allow all outbound traffic by default\", \"-1\", \"0.0.0.0/0\" ] }, { \"id\": \"d65adb9a-6e1a-4a64-9971-baecb082e617\", \"name\": \"VPCssmmessagesSecurityGroup -> VPCssmmessages\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.vpcssmmessages\", \"tags\": [ \"tcp\", \"443\", \"443\" ] }, { \"id\": \"65cce749-e20c-472f-8323-6aa6693e4205\", \"name\": \"VPCssmmessages -> VPCssmmessagesSecurityGroup\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.vpcssmmessages\", \"destination\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.vpcssmsecuritygroup.0_0_0_0_0\", \"tags\": [ \"Allow all outbound traffic by default\", \"-1\", \"0.0.0.0/0\" ] }, { \"id\": \"86165718-ca5f-4ddb-b981-0566f6d8f52a\", \"name\": \"VPCssmmessagesSecurityGroup -> VPCssmmessages\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.vpcssmmessages\", \"tags\": [ \"tcp\", \"443\", \"443\" ] }, { \"id\": \"76a092f4-1f7f-4cad-8e65-ad29065aeac5\", \"name\": \"VPCssmmessages -> VPCssmmessagesSecurityGroup\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.vpcssmmessages\", \"destination\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.vpcssmsecuritygroup.0_0_0_0_0\", \"tags\": [ \"Allow all outbound traffic by default\", \"-1\", \"0.0.0.0/0\" ] }, { \"id\": \"101a5dc5-1d25-445a-92a2-71bafe2661b5\", \"name\": \"VPCmonitoringSecurityGroup -> VPCmonitoring\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.vpcmonitoring\", \"tags\": [ \"tcp\", \"443\", \"443\" ] }, { \"id\": \"abcefff3-5de5-4cae-9b72-4c1db550d782\", \"name\": \"VPCmonitoring -> VPCmonitoringSecurityGroup\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.vpcmonitoring\", \"destination\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.vpcssmsecuritygroup.0_0_0_0_0\", \"tags\": [ \"Allow all outbound traffic by default\", \"-1\", \"0.0.0.0/0\" ] }, { \"id\": \"60e99a7e-6e0a-44e2-89a9-f8186e6221d4\", \"name\": \"VPCmonitoringSecurityGroup -> VPCmonitoring\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.vpcmonitoring\", \"tags\": [ \"tcp\", \"443\", \"443\" ] }, { \"id\": \"893291bd-509f-40e1-b24d-bce8f1eb6e3a\", \"name\": \"VPCmonitoring -> VPCmonitoringSecurityGroup\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.vpcmonitoring\", \"destination\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.vpcssmsecuritygroup.0_0_0_0_0\", \"tags\": [ \"Allow all outbound traffic by default\", \"-1\", \"0.0.0.0/0\" ] }, { \"id\": \"fffa11dd-2d92-4d9e-b28c-a0468af49870\", \"name\": \"Service -> OutboundSecurityGroup\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.service\", \"destination\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.outboundsecuritygroup.255_255_255_255_32\", \"tags\": [ \"Disallow all traffic\", \"icmp\", \"255.255.255.255/32\" ] }, { \"id\": \"5e84eded-dd7a-48f2-83df-714bce5ddd81\", \"name\": \"Service -> OutboundSecurityGroup\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.service\", \"destination\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.outboundsecuritygroup.255_255_255_255_32\", \"tags\": [ \"Disallow all traffic\", \"icmp\", \"255.255.255.255/32\" ] }, { \"id\": \"5c22512c-36c9-421c-a7da-bb1bf2994956\", \"name\": \"ServiceLB -> Service\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.servicelb\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.service\", \"tags\": [ \"Load balancer to target\", \"tcp\", \"80\", \"80\", \"Load balancer to target\", \"tcp\", \"80\", \"80\" ] }, { \"id\": \"9224208d-918b-4406-af96-1407e807fa7e\", \"name\": \"ServiceLB -> Service\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.servicelb\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.service\", \"tags\": [ \"Load balancer to target\", \"tcp\", \"80\", \"80\", \"Load balancer to target\", \"tcp\", \"80\", \"80\" ] }, { \"id\": \"8656b4a0-0fdf-4fc8-8207-888388a0a2a1\", \"name\": \"Canary -> ServiceLB\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet1.canary\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.servicelb\", \"tags\": [ \"from ECSFargateGoCanaryStackCanarySecurityGroup:443\", \"tcp\", \"443\", \"443\" ] }, { \"id\": \"24b32b34-d8df-44eb-bf06-5bafdad9c3a7\", \"name\": \"Canary -> ServiceLB\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet2.canary\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.servicelb\", \"tags\": [ \"from ECSFargateGoCanaryStackCanarySecurityGroup:443\", \"tcp\", \"443\", \"443\" ] }, { \"id\": \"d0a14b14-c7af-4f2f-8a09-7d20924b85a2\", \"name\": \"ServiceLB -> Service\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.servicelb\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.service\", \"tags\": [ \"Load balancer to target\", \"tcp\", \"80\", \"80\", \"Load balancer to target\", \"tcp\", \"80\", \"80\" ] }, { \"id\": \"a4bb6f9e-91ca-4314-9fab-04aa434c4099\", \"name\": \"ServiceLB -> Service\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.servicelb\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.service\", \"tags\": [ \"Load balancer to target\", \"tcp\", \"80\", \"80\", \"Load balancer to target\", \"tcp\", \"80\", \"80\" ] }, { \"id\": \"db637226-95ad-410d-b482-8e2fa8c5cbff\", \"name\": \"Canary -> ServiceLB\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet1.canary\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.servicelb\", \"tags\": [ \"from ECSFargateGoCanaryStackCanarySecurityGroup:443\", \"tcp\", \"443\", \"443\" ] }, { \"id\": \"73da31ec-24b5-48d2-8366-269b08d08ab6\", \"name\": \"Canary -> ServiceLB\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet2.canary\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.servicelb\", \"tags\": [ \"from ECSFargateGoCanaryStackCanarySecurityGroup:443\", \"tcp\", \"443\", \"443\" ] } ] } Visio project example OTM file Generated project { \"otmVersion\": \"0.1.0\", \"project\": { \"name\": \"Aws with tz and vpt\", \"id\": \"vs-aws-tz-vpc\" }, \"representations\": [ { \"name\": \"Visio\", \"id\": \"Visio\", \"type\": \"diagram\", \"size\": { \"width\": 1000, \"height\": 1000 } } ], \"trustZones\": [ { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\", \"name\": \"Public Cloud\", \"risk\": { \"trustRating\": 10 } }, { \"id\": \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\", \"name\": \"Private Secured\", \"risk\": { \"trustRating\": 10 } } ], \"components\": [ { \"id\": \"1\", \"name\": \"Amazon EC2\", \"type\": \"ec2\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\": \"12\", \"name\": \"Custom machine\", \"type\": \"ec2\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\": \"30\", \"name\": \"Private Database\", \"type\": \"rds\", \"parent\": { \"trustZone\": \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" } }, { \"id\": \"35\", \"name\": \"Amazon CloudWatch\", \"type\": \"cloudwatch\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\": \"41\", \"name\": \"Custom log system\", \"type\": \"cloudwatch\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } } ], \"dataflows\": [ { \"id\": \"17\", \"name\": \"6ead9f3e-fa04-4b61-b7ba-523aaf27ef7f\", \"source\": \"1\", \"destination\": \"12\" }, { \"id\": \"34\", \"name\": \"64bbe075-4999-423c-b40a-653c86493ee5\", \"source\": \"12\", \"destination\": \"30\" }, { \"id\": \"40\", \"name\": \"682fd394-5b8c-44d2-840b-fec8da18126f\", \"source\": \"1\", \"destination\": \"35\" }, { \"id\": \"46\", \"name\": \"c6d711f1-c867-44c0-a022-89a8babebbe3\", \"source\": \"12\", \"destination\": \"41\" } ] } Terraform project example OTM file Generated project { \"otmVersion\": \"0.1.0\", \"project\": { \"name\": \"Terraform ELB example\", \"id\": \"tf-elb-ex\" }, \"representations\": [ { \"name\": \"Terraform\", \"id\": \"Terraform\", \"type\": \"code\" } ], \"trustZones\": [ { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\", \"name\": \"Public Cloud\", \"risk\": { \"trustRating\": 10 } } ], \"components\": [ { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_vpc-foo\", \"name\": \"foo\", \"type\": \"vpc\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"tags\": [ \"aws_vpc\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_vpc-foo.aws_subnet-baz\", \"name\": \"baz\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_vpc-foo\" }, \"tags\": [ \"aws_subnet\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_vpc-foo.aws_subnet-bar\", \"name\": \"bar\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_vpc-foo\" }, \"tags\": [ \"aws_subnet\" ] } ], \"dataflows\": [] } MTMT project example OTM file Generated project { \"otmVersion\": \"0.1.0\", \"project\": { \"name\": \"mtmt_project_name\", \"id\": \"mtmt_project_id\" }, \"representations\": [ { \"name\": \"Microsoft Threat Modeling Tool\", \"id\": \"Microsoft Threat Modeling Tool\", \"type\": \"threat-model\" }, { \"name\": \"mtmt_project_id Diagram Representation\", \"id\": \"mtmt_project_id-diagram\", \"type\": \"diagram\", \"size\": { \"width\": 2000, \"height\": 2000 } } ], \"trustZones\": [ { \"id\": \"6376d53e-6461-412b-8e04-7b3fe2b397de\", \"name\": \"Internet\", \"risk\": { \"trustRating\": 10 }, \"properties\": { \"Name\": \"Internet\", \"Dataflow Order\": \"0\" }, \"representations\": [ { \"name\": \"Internet Representation\", \"id\": \"7537441a-1c03-48c0-b9c8-f82d5906c139-representation\", \"representation\": \"mtmt_project_id-diagram\", \"size\": { \"width\": 202, \"height\": 281 }, \"position\": { \"x\": 386, \"y\": 151 } } ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\", \"name\": \"Public Cloud\", \"risk\": { \"trustRating\": 10 }, \"properties\": { \"Name\": \"Public Cloud\", \"Dataflow Order\": \"0\" }, \"representations\": [ { \"name\": \"Public Cloud Representation\", \"id\": \"24cdf4da-ac7f-4a35-bab0-29256d4169bf-representation\", \"representation\": \"mtmt_project_id-diagram\", \"size\": { \"width\": 371, \"height\": 308 }, \"position\": { \"x\": 744, \"y\": 142 } } ] } ], \"components\": [ { \"id\": \"53245f54-0656-4ede-a393-357aeaa2e20f\", \"name\": \"Accounting PostgreSQL\", \"type\": \"CD-MICROSOFT-AZURE-DB-POSTGRESQL\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"properties\": { \"Name\": \"Accounting PostgreSQL\", \"Out Of Scope\": \"false\", \"Azure Postgres DB Firewall Settings\": \"Select\", \"Azure Postgres DB TLS Enforced\": \"Select\" }, \"representations\": [ { \"name\": \"Accounting PostgreSQL Representation\", \"id\": \"53245f54-0656-4ede-a393-357aeaa2e20f-representation\", \"representation\": \"mtmt_project_id-diagram\", \"size\": { \"width\": 100, \"height\": 100 }, \"position\": { \"x\": 231, \"y\": 40 } } ], \"threats\": [ { \"threat\": \"55\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"55\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"1\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"1\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"2\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"2\", \"state\": \"RECOMMENDED\" } ] } ] }, { \"id\": \"6183b7fa-eba5-4bf8-a0af-c3e30d144a10\", \"name\": \"Mobile Client\", \"type\": \"android-device-client\", \"parent\": { \"trustZone\": \"6376d53e-6461-412b-8e04-7b3fe2b397de\" }, \"properties\": { \"Name\": \"Mobile Client\", \"Out Of Scope\": \"false\", \"Mobile Client Technologies\": \"Android\" }, \"representations\": [ { \"name\": \"Mobile Client Representation\", \"id\": \"6183b7fa-eba5-4bf8-a0af-c3e30d144a10-representation\", \"representation\": \"mtmt_project_id-diagram\", \"size\": { \"width\": 100, \"height\": 100 }, \"position\": { \"x\": 47, \"y\": 89 } } ], \"threats\": [ { \"threat\": \"69\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"69\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"68\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"68\", \"state\": \"RECOMMENDED\" } ] } ] }, { \"id\": \"5d15323e-3729-4694-87b1-181c90af5045\", \"name\": \"Public API v2\", \"type\": \"web-service\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"properties\": { \"Name\": \"Public API v2\", \"Out Of Scope\": \"false\", \"Web API Technologies\": \"Select\", \"Hosting environment\": \"Select\", \"Identity Provider\": \"Select\" }, \"representations\": [ { \"name\": \"Public API v2 Representation\", \"id\": \"5d15323e-3729-4694-87b1-181c90af5045-representation\", \"representation\": \"mtmt_project_id-diagram\", \"size\": { \"width\": 100, \"height\": 100 }, \"position\": { \"x\": 21, \"y\": 101 } } ], \"threats\": [ { \"threat\": \"3\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"3\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"4\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"4\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"5\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"5\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"6\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"6\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"7\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"7\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"8\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"8\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"9\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"9\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"10\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"10\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"62\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"62\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"61\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"61\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"60\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"60\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"59\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"59\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"58\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"58\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"57\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"57\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"56\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"56\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"25\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"25\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"26\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"26\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"28\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"28\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"29\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"29\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"30\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"30\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"31\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"31\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"32\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"32\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"33\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"33\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"35\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"35\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"36\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"36\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"37\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"37\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"38\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"38\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"39\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"39\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"67\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"67\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"66\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"66\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"63\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"63\", \"state\": \"RECOMMENDED\" } ] } ] }, { \"id\": \"91882aca-8249-49a7-96f0-164b68411b48\", \"name\": \"Azure File Storage\", \"type\": \"azure-storage\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"properties\": { \"Name\": \"Azure File Storage\", \"Out Of Scope\": \"false\", \"Storage Type\": \"Select\", \"HTTPS Enforced\": \"Select\", \"Network Security\": \"Select\", \"CORS Enabled\": \"Select\" }, \"representations\": [ { \"name\": \"Azure File Storage Representation\", \"id\": \"91882aca-8249-49a7-96f0-164b68411b48-representation\", \"representation\": \"mtmt_project_id-diagram\", \"size\": { \"width\": 100, \"height\": 100 }, \"position\": { \"x\": 230, \"y\": 169 } } ], \"threats\": [ { \"threat\": \"11\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"11\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"12\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"12\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"13\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"13\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"14\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"14\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"15\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"15\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"16\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"16\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"17\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"17\", \"state\": \"RECOMMENDED\" } ] } ] } ], \"dataflows\": [ { \"id\": \"eb072144-af37-4b75-b46b-b78111850d3e\", \"name\": \"PSQL Request\", \"source\": \"5d15323e-3729-4694-87b1-181c90af5045\", \"destination\": \"53245f54-0656-4ede-a393-357aeaa2e20f\", \"bidirectional\": false, \"properties\": { \"Request\": {}, \"Name\": \"PSQL Request\", \"Dataflow Order\": \"0\", \"Out Of Scope\": \"false\", \"Reason For Out Of Scope\": {}, \"Configurable Attributes\": {}, \"As Generic Data Flow\": {}, \"Show Boundary Threats\": \"Select\" } }, { \"id\": \"36091fd8-dba8-424e-a3cd-784ea6bcb9e0\", \"name\": \"PSQL Response\", \"source\": \"53245f54-0656-4ede-a393-357aeaa2e20f\", \"destination\": \"5d15323e-3729-4694-87b1-181c90af5045\", \"bidirectional\": false, \"properties\": { \"Response\": {}, \"Name\": \"PSQL Response\", \"Dataflow Order\": \"0\", \"Out Of Scope\": \"false\", \"Reason For Out Of Scope\": {}, \"Configurable Attributes\": {}, \"As Generic Data Flow\": {}, \"Show Boundary Threats\": \"Select\" } }, { \"id\": \"f5fe3c6e-e10b-4252-a4aa-4ec6108c96a6\", \"name\": \"File Request\", \"source\": \"5d15323e-3729-4694-87b1-181c90af5045\", \"destination\": \"91882aca-8249-49a7-96f0-164b68411b48\", \"bidirectional\": false, \"properties\": { \"Request\": {}, \"Name\": \"File Request\", \"Dataflow Order\": \"0\", \"Out Of Scope\": \"false\", \"Reason For Out Of Scope\": {}, \"Configurable Attributes\": {}, \"As Generic Data Flow\": {}, \"Show Boundary Threats\": \"Select\" } }, { \"id\": \"d826de3d-1464-4d1f-8105-aa0449a50aec\", \"name\": \"File Response\", \"source\": \"91882aca-8249-49a7-96f0-164b68411b48\", \"destination\": \"5d15323e-3729-4694-87b1-181c90af5045\", \"bidirectional\": false, \"properties\": { \"Response\": {}, \"Name\": \"File Response\", \"Dataflow Order\": \"0\", \"Out Of Scope\": \"false\", \"Reason For Out Of Scope\": {}, \"Configurable Attributes\": {}, \"As Generic Data Flow\": {}, \"Show Boundary Threats\": \"Select\" } }, { \"id\": \"9840bcdf-c444-437d-8289-d5468f41b0db\", \"name\": \"API Request\", \"source\": \"6183b7fa-eba5-4bf8-a0af-c3e30d144a10\", \"destination\": \"5d15323e-3729-4694-87b1-181c90af5045\", \"bidirectional\": false, \"properties\": { \"Request\": {}, \"Name\": \"API Request\", \"Dataflow Order\": \"0\", \"Out Of Scope\": \"false\", \"Reason For Out Of Scope\": {}, \"Configurable Attributes\": {}, \"As Generic Data Flow\": {}, \"Show Boundary Threats\": \"Select\" } }, { \"id\": \"5861370d-b333-4d4b-9420-95425026e9c9\", \"name\": \"API Response\", \"source\": \"5d15323e-3729-4694-87b1-181c90af5045\", \"destination\": \"6183b7fa-eba5-4bf8-a0af-c3e30d144a10\", \"bidirectional\": false, \"properties\": { \"Response\": {}, \"Name\": \"API Response\", \"Dataflow Order\": \"0\", \"Out Of Scope\": \"false\", \"Reason For Out Of Scope\": {}, \"Configurable Attributes\": {}, \"As Generic Data Flow\": {}, \"Show Boundary Threats\": \"Select\" } } ], \"threats\": [ { \"name\": \"An adversary can gain unauthorized access to Azure Postgres DB instances due to weak network security configuration\", \"id\": \"55\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain unauthorized access to Accounting PostgreSQL instances due to weak network security configuration\" }, { \"name\": \"An adversary may read and/or tamper with the data transmitted to Azure Postgres DB due to weak configuration\", \"id\": \"1\", \"categories\": [ \"Tampering\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may read and/or tamper with the data transmitted to Accounting PostgreSQL due to weak configuration\" }, { \"name\": \"An adversary can gain long term, persistent access to an Azure Postgres DB instance through the compromise of local user account password(s)\", \"id\": \"2\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain long term, persistent access to Accounting PostgreSQL instance through the compromise of local user account password(s)\" }, { \"name\": \"An adversary may gain unauthorized access to Web API due to poor access control checks\", \"id\": \"3\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may gain unauthorized access to Web API due to poor access control checks\" }, { \"name\": \"An adversary can gain access to sensitive information from an API through error messages\", \"id\": \"4\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to sensitive data such as the following, through verbose error messages - Server names - Connection strings - Usernames - Passwords - SQL procedures - Details of dynamic SQL failures - Stack trace and lines of code - Variables stored in memory - Drive and folder locations - Application install points - Host configuration settings - Other internal application details\" }, { \"name\": \"An adversary can gain access to sensitive data by sniffing traffic to Web API\", \"id\": \"5\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to sensitive data by sniffing traffic to Web API\" }, { \"name\": \"An adversary can gain access to sensitive data stored in Web API's config files\", \"id\": \"6\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to the config files. and if sensitive data is stored in it, it would be compromised\" }, { \"name\": \"Attacker can deny a malicious act on an API leading to repudiation issues\", \"id\": \"7\", \"categories\": [ \"Repudiation\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"Attacker can deny a malicious act on an API leading to repudiation issues\" }, { \"name\": \"An adversary may spoof Accounting PostgreSQL and gain access to Web API\", \"id\": \"8\", \"categories\": [ \"Spoofing\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"If proper authentication is not in place, an adversary can spoof a source process or external entity and gain unauthorized access to the Web Application\" }, { \"name\": \"An adversary may inject malicious inputs into an API and affect downstream processes\", \"id\": \"9\", \"categories\": [ \"Tampering\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may inject malicious inputs into an API and affect downstream processes\" }, { \"name\": \"An adversary can gain access to sensitive data by performing SQL injection through Web API\", \"id\": \"10\", \"categories\": [ \"Tampering\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"SQL injection is an attack in which malicious code is inserted into strings that are later passed to an instance of SQL Server for parsing and execution. The primary form of SQL injection consists of direct insertion of code into user-input variables that are concatenated with SQL commands and executed. A less direct attack injects malicious code into strings that are destined for storage in a table or as metadata. When the stored strings are subsequently concatenated into a dynamic SQL command, the malicious code is executed\" }, { \"name\": \"An adversary can gain unauthorized access to Azure File Storage due to weak access control restrictions\", \"id\": \"11\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain unauthorized access to Azure File Storage due to weak access control restrictions\" }, { \"name\": \"An adversary can gain unauthorized access to Azure File Storage instances due to weak network configuration\", \"id\": \"12\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain unauthorized access to Azure File Storage instances due to weak network configuration\" }, { \"name\": \"An adversary may gain unauthorized access to Azure File Storage account in a subscription\", \"id\": \"13\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may gain unauthorized access to Azure File Storage account in a subscription\" }, { \"name\": \"An adversary can abuse poorly managed Azure File Storage account access keys\", \"id\": \"14\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can abuse poorly managed Azure File Storage account access keys and gain unauthorized access to storage\" }, { \"name\": \"An adversary can abuse an insecure communication channel between a client and Azure File Storage\", \"id\": \"15\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can abuse an insecure communication channel between a client and Azure File Storage\" }, { \"name\": \"An adversary can deny actions on Azure File Storage due to lack of auditing\", \"id\": \"16\", \"categories\": [ \"Repudiation\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"Proper logging of all security events and user actions builds traceability in a system and denies any possible repudiation issues. In the absence of proper auditing and logging controls, it would become impossible to implement any accountability in a system\" }, { \"name\": \"An adversary can gain unauthorized access to Azure File Storage due to weak CORS configuration\", \"id\": \"17\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain unauthorized access to Azure File Storage due to weak CORS configuration\" }, { \"name\": \"An adversary may inject malicious inputs into an API and affect downstream processes\", \"id\": \"62\", \"categories\": [ \"Tampering\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may inject malicious inputs into an API and affect downstream processes\" }, { \"name\": \"An adversary may spoof Azure File Storage and gain access to Web API\", \"id\": \"61\", \"categories\": [ \"Spoofing\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"If proper authentication is not in place, an adversary can spoof a source process or external entity and gain unauthorized access to the Web Application\" }, { \"name\": \"Attacker can deny a malicious act on an API leading to repudiation issues\", \"id\": \"60\", \"categories\": [ \"Repudiation\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"Attacker can deny a malicious act on an API leading to repudiation issues\" }, { \"name\": \"An adversary can gain access to sensitive data stored in Web API's config files\", \"id\": \"59\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to the config files. and if sensitive data is stored in it, it would be compromised\" }, { \"name\": \"An adversary can gain access to sensitive data by sniffing traffic to Web API\", \"id\": \"58\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to sensitive data by sniffing traffic to Web API\" }, { \"name\": \"An adversary can gain access to sensitive information from an API through error messages\", \"id\": \"57\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to sensitive data such as the following, through verbose error messages - Server names - Connection strings - Usernames - Passwords - SQL procedures - Details of dynamic SQL failures - Stack trace and lines of code - Variables stored in memory - Drive and folder locations - Application install points - Host configuration settings - Other internal application details\" }, { \"name\": \"An adversary may gain unauthorized access to Web API due to poor access control checks\", \"id\": \"56\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may gain unauthorized access to Web API due to poor access control checks\" }, { \"name\": \"An adversary may jail break into a mobile device and gain elevated privileges\", \"id\": \"25\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may jail break into a mobile device and gain elevated privileges\" }, { \"name\": \"An adversary may gain unauthorized access to Web API due to poor access control checks\", \"id\": \"26\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may gain unauthorized access to Web API due to poor access control checks\" }, { \"name\": \"An adversary may spoof an Azure administrator and gain access to Azure subscription portal\", \"id\": \"69\", \"categories\": [ \"Spoofing\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may spoof an Azure administrator and gain access to Azure subscription portal if the administrator's credentials are compromised\" }, { \"name\": \"An adversary can gain access to sensitive information from an API through error messages\", \"id\": \"28\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to sensitive data such as the following, through verbose error messages - Server names - Connection strings - Usernames - Passwords - SQL procedures - Details of dynamic SQL failures - Stack trace and lines of code - Variables stored in memory - Drive and folder locations - Application install points - Host configuration settings - Other internal application details\" }, { \"name\": \"An adversary can gain access to sensitive data by sniffing traffic from Mobile client\", \"id\": \"29\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to sensitive data by sniffing traffic from Mobile client\" }, { \"name\": \"An adversary can gain access to sensitive data by sniffing traffic to Web API\", \"id\": \"30\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to sensitive data by sniffing traffic to Web API\" }, { \"name\": \"An adversary can gain sensitive data from mobile device\", \"id\": \"31\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"If application saves sensitive PII or HBI data on phone SD card or local storage, then it ay get stolen\" }, { \"name\": \"An adversary can gain access to sensitive data stored in Web API's config files\", \"id\": \"32\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to the config files. and if sensitive data is stored in it, it would be compromised\" }, { \"name\": \"Attacker can deny a malicious act on an API leading to repudiation issues\", \"id\": \"33\", \"categories\": [ \"Repudiation\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"Attacker can deny a malicious act on an API leading to repudiation issues\" }, { \"name\": \"An adversary can gain unauthorized access to resources in an Azure subscription\", \"id\": \"68\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain unauthorized access to resources in Azure subscription. The adversary can be either a disgruntled internal user, or someone who has stolen the credentials of an Azure subscription\" }, { \"name\": \"An adversary obtains refresh or access tokens from Mobile Client and uses them to obtain access to the Public API v2 API\", \"id\": \"35\", \"categories\": [ \"Spoofing\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"On a public client (e.g. a mobile device), refresh tokens may be stolen and used by an attacker to obtain access to the API. Depending on the client type, there are different ways that tokens may be revealed to an attacker and therefore different ways to protect them, some involving how the software using the tokens requests, stores and refreshes them\" }, { \"name\": \"An adversary may spoof Mobile Client and gain access to Web API\", \"id\": \"36\", \"categories\": [ \"Spoofing\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"If proper authentication is not in place, an adversary can spoof a source process or external entity and gain unauthorized access to the Web Application\" }, { \"name\": \"An adversary may inject malicious inputs into an API and affect downstream processes\", \"id\": \"37\", \"categories\": [ \"Tampering\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may inject malicious inputs into an API and affect downstream processes\" }, { \"name\": \"An adversary can reverse engineer and tamper binaries\", \"id\": \"38\", \"categories\": [ \"Tampering\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can use various tools, reverse engineer binaries and abuse them by tampering\" }, { \"name\": \"An adversary can gain access to sensitive data by performing SQL injection through Web API\", \"id\": \"39\", \"categories\": [ \"Tampering\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"SQL injection is an attack in which malicious code is inserted into strings that are later passed to an instance of SQL Server for parsing and execution. The primary form of SQL injection consists of direct insertion of code into user-input variables that are concatenated with SQL commands and executed. A less direct attack injects malicious code into strings that are destined for storage in a table or as metadata. When the stored strings are subsequently concatenated into a dynamic SQL command, the malicious code is executed\" }, { \"name\": \"An adversary may spoof an Azure administrator and gain access to Azure subscription portal\", \"id\": \"67\", \"categories\": [ \"Spoofing\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may spoof an Azure administrator and gain access to Azure subscription portal if the administrator's credentials are compromised\" }, { \"name\": \"An adversary can gain unauthorized access to resources in an Azure subscription\", \"id\": \"66\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain unauthorized access to resources in Azure subscription. The adversary can be either a disgruntled internal user, or someone who has stolen the credentials of an Azure subscription\" }, { \"name\": \"An adversary can gain access to sensitive data by performing SQL injection through Web API\", \"id\": \"63\", \"categories\": [ \"Tampering\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"SQL injection is an attack in which malicious code is inserted into strings that are later passed to an instance of SQL Server for parsing and execution. The primary form of SQL injection consists of direct insertion of code into user-input variables that are concatenated with SQL commands and executed. A less direct attack injects malicious code into strings that are destined for storage in a table or as metadata. When the stored strings are subsequently concatenated into a dynamic SQL command, the malicious code is executed\" } ], \"mitigations\": [ { \"name\": \"Restrict access to Azure Postgres DB instances by configuring server-level firewall rules to only permit connections from selected IP addresses where possible\", \"id\": \"55\", \"riskReduction\": 100, \"description\": \"Restrict access to Azure Postgres DB instances by configuring server-level firewall rules to only permit connections from selected IP addresses where possible. Refer: <a href=\\\"https://aka.ms/tmt-th153\\\">https://aka.ms/tmt-th153</a>\" }, { \"name\": \"Enforce communication between clients and Azure Postgres DB to be over SSL/TLS by enabling the Enforce SSL connection feature on the server\", \"id\": \"1\", \"riskReduction\": 100, \"description\": \"Enforce communication between clients and Azure Postgres DB to be over SSL/TLS by enabling the Enforce SSL connection feature on the server. Check that the connection strings used to connect to MySQL databases have the right configuration (e.g. ssl = true or sslmode=require or sslmode=true are set). Refer: <a href=\\\"https://aka.ms/tmt-th154a\\\">https://aka.ms/tmt-th154a</a> Configure MySQL server to use a verifiable SSL certificate (needed for SSL/TLS communication). Refer: <a href=\\\"https://aka.ms/tmt-th154b\\\">https://aka.ms/tmt-th154b</a>\" }, { \"name\": \"It is recommended to rotate user account passwords (e\", \"id\": \"2\", \"riskReduction\": 100, \"description\": \"It is recommended to rotate user account passwords (e.g. those used in connection strings) regularly, in accordance with your organization's policies. Store secrets in a secret storage solution (e.g. Azure Key Vault)\" }, { \"name\": \"Implement proper authorization mechanism in ASP\", \"id\": \"3\", \"riskReduction\": 100, \"description\": \"Implement proper authorization mechanism in ASP.NET Web API. Refer: <a href=\\\"https://aka.ms/tmtauthz#authz-aspnet\\\">https://aka.ms/tmtauthz#authz-aspnet</a>\" }, { \"name\": \"Ensure that proper exception handling is done in ASP\", \"id\": \"4\", \"riskReduction\": 100, \"description\": \"Ensure that proper exception handling is done in ASP.NET Web API. Refer: <a href=\\\"https://aka.ms/tmtxmgmt#exception\\\">https://aka.ms/tmtxmgmt#exception</a>\" }, { \"name\": \"Force all traffic to Web APIs over HTTPS connection\", \"id\": \"5\", \"riskReduction\": 100, \"description\": \"Force all traffic to Web APIs over HTTPS connection. Refer: <a href=\\\"https://aka.ms/tmtcommsec#webapi-https\\\">https://aka.ms/tmtcommsec#webapi-https</a>\" }, { \"name\": \"Encrypt sections of Web API's configuration files that contain sensitive data\", \"id\": \"6\", \"riskReduction\": 100, \"description\": \"Encrypt sections of Web API's configuration files that contain sensitive data. Refer: <a href=\\\"https://aka.ms/tmtconfigmgmt#config-sensitive\\\">https://aka.ms/tmtconfigmgmt#config-sensitive</a>\" }, { \"name\": \"Ensure that auditing and logging is enforced on Web API\", \"id\": \"7\", \"riskReduction\": 100, \"description\": \"Ensure that auditing and logging is enforced on Web API. Refer: <a href=\\\"https://aka.ms/tmtauditlog#logging-web-api\\\">https://aka.ms/tmtauditlog#logging-web-api</a>\" }, { \"name\": \"Ensure that standard authentication techniques are used to secure Web APIs\", \"id\": \"8\", \"riskReduction\": 100, \"description\": \"Ensure that standard authentication techniques are used to secure Web APIs. Refer: <a href=\\\"https://aka.ms/tmtauthn#authn-secure-api\\\">https://aka.ms/tmtauthn#authn-secure-api</a>\" }, { \"name\": \"Ensure that model validation is done on Web API methods\", \"id\": \"9\", \"riskReduction\": 100, \"description\": \"Ensure that model validation is done on Web API methods. Refer: <a href=\\\"https://aka.ms/tmtinputval#validation-api\\\">https://aka.ms/tmtinputval#validation-api</a> Implement input validation on all string type parameters accepted by Web API methods. Refer: <a href=\\\"https://aka.ms/tmtinputval#string-api\\\">https://aka.ms/tmtinputval#string-api</a>\" }, { \"name\": \"Ensure that type-safe parameters are used in Web API for data access\", \"id\": \"10\", \"riskReduction\": 100, \"description\": \"Ensure that type-safe parameters are used in Web API for data access. Refer: <a href=\\\"https://aka.ms/tmtinputval#typesafe-api\\\">https://aka.ms/tmtinputval#typesafe-api</a>\" }, { \"name\": \"Grant limited access to objects in Azure Storage using SAS or SAP\", \"id\": \"11\", \"riskReduction\": 100, \"description\": \"Grant limited access to objects in Azure Storage using SAS or SAP. It is recommended to scope SAS and SAP to permit only the necessary permissions over a short period of time. Refer: <a href=\\\"https://aka.ms/tmt-th17a\\\">https://aka.ms/tmt-th17a</a> and <a href=\\\"https://aka.ms/tmt-th17b\\\">https://aka.ms/tmt-th17b</a>\" }, { \"name\": \"It is recommended to restrict access to Azure Storage instances to selected networks where possible\", \"id\": \"12\", \"riskReduction\": 100, \"description\": \"It is recommended to restrict access to Azure Storage instances to selected networks where possible. <a href=\\\"https://aka.ms/tmt-th140\\\">https://aka.ms/tmt-th140</a>\" }, { \"name\": \"Assign the appropriate Role-Based Access Control (RBAC) role to users, groups and applications at the right scope for the Azure Storage instance\", \"id\": \"13\", \"riskReduction\": 100, \"description\": \"Assign the appropriate Role-Based Access Control (RBAC) role to users, groups and applications at the right scope for the Azure Storage instance. Refer: <a href=\\\"https://aka.ms/tmt-th67\\\">https://aka.ms/tmt-th67</a>\" }, { \"name\": \"Ensure secure management and storage of Azure storage access keys\", \"id\": \"14\", \"riskReduction\": 100, \"description\": \"Ensure secure management and storage of Azure storage access keys. It is recommended to rotate storage access keys regularly, in accordance with organizational policies. Refer: <a href=\\\"https://aka.ms/tmt-th63\\\">https://aka.ms/tmt-th63</a>\" }, { \"name\": \"Ensure that communication to Azure Storage is over HTTPS\", \"id\": \"15\", \"riskReduction\": 100, \"description\": \"Ensure that communication to Azure Storage is over HTTPS. It is recommended to enable the secure transfer required option to force communication with Azure Storage to be over HTTPS. Use Client-Side Encryption to store sensitive data in Azure Storage. Refer: <a href=\\\"https://aka.ms/tmt-th65\\\">https://aka.ms/tmt-th65</a>\" }, { \"name\": \"Use Azure Storage Analytics to audit access of Azure Storage\", \"id\": \"16\", \"riskReduction\": 100, \"description\": \"Use Azure Storage Analytics to audit access of Azure Storage. If possible, audit the calls to the Azure Storage instance at the source of the call. Refer: <a href=\\\"https://aka.ms/tmt-th20\\\">https://aka.ms/tmt-th20</a>\" }, { \"name\": \"Ensure that only specific, trusted origins are allowed\", \"id\": \"17\", \"riskReduction\": 100, \"description\": \"Ensure that only specific, trusted origins are allowed. Refer: <a href=\\\"https://aka.ms/tmt-th21\\\">https://aka.ms/tmt-th21</a>\" }, { \"name\": \"Ensure that model validation is done on Web API methods\", \"id\": \"62\", \"riskReduction\": 100, \"description\": \"Ensure that model validation is done on Web API methods. Refer: <a href=\\\"https://aka.ms/tmtinputval#validation-api\\\">https://aka.ms/tmtinputval#validation-api</a> Implement input validation on all string type parameters accepted by Web API methods. Refer: <a href=\\\"https://aka.ms/tmtinputval#string-api\\\">https://aka.ms/tmtinputval#string-api</a>\" }, { \"name\": \"Ensure that standard authentication techniques are used to secure Web APIs\", \"id\": \"61\", \"riskReduction\": 100, \"description\": \"Ensure that standard authentication techniques are used to secure Web APIs. Refer: <a href=\\\"https://aka.ms/tmtauthn#authn-secure-api\\\">https://aka.ms/tmtauthn#authn-secure-api</a>\" }, { \"name\": \"Ensure that auditing and logging is enforced on Web API\", \"id\": \"60\", \"riskReduction\": 100, \"description\": \"Ensure that auditing and logging is enforced on Web API. Refer: <a href=\\\"https://aka.ms/tmtauditlog#logging-web-api\\\">https://aka.ms/tmtauditlog#logging-web-api</a>\" }, { \"name\": \"Encrypt sections of Web API's configuration files that contain sensitive data\", \"id\": \"59\", \"riskReduction\": 100, \"description\": \"Encrypt sections of Web API's configuration files that contain sensitive data. Refer: <a href=\\\"https://aka.ms/tmtconfigmgmt#config-sensitive\\\">https://aka.ms/tmtconfigmgmt#config-sensitive</a>\" }, { \"name\": \"Force all traffic to Web APIs over HTTPS connection\", \"id\": \"58\", \"riskReduction\": 100, \"description\": \"Force all traffic to Web APIs over HTTPS connection. Refer: <a href=\\\"https://aka.ms/tmtcommsec#webapi-https\\\">https://aka.ms/tmtcommsec#webapi-https</a>\" }, { \"name\": \"Ensure that proper exception handling is done in ASP\", \"id\": \"57\", \"riskReduction\": 100, \"description\": \"Ensure that proper exception handling is done in ASP.NET Web API. Refer: <a href=\\\"https://aka.ms/tmtxmgmt#exception\\\">https://aka.ms/tmtxmgmt#exception</a>\" }, { \"name\": \"Implement proper authorization mechanism in ASP\", \"id\": \"56\", \"riskReduction\": 100, \"description\": \"Implement proper authorization mechanism in ASP.NET Web API. Refer: <a href=\\\"https://aka.ms/tmtauthz#authz-aspnet\\\">https://aka.ms/tmtauthz#authz-aspnet</a>\" }, { \"name\": \"Implement implicit jailbreak or rooting detection\", \"id\": \"25\", \"riskReduction\": 100, \"description\": \"Implement implicit jailbreak or rooting detection. Refer: <a href=\\\"https://aka.ms/tmtauthz#rooting-detection\\\">https://aka.ms/tmtauthz#rooting-detection</a>\" }, { \"name\": \"Implement proper authorization mechanism in ASP\", \"id\": \"26\", \"riskReduction\": 100, \"description\": \"Implement proper authorization mechanism in ASP.NET Web API. Refer: <a href=\\\"https://aka.ms/tmtauthz#authz-aspnet\\\">https://aka.ms/tmtauthz#authz-aspnet</a>\" }, { \"name\": \"Enable fine-grained access management to Azure Subscription using RBAC\", \"id\": \"69\", \"riskReduction\": 100, \"description\": \"Enable fine-grained access management to Azure Subscription using RBAC. Refer: <a href=\\\"https://aka.ms/tmtauthz#grained-rbac\\\">https://aka.ms/tmtauthz#grained-rbac</a> Enable Azure Multi-Factor Authentication for Azure Administrators. Refer: <a href=\\\"https://aka.ms/tmtauthn#multi-factor-azure-admin\\\">https://aka.ms/tmtauthn#multi-factor-azure-admin</a>\" }, { \"name\": \"Ensure that proper exception handling is done in ASP\", \"id\": \"28\", \"riskReduction\": 100, \"description\": \"Ensure that proper exception handling is done in ASP.NET Web API. Refer: <a href=\\\"https://aka.ms/tmtxmgmt#exception\\\">https://aka.ms/tmtxmgmt#exception</a>\" }, { \"name\": \"Implement Certificate Pinning\", \"id\": \"29\", \"riskReduction\": 100, \"description\": \"Implement Certificate Pinning. Refer: <a href=\\\"https://aka.ms/tmtcommsec#cert-pinning\\\">https://aka.ms/tmtcommsec#cert-pinning</a>\" }, { \"name\": \"Force all traffic to Web APIs over HTTPS connection\", \"id\": \"30\", \"riskReduction\": 100, \"description\": \"Force all traffic to Web APIs over HTTPS connection. Refer: <a href=\\\"https://aka.ms/tmtcommsec#webapi-https\\\">https://aka.ms/tmtcommsec#webapi-https</a>\" }, { \"name\": \"Encrypt sensitive or PII data written to phones local storage\", \"id\": \"31\", \"riskReduction\": 100, \"description\": \"Encrypt sensitive or PII data written to phones local storage. Refer: <a href=\\\"https://aka.ms/tmtdata#pii-phones\\\">https://aka.ms/tmtdata#pii-phones</a>\" }, { \"name\": \"Encrypt sections of Web API's configuration files that contain sensitive data\", \"id\": \"32\", \"riskReduction\": 100, \"description\": \"Encrypt sections of Web API's configuration files that contain sensitive data. Refer: <a href=\\\"https://aka.ms/tmtconfigmgmt#config-sensitive\\\">https://aka.ms/tmtconfigmgmt#config-sensitive</a>\" }, { \"name\": \"Ensure that auditing and logging is enforced on Web API\", \"id\": \"33\", \"riskReduction\": 100, \"description\": \"Ensure that auditing and logging is enforced on Web API. Refer: <a href=\\\"https://aka.ms/tmtauditlog#logging-web-api\\\">https://aka.ms/tmtauditlog#logging-web-api</a>\" }, { \"name\": \"Enable fine-grained access management to Azure Subscription using RBAC\", \"id\": \"68\", \"riskReduction\": 100, \"description\": \"Enable fine-grained access management to Azure Subscription using RBAC. Refer: <a href=\\\"https://aka.ms/tmtauthz#grained-rbac\\\">https://aka.ms/tmtauthz#grained-rbac</a>\" }, { \"name\": \"Use ADAL libraries to manage token requests from OAuth2 clients to AAD (or on-premises AD)\", \"id\": \"35\", \"riskReduction\": 100, \"description\": \"Use ADAL libraries to manage token requests from OAuth2 clients to AAD (or on-premises AD). Refer: <a href=\\\"https://aka.ms/tmtauthn#adal-oauth2\\\">https://aka.ms/tmtauthn#adal-oauth2</a>\" }, { \"name\": \"Ensure that standard authentication techniques are used to secure Web APIs\", \"id\": \"36\", \"riskReduction\": 100, \"description\": \"Ensure that standard authentication techniques are used to secure Web APIs. Refer: <a href=\\\"https://aka.ms/tmtauthn#authn-secure-api\\\">https://aka.ms/tmtauthn#authn-secure-api</a>\" }, { \"name\": \"Ensure that model validation is done on Web API methods\", \"id\": \"37\", \"riskReduction\": 100, \"description\": \"Ensure that model validation is done on Web API methods. Refer: <a href=\\\"https://aka.ms/tmtinputval#validation-api\\\">https://aka.ms/tmtinputval#validation-api</a> Implement input validation on all string type parameters accepted by Web API methods. Refer: <a href=\\\"https://aka.ms/tmtinputval#string-api\\\">https://aka.ms/tmtinputval#string-api</a>\" }, { \"name\": \"Obfuscate generated binaries before distributing to end users\", \"id\": \"38\", \"riskReduction\": 100, \"description\": \"Obfuscate generated binaries before distributing to end users. Refer: <a href=\\\"https://aka.ms/tmtdata#binaries-end\\\">https://aka.ms/tmtdata#binaries-end</a>\" }, { \"name\": \"Ensure that type-safe parameters are used in Web API for data access\", \"id\": \"39\", \"riskReduction\": 100, \"description\": \"Ensure that type-safe parameters are used in Web API for data access. Refer: <a href=\\\"https://aka.ms/tmtinputval#typesafe-api\\\">https://aka.ms/tmtinputval#typesafe-api</a>\" }, { \"name\": \"Enable fine-grained access management to Azure Subscription using RBAC\", \"id\": \"67\", \"riskReduction\": 100, \"description\": \"Enable fine-grained access management to Azure Subscription using RBAC. Refer: <a href=\\\"https://aka.ms/tmtauthz#grained-rbac\\\">https://aka.ms/tmtauthz#grained-rbac</a> Enable Azure Multi-Factor Authentication for Azure Administrators. Refer: <a href=\\\"https://aka.ms/tmtauthn#multi-factor-azure-admin\\\">https://aka.ms/tmtauthn#multi-factor-azure-admin</a>\" }, { \"name\": \"Enable fine-grained access management to Azure Subscription using RBAC\", \"id\": \"66\", \"riskReduction\": 100, \"description\": \"Enable fine-grained access management to Azure Subscription using RBAC. Refer: <a href=\\\"https://aka.ms/tmtauthz#grained-rbac\\\">https://aka.ms/tmtauthz#grained-rbac</a>\" }, { \"name\": \"Ensure that type-safe parameters are used in Web API for data access\", \"id\": \"63\", \"riskReduction\": 100, \"description\": \"Ensure that type-safe parameters are used in Web API for data access. Refer: <a href=\\\"https://aka.ms/tmtinputval#typesafe-api\\\">https://aka.ms/tmtinputval#typesafe-api</a>\" } ] } Open Threat Model parsing How to create a new StartLeft Processor It is possible to use StartLeft for parsing different formats to OTM, or even creating a new StartLeft Processor for formats that are not currently supported. There is an in depth tutorial explaining what is a StartLeft Processor and how to create one from scratch in the following link: Create a new StartLeft Processor Creating a StartLeft Processor allows you to focus on the parsing logic, while StartLeft takes care of building and validating the OTM and exposing an API or CLI for ease of operation. How to create an OTM Parser without using StartLeft Although creating a new StartLeft Processor is the preferred method of supporting new formats, it is also possible to develop your own OTM parser. An example of how to create it is detailed in the following link: https://www.iriusrisk.com/resources-blog/how-to-create-an-open-threat-model-parser","title":"Open Threat Model (OTM)"},{"location":"Open-Threat-Model-%28OTM%29/#open-threat-model-standard","text":"The Open Threat Modeling Format (OTM) defines a platform independent way to define the threat model of any system. It\u2019s a simple and tool agnostic YAML (or JSON ) format that describes the essential elements and properties of a threat model and which allows to understand what are the components of a system, how are they distributed, the security risks that could be exposed to attackers and the mitigations that could be implemented to avoid those vulnerabilities (see https://www.iriusrisk.com/resources-blog/introduction-to-the-open-threat-model-standard ). A detailed description about the standard is included in the OTM Project .","title":"Open Threat Model standard"},{"location":"Open-Threat-Model-%28OTM%29/#format","text":"An OTM document is itself a JSON object, which may be represented either in JSON or YAML format. All field names in the specification are case-sensitive. This includes all fields that are used as keys in a map. The specification follows the same approach to JSON formats as the OpenAPI specification. See the Swagger specification for more information. Manual OTM example otmVersion: 0.1.0 project: name: Manual ThreatModel id: manual-threatmodel trustZones: - id: f0ba7722-39b6-4c81-8290-a30a248bb8d9 name: Internet risk: trustRating: 1 - id: 6376d53e-6461-412b-8e04-7b3fe2b397de name: Public risk: trustRating: 1 - id: 2ab4effa-40b7-4cd2-ba81-8247d29a6f2d name: Private Secured risk: trustRating: 100 components: - id: user name: User type: generic-client parent: trustZone: f0ba7722-39b6-4c81-8290-a30a248bb8d9 - id: web-server name: Web server type: web-application-server-side parent: trustZone: 6376d53e-6461-412b-8e04-7b3fe2b397de - id: database name: Database type: postgresql parent: trustZone: 2ab4effa-40b7-4cd2-ba81-8247d29a6f2d dataflows: - id: client-connection name: Client connection source: user destination: web-server - id: database-connection name: Database connection source: web-server destination: database","title":"Format"},{"location":"Open-Threat-Model-%28OTM%29/#schema","text":"The OTM object schema is as follows: Field Type Description otmVersion String REQUIRED This field states the OTM version used in the current file. It is an important field in order to ensure backwards compatibility. project Project object REQUIRED The project node represents the entity within all the other elements are grouped. It's the unit of work. representations Representations object Representations define different ways in which the project may be represented. Representation is an abstract concept and there might be several implementations. assets Assets object Assets are the different kinds of sensible information that take part in our threat model. components Components object Components are the different pieces of software / hardware that make up our project. dataflows DataFlows object Data flows are the elements that describe the movement of relevant information (assets) across our architecture. trustZones TrustZones object Trust zones are the different areas within which components are located. They define how trustworthy an area is, based on how accessible it is: the more accessible, the less trustworthy. threats Threats object Threats are the undesirable outcomes that can occur in our system and that we want to prevent. mitigations Mitigations object Mitigations are the actions that we can take (or controls that we can put in place) in order to prevent a threat from taking place.","title":"Schema"},{"location":"Open-Threat-Model-%28OTM%29/#open-threat-model-examples","text":"Some examples of otm files are shown below, along with the project that each one generates. Cloudformation project example OTM file Generated project { \"otmVersion\": \"0.1.0\", \"project\": { \"name\": \"cft_multiple_files_project\", \"id\": \"cft_multiple_files_project_id\" }, \"representations\": [ { \"name\": \"CloudFormation\", \"id\": \"CloudFormation\", \"type\": \"code\" } ], \"trustZones\": [ { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\", \"name\": \"Public Cloud\", \"risk\": { \"trustRating\": 10 } }, { \"id\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9\", \"name\": \"Internet\", \"risk\": { \"trustRating\": 10 } } ], \"components\": [ { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\", \"name\": \"CustomVPC\", \"type\": \"vpc\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"tags\": [ \"AWS::EC2::VPC\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1\", \"name\": \"PrivateSubnet1\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\" }, \"tags\": [ \"AWS::EC2::Subnet\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2\", \"name\": \"PrivateSubnet2\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\" }, \"tags\": [ \"AWS::EC2::Subnet\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet1\", \"name\": \"PublicSubnet1\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\" }, \"tags\": [ \"AWS::EC2::Subnet\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet2\", \"name\": \"PublicSubnet2\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\" }, \"tags\": [ \"AWS::EC2::Subnet\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.vpcssm\", \"name\": \"VPCssm\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1\" }, \"tags\": [ \"AWS::EC2::VPCEndpoint\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.vpcssm\", \"name\": \"VPCssm\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2\" }, \"tags\": [ \"AWS::EC2::VPCEndpoint\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.vpcssmmessages\", \"name\": \"VPCssmmessages\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1\" }, \"tags\": [ \"AWS::EC2::VPCEndpoint\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.vpcssmmessages\", \"name\": \"VPCssmmessages\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2\" }, \"tags\": [ \"AWS::EC2::VPCEndpoint\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.vpcmonitoring\", \"name\": \"VPCmonitoring\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1\" }, \"tags\": [ \"AWS::EC2::VPCEndpoint\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.vpcmonitoring\", \"name\": \"VPCmonitoring\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2\" }, \"tags\": [ \"AWS::EC2::VPCEndpoint\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.service\", \"name\": \"Service\", \"type\": \"elastic-container-service\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1\" }, \"tags\": [ \"AWS::ECS::Service\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.service\", \"name\": \"Service\", \"type\": \"elastic-container-service\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2\" }, \"tags\": [ \"AWS::ECS::Service\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.service.servicetaskdefinition\", \"name\": \"ServiceTaskDefinition\", \"type\": \"docker-container\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.service\" }, \"tags\": [ \"AWS::ECS::TaskDefinition\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.service.servicetaskdefinition\", \"name\": \"ServiceTaskDefinition\", \"type\": \"docker-container\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.service\" }, \"tags\": [ \"AWS::ECS::TaskDefinition\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.servicelb\", \"name\": \"ServiceLB\", \"type\": \"load-balancer\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1\" }, \"tags\": [ \"AWS::ElasticLoadBalancingV2::LoadBalancer\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.servicelb\", \"name\": \"ServiceLB\", \"type\": \"load-balancer\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2\" }, \"tags\": [ \"AWS::ElasticLoadBalancingV2::LoadBalancer\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet1.canary\", \"name\": \"Canary\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet1\" }, \"tags\": [ \"AWS::Synthetics::Canary\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet2.canary\", \"name\": \"Canary\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet2\" }, \"tags\": [ \"AWS::Synthetics::Canary\" ] }, { \"id\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.vpcssmsecuritygroup.0_0_0_0_0\", \"name\": \"0.0.0.0/0\", \"type\": \"generic-client\", \"parent\": { \"trustZone\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9\" }, \"tags\": [ \"Outbound connection destination IP\" ] }, { \"id\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.outboundsecuritygroup.255_255_255_255_32\", \"name\": \"255.255.255.255/32\", \"type\": \"generic-client\", \"parent\": { \"trustZone\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9\" }, \"tags\": [ \"Outbound connection destination IP\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.vpcssm-altsource\", \"name\": \"Systems Manager from VPCEndpoint (grouped)\", \"type\": \"CD-SYSTEMS-MANAGER\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"tags\": [ \"VPCssm (AWS::EC2::VPCEndpoint)\", \"VPCssmmessages (AWS::EC2::VPCEndpoint)\" ] } ], \"dataflows\": [ { \"id\": \"f50bd3e2-40cd-4e6a-a794-774bb2f213c2\", \"name\": \"VPCssmSecurityGroup -> VPCssm\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.vpcssm\", \"tags\": [ \"tcp\", \"443\", \"443\" ] }, { \"id\": \"04e8573e-d0aa-4964-ba5a-3492c705f111\", \"name\": \"VPCssm -> VPCssmSecurityGroup\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.vpcssm\", \"destination\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.vpcssmsecuritygroup.0_0_0_0_0\", \"tags\": [ \"Allow all outbound traffic by default\", \"-1\", \"0.0.0.0/0\" ] }, { \"id\": \"617dee3d-8a20-4153-8c70-9c32fc7ecde3\", \"name\": \"VPCssmSecurityGroup -> VPCssm\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.vpcssm\", \"tags\": [ \"tcp\", \"443\", \"443\" ] }, { \"id\": \"dae9fa64-9828-4710-a3e6-bf618b6a47e6\", \"name\": \"VPCssm -> VPCssmSecurityGroup\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.vpcssm\", \"destination\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.vpcssmsecuritygroup.0_0_0_0_0\", \"tags\": [ \"Allow all outbound traffic by default\", \"-1\", \"0.0.0.0/0\" ] }, { \"id\": \"d65adb9a-6e1a-4a64-9971-baecb082e617\", \"name\": \"VPCssmmessagesSecurityGroup -> VPCssmmessages\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.vpcssmmessages\", \"tags\": [ \"tcp\", \"443\", \"443\" ] }, { \"id\": \"65cce749-e20c-472f-8323-6aa6693e4205\", \"name\": \"VPCssmmessages -> VPCssmmessagesSecurityGroup\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.vpcssmmessages\", \"destination\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.vpcssmsecuritygroup.0_0_0_0_0\", \"tags\": [ \"Allow all outbound traffic by default\", \"-1\", \"0.0.0.0/0\" ] }, { \"id\": \"86165718-ca5f-4ddb-b981-0566f6d8f52a\", \"name\": \"VPCssmmessagesSecurityGroup -> VPCssmmessages\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.vpcssmmessages\", \"tags\": [ \"tcp\", \"443\", \"443\" ] }, { \"id\": \"76a092f4-1f7f-4cad-8e65-ad29065aeac5\", \"name\": \"VPCssmmessages -> VPCssmmessagesSecurityGroup\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.vpcssmmessages\", \"destination\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.vpcssmsecuritygroup.0_0_0_0_0\", \"tags\": [ \"Allow all outbound traffic by default\", \"-1\", \"0.0.0.0/0\" ] }, { \"id\": \"101a5dc5-1d25-445a-92a2-71bafe2661b5\", \"name\": \"VPCmonitoringSecurityGroup -> VPCmonitoring\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.vpcmonitoring\", \"tags\": [ \"tcp\", \"443\", \"443\" ] }, { \"id\": \"abcefff3-5de5-4cae-9b72-4c1db550d782\", \"name\": \"VPCmonitoring -> VPCmonitoringSecurityGroup\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.vpcmonitoring\", \"destination\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.vpcssmsecuritygroup.0_0_0_0_0\", \"tags\": [ \"Allow all outbound traffic by default\", \"-1\", \"0.0.0.0/0\" ] }, { \"id\": \"60e99a7e-6e0a-44e2-89a9-f8186e6221d4\", \"name\": \"VPCmonitoringSecurityGroup -> VPCmonitoring\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.vpcmonitoring\", \"tags\": [ \"tcp\", \"443\", \"443\" ] }, { \"id\": \"893291bd-509f-40e1-b24d-bce8f1eb6e3a\", \"name\": \"VPCmonitoring -> VPCmonitoringSecurityGroup\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.vpcmonitoring\", \"destination\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.vpcssmsecuritygroup.0_0_0_0_0\", \"tags\": [ \"Allow all outbound traffic by default\", \"-1\", \"0.0.0.0/0\" ] }, { \"id\": \"fffa11dd-2d92-4d9e-b28c-a0468af49870\", \"name\": \"Service -> OutboundSecurityGroup\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.service\", \"destination\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.outboundsecuritygroup.255_255_255_255_32\", \"tags\": [ \"Disallow all traffic\", \"icmp\", \"255.255.255.255/32\" ] }, { \"id\": \"5e84eded-dd7a-48f2-83df-714bce5ddd81\", \"name\": \"Service -> OutboundSecurityGroup\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.service\", \"destination\": \"f0ba7722-39b6-4c81-8290-a30a248bb8d9.outboundsecuritygroup.255_255_255_255_32\", \"tags\": [ \"Disallow all traffic\", \"icmp\", \"255.255.255.255/32\" ] }, { \"id\": \"5c22512c-36c9-421c-a7da-bb1bf2994956\", \"name\": \"ServiceLB -> Service\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.servicelb\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.service\", \"tags\": [ \"Load balancer to target\", \"tcp\", \"80\", \"80\", \"Load balancer to target\", \"tcp\", \"80\", \"80\" ] }, { \"id\": \"9224208d-918b-4406-af96-1407e807fa7e\", \"name\": \"ServiceLB -> Service\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.servicelb\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.service\", \"tags\": [ \"Load balancer to target\", \"tcp\", \"80\", \"80\", \"Load balancer to target\", \"tcp\", \"80\", \"80\" ] }, { \"id\": \"8656b4a0-0fdf-4fc8-8207-888388a0a2a1\", \"name\": \"Canary -> ServiceLB\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet1.canary\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.servicelb\", \"tags\": [ \"from ECSFargateGoCanaryStackCanarySecurityGroup:443\", \"tcp\", \"443\", \"443\" ] }, { \"id\": \"24b32b34-d8df-44eb-bf06-5bafdad9c3a7\", \"name\": \"Canary -> ServiceLB\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet2.canary\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.servicelb\", \"tags\": [ \"from ECSFargateGoCanaryStackCanarySecurityGroup:443\", \"tcp\", \"443\", \"443\" ] }, { \"id\": \"d0a14b14-c7af-4f2f-8a09-7d20924b85a2\", \"name\": \"ServiceLB -> Service\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.servicelb\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1.service\", \"tags\": [ \"Load balancer to target\", \"tcp\", \"80\", \"80\", \"Load balancer to target\", \"tcp\", \"80\", \"80\" ] }, { \"id\": \"a4bb6f9e-91ca-4314-9fab-04aa434c4099\", \"name\": \"ServiceLB -> Service\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.servicelb\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.service\", \"tags\": [ \"Load balancer to target\", \"tcp\", \"80\", \"80\", \"Load balancer to target\", \"tcp\", \"80\", \"80\" ] }, { \"id\": \"db637226-95ad-410d-b482-8e2fa8c5cbff\", \"name\": \"Canary -> ServiceLB\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet1.canary\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.servicelb\", \"tags\": [ \"from ECSFargateGoCanaryStackCanarySecurityGroup:443\", \"tcp\", \"443\", \"443\" ] }, { \"id\": \"73da31ec-24b5-48d2-8366-269b08d08ab6\", \"name\": \"Canary -> ServiceLB\", \"source\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.publicsubnet2.canary\", \"destination\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet2.servicelb\", \"tags\": [ \"from ECSFargateGoCanaryStackCanarySecurityGroup:443\", \"tcp\", \"443\", \"443\" ] } ] } Visio project example OTM file Generated project { \"otmVersion\": \"0.1.0\", \"project\": { \"name\": \"Aws with tz and vpt\", \"id\": \"vs-aws-tz-vpc\" }, \"representations\": [ { \"name\": \"Visio\", \"id\": \"Visio\", \"type\": \"diagram\", \"size\": { \"width\": 1000, \"height\": 1000 } } ], \"trustZones\": [ { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\", \"name\": \"Public Cloud\", \"risk\": { \"trustRating\": 10 } }, { \"id\": \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\", \"name\": \"Private Secured\", \"risk\": { \"trustRating\": 10 } } ], \"components\": [ { \"id\": \"1\", \"name\": \"Amazon EC2\", \"type\": \"ec2\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\": \"12\", \"name\": \"Custom machine\", \"type\": \"ec2\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\": \"30\", \"name\": \"Private Database\", \"type\": \"rds\", \"parent\": { \"trustZone\": \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" } }, { \"id\": \"35\", \"name\": \"Amazon CloudWatch\", \"type\": \"cloudwatch\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\": \"41\", \"name\": \"Custom log system\", \"type\": \"cloudwatch\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } } ], \"dataflows\": [ { \"id\": \"17\", \"name\": \"6ead9f3e-fa04-4b61-b7ba-523aaf27ef7f\", \"source\": \"1\", \"destination\": \"12\" }, { \"id\": \"34\", \"name\": \"64bbe075-4999-423c-b40a-653c86493ee5\", \"source\": \"12\", \"destination\": \"30\" }, { \"id\": \"40\", \"name\": \"682fd394-5b8c-44d2-840b-fec8da18126f\", \"source\": \"1\", \"destination\": \"35\" }, { \"id\": \"46\", \"name\": \"c6d711f1-c867-44c0-a022-89a8babebbe3\", \"source\": \"12\", \"destination\": \"41\" } ] } Terraform project example OTM file Generated project { \"otmVersion\": \"0.1.0\", \"project\": { \"name\": \"Terraform ELB example\", \"id\": \"tf-elb-ex\" }, \"representations\": [ { \"name\": \"Terraform\", \"id\": \"Terraform\", \"type\": \"code\" } ], \"trustZones\": [ { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\", \"name\": \"Public Cloud\", \"risk\": { \"trustRating\": 10 } } ], \"components\": [ { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_vpc-foo\", \"name\": \"foo\", \"type\": \"vpc\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"tags\": [ \"aws_vpc\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_vpc-foo.aws_subnet-baz\", \"name\": \"baz\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_vpc-foo\" }, \"tags\": [ \"aws_subnet\" ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_vpc-foo.aws_subnet-bar\", \"name\": \"bar\", \"type\": \"empty-component\", \"parent\": { \"component\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_vpc-foo\" }, \"tags\": [ \"aws_subnet\" ] } ], \"dataflows\": [] } MTMT project example OTM file Generated project { \"otmVersion\": \"0.1.0\", \"project\": { \"name\": \"mtmt_project_name\", \"id\": \"mtmt_project_id\" }, \"representations\": [ { \"name\": \"Microsoft Threat Modeling Tool\", \"id\": \"Microsoft Threat Modeling Tool\", \"type\": \"threat-model\" }, { \"name\": \"mtmt_project_id Diagram Representation\", \"id\": \"mtmt_project_id-diagram\", \"type\": \"diagram\", \"size\": { \"width\": 2000, \"height\": 2000 } } ], \"trustZones\": [ { \"id\": \"6376d53e-6461-412b-8e04-7b3fe2b397de\", \"name\": \"Internet\", \"risk\": { \"trustRating\": 10 }, \"properties\": { \"Name\": \"Internet\", \"Dataflow Order\": \"0\" }, \"representations\": [ { \"name\": \"Internet Representation\", \"id\": \"7537441a-1c03-48c0-b9c8-f82d5906c139-representation\", \"representation\": \"mtmt_project_id-diagram\", \"size\": { \"width\": 202, \"height\": 281 }, \"position\": { \"x\": 386, \"y\": 151 } } ] }, { \"id\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\", \"name\": \"Public Cloud\", \"risk\": { \"trustRating\": 10 }, \"properties\": { \"Name\": \"Public Cloud\", \"Dataflow Order\": \"0\" }, \"representations\": [ { \"name\": \"Public Cloud Representation\", \"id\": \"24cdf4da-ac7f-4a35-bab0-29256d4169bf-representation\", \"representation\": \"mtmt_project_id-diagram\", \"size\": { \"width\": 371, \"height\": 308 }, \"position\": { \"x\": 744, \"y\": 142 } } ] } ], \"components\": [ { \"id\": \"53245f54-0656-4ede-a393-357aeaa2e20f\", \"name\": \"Accounting PostgreSQL\", \"type\": \"CD-MICROSOFT-AZURE-DB-POSTGRESQL\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"properties\": { \"Name\": \"Accounting PostgreSQL\", \"Out Of Scope\": \"false\", \"Azure Postgres DB Firewall Settings\": \"Select\", \"Azure Postgres DB TLS Enforced\": \"Select\" }, \"representations\": [ { \"name\": \"Accounting PostgreSQL Representation\", \"id\": \"53245f54-0656-4ede-a393-357aeaa2e20f-representation\", \"representation\": \"mtmt_project_id-diagram\", \"size\": { \"width\": 100, \"height\": 100 }, \"position\": { \"x\": 231, \"y\": 40 } } ], \"threats\": [ { \"threat\": \"55\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"55\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"1\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"1\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"2\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"2\", \"state\": \"RECOMMENDED\" } ] } ] }, { \"id\": \"6183b7fa-eba5-4bf8-a0af-c3e30d144a10\", \"name\": \"Mobile Client\", \"type\": \"android-device-client\", \"parent\": { \"trustZone\": \"6376d53e-6461-412b-8e04-7b3fe2b397de\" }, \"properties\": { \"Name\": \"Mobile Client\", \"Out Of Scope\": \"false\", \"Mobile Client Technologies\": \"Android\" }, \"representations\": [ { \"name\": \"Mobile Client Representation\", \"id\": \"6183b7fa-eba5-4bf8-a0af-c3e30d144a10-representation\", \"representation\": \"mtmt_project_id-diagram\", \"size\": { \"width\": 100, \"height\": 100 }, \"position\": { \"x\": 47, \"y\": 89 } } ], \"threats\": [ { \"threat\": \"69\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"69\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"68\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"68\", \"state\": \"RECOMMENDED\" } ] } ] }, { \"id\": \"5d15323e-3729-4694-87b1-181c90af5045\", \"name\": \"Public API v2\", \"type\": \"web-service\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"properties\": { \"Name\": \"Public API v2\", \"Out Of Scope\": \"false\", \"Web API Technologies\": \"Select\", \"Hosting environment\": \"Select\", \"Identity Provider\": \"Select\" }, \"representations\": [ { \"name\": \"Public API v2 Representation\", \"id\": \"5d15323e-3729-4694-87b1-181c90af5045-representation\", \"representation\": \"mtmt_project_id-diagram\", \"size\": { \"width\": 100, \"height\": 100 }, \"position\": { \"x\": 21, \"y\": 101 } } ], \"threats\": [ { \"threat\": \"3\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"3\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"4\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"4\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"5\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"5\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"6\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"6\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"7\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"7\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"8\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"8\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"9\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"9\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"10\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"10\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"62\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"62\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"61\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"61\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"60\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"60\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"59\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"59\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"58\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"58\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"57\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"57\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"56\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"56\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"25\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"25\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"26\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"26\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"28\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"28\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"29\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"29\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"30\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"30\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"31\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"31\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"32\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"32\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"33\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"33\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"35\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"35\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"36\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"36\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"37\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"37\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"38\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"38\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"39\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"39\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"67\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"67\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"66\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"66\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"63\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"63\", \"state\": \"RECOMMENDED\" } ] } ] }, { \"id\": \"91882aca-8249-49a7-96f0-164b68411b48\", \"name\": \"Azure File Storage\", \"type\": \"azure-storage\", \"parent\": { \"trustZone\": \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"properties\": { \"Name\": \"Azure File Storage\", \"Out Of Scope\": \"false\", \"Storage Type\": \"Select\", \"HTTPS Enforced\": \"Select\", \"Network Security\": \"Select\", \"CORS Enabled\": \"Select\" }, \"representations\": [ { \"name\": \"Azure File Storage Representation\", \"id\": \"91882aca-8249-49a7-96f0-164b68411b48-representation\", \"representation\": \"mtmt_project_id-diagram\", \"size\": { \"width\": 100, \"height\": 100 }, \"position\": { \"x\": 230, \"y\": 169 } } ], \"threats\": [ { \"threat\": \"11\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"11\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"12\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"12\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"13\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"13\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"14\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"14\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"15\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"15\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"16\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"16\", \"state\": \"RECOMMENDED\" } ] }, { \"threat\": \"17\", \"state\": \"AutoGenerated\", \"mitigations\": [ { \"mitigation\": \"17\", \"state\": \"RECOMMENDED\" } ] } ] } ], \"dataflows\": [ { \"id\": \"eb072144-af37-4b75-b46b-b78111850d3e\", \"name\": \"PSQL Request\", \"source\": \"5d15323e-3729-4694-87b1-181c90af5045\", \"destination\": \"53245f54-0656-4ede-a393-357aeaa2e20f\", \"bidirectional\": false, \"properties\": { \"Request\": {}, \"Name\": \"PSQL Request\", \"Dataflow Order\": \"0\", \"Out Of Scope\": \"false\", \"Reason For Out Of Scope\": {}, \"Configurable Attributes\": {}, \"As Generic Data Flow\": {}, \"Show Boundary Threats\": \"Select\" } }, { \"id\": \"36091fd8-dba8-424e-a3cd-784ea6bcb9e0\", \"name\": \"PSQL Response\", \"source\": \"53245f54-0656-4ede-a393-357aeaa2e20f\", \"destination\": \"5d15323e-3729-4694-87b1-181c90af5045\", \"bidirectional\": false, \"properties\": { \"Response\": {}, \"Name\": \"PSQL Response\", \"Dataflow Order\": \"0\", \"Out Of Scope\": \"false\", \"Reason For Out Of Scope\": {}, \"Configurable Attributes\": {}, \"As Generic Data Flow\": {}, \"Show Boundary Threats\": \"Select\" } }, { \"id\": \"f5fe3c6e-e10b-4252-a4aa-4ec6108c96a6\", \"name\": \"File Request\", \"source\": \"5d15323e-3729-4694-87b1-181c90af5045\", \"destination\": \"91882aca-8249-49a7-96f0-164b68411b48\", \"bidirectional\": false, \"properties\": { \"Request\": {}, \"Name\": \"File Request\", \"Dataflow Order\": \"0\", \"Out Of Scope\": \"false\", \"Reason For Out Of Scope\": {}, \"Configurable Attributes\": {}, \"As Generic Data Flow\": {}, \"Show Boundary Threats\": \"Select\" } }, { \"id\": \"d826de3d-1464-4d1f-8105-aa0449a50aec\", \"name\": \"File Response\", \"source\": \"91882aca-8249-49a7-96f0-164b68411b48\", \"destination\": \"5d15323e-3729-4694-87b1-181c90af5045\", \"bidirectional\": false, \"properties\": { \"Response\": {}, \"Name\": \"File Response\", \"Dataflow Order\": \"0\", \"Out Of Scope\": \"false\", \"Reason For Out Of Scope\": {}, \"Configurable Attributes\": {}, \"As Generic Data Flow\": {}, \"Show Boundary Threats\": \"Select\" } }, { \"id\": \"9840bcdf-c444-437d-8289-d5468f41b0db\", \"name\": \"API Request\", \"source\": \"6183b7fa-eba5-4bf8-a0af-c3e30d144a10\", \"destination\": \"5d15323e-3729-4694-87b1-181c90af5045\", \"bidirectional\": false, \"properties\": { \"Request\": {}, \"Name\": \"API Request\", \"Dataflow Order\": \"0\", \"Out Of Scope\": \"false\", \"Reason For Out Of Scope\": {}, \"Configurable Attributes\": {}, \"As Generic Data Flow\": {}, \"Show Boundary Threats\": \"Select\" } }, { \"id\": \"5861370d-b333-4d4b-9420-95425026e9c9\", \"name\": \"API Response\", \"source\": \"5d15323e-3729-4694-87b1-181c90af5045\", \"destination\": \"6183b7fa-eba5-4bf8-a0af-c3e30d144a10\", \"bidirectional\": false, \"properties\": { \"Response\": {}, \"Name\": \"API Response\", \"Dataflow Order\": \"0\", \"Out Of Scope\": \"false\", \"Reason For Out Of Scope\": {}, \"Configurable Attributes\": {}, \"As Generic Data Flow\": {}, \"Show Boundary Threats\": \"Select\" } } ], \"threats\": [ { \"name\": \"An adversary can gain unauthorized access to Azure Postgres DB instances due to weak network security configuration\", \"id\": \"55\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain unauthorized access to Accounting PostgreSQL instances due to weak network security configuration\" }, { \"name\": \"An adversary may read and/or tamper with the data transmitted to Azure Postgres DB due to weak configuration\", \"id\": \"1\", \"categories\": [ \"Tampering\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may read and/or tamper with the data transmitted to Accounting PostgreSQL due to weak configuration\" }, { \"name\": \"An adversary can gain long term, persistent access to an Azure Postgres DB instance through the compromise of local user account password(s)\", \"id\": \"2\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain long term, persistent access to Accounting PostgreSQL instance through the compromise of local user account password(s)\" }, { \"name\": \"An adversary may gain unauthorized access to Web API due to poor access control checks\", \"id\": \"3\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may gain unauthorized access to Web API due to poor access control checks\" }, { \"name\": \"An adversary can gain access to sensitive information from an API through error messages\", \"id\": \"4\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to sensitive data such as the following, through verbose error messages - Server names - Connection strings - Usernames - Passwords - SQL procedures - Details of dynamic SQL failures - Stack trace and lines of code - Variables stored in memory - Drive and folder locations - Application install points - Host configuration settings - Other internal application details\" }, { \"name\": \"An adversary can gain access to sensitive data by sniffing traffic to Web API\", \"id\": \"5\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to sensitive data by sniffing traffic to Web API\" }, { \"name\": \"An adversary can gain access to sensitive data stored in Web API's config files\", \"id\": \"6\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to the config files. and if sensitive data is stored in it, it would be compromised\" }, { \"name\": \"Attacker can deny a malicious act on an API leading to repudiation issues\", \"id\": \"7\", \"categories\": [ \"Repudiation\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"Attacker can deny a malicious act on an API leading to repudiation issues\" }, { \"name\": \"An adversary may spoof Accounting PostgreSQL and gain access to Web API\", \"id\": \"8\", \"categories\": [ \"Spoofing\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"If proper authentication is not in place, an adversary can spoof a source process or external entity and gain unauthorized access to the Web Application\" }, { \"name\": \"An adversary may inject malicious inputs into an API and affect downstream processes\", \"id\": \"9\", \"categories\": [ \"Tampering\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may inject malicious inputs into an API and affect downstream processes\" }, { \"name\": \"An adversary can gain access to sensitive data by performing SQL injection through Web API\", \"id\": \"10\", \"categories\": [ \"Tampering\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"SQL injection is an attack in which malicious code is inserted into strings that are later passed to an instance of SQL Server for parsing and execution. The primary form of SQL injection consists of direct insertion of code into user-input variables that are concatenated with SQL commands and executed. A less direct attack injects malicious code into strings that are destined for storage in a table or as metadata. When the stored strings are subsequently concatenated into a dynamic SQL command, the malicious code is executed\" }, { \"name\": \"An adversary can gain unauthorized access to Azure File Storage due to weak access control restrictions\", \"id\": \"11\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain unauthorized access to Azure File Storage due to weak access control restrictions\" }, { \"name\": \"An adversary can gain unauthorized access to Azure File Storage instances due to weak network configuration\", \"id\": \"12\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain unauthorized access to Azure File Storage instances due to weak network configuration\" }, { \"name\": \"An adversary may gain unauthorized access to Azure File Storage account in a subscription\", \"id\": \"13\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may gain unauthorized access to Azure File Storage account in a subscription\" }, { \"name\": \"An adversary can abuse poorly managed Azure File Storage account access keys\", \"id\": \"14\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can abuse poorly managed Azure File Storage account access keys and gain unauthorized access to storage\" }, { \"name\": \"An adversary can abuse an insecure communication channel between a client and Azure File Storage\", \"id\": \"15\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can abuse an insecure communication channel between a client and Azure File Storage\" }, { \"name\": \"An adversary can deny actions on Azure File Storage due to lack of auditing\", \"id\": \"16\", \"categories\": [ \"Repudiation\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"Proper logging of all security events and user actions builds traceability in a system and denies any possible repudiation issues. In the absence of proper auditing and logging controls, it would become impossible to implement any accountability in a system\" }, { \"name\": \"An adversary can gain unauthorized access to Azure File Storage due to weak CORS configuration\", \"id\": \"17\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain unauthorized access to Azure File Storage due to weak CORS configuration\" }, { \"name\": \"An adversary may inject malicious inputs into an API and affect downstream processes\", \"id\": \"62\", \"categories\": [ \"Tampering\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may inject malicious inputs into an API and affect downstream processes\" }, { \"name\": \"An adversary may spoof Azure File Storage and gain access to Web API\", \"id\": \"61\", \"categories\": [ \"Spoofing\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"If proper authentication is not in place, an adversary can spoof a source process or external entity and gain unauthorized access to the Web Application\" }, { \"name\": \"Attacker can deny a malicious act on an API leading to repudiation issues\", \"id\": \"60\", \"categories\": [ \"Repudiation\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"Attacker can deny a malicious act on an API leading to repudiation issues\" }, { \"name\": \"An adversary can gain access to sensitive data stored in Web API's config files\", \"id\": \"59\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to the config files. and if sensitive data is stored in it, it would be compromised\" }, { \"name\": \"An adversary can gain access to sensitive data by sniffing traffic to Web API\", \"id\": \"58\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to sensitive data by sniffing traffic to Web API\" }, { \"name\": \"An adversary can gain access to sensitive information from an API through error messages\", \"id\": \"57\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to sensitive data such as the following, through verbose error messages - Server names - Connection strings - Usernames - Passwords - SQL procedures - Details of dynamic SQL failures - Stack trace and lines of code - Variables stored in memory - Drive and folder locations - Application install points - Host configuration settings - Other internal application details\" }, { \"name\": \"An adversary may gain unauthorized access to Web API due to poor access control checks\", \"id\": \"56\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may gain unauthorized access to Web API due to poor access control checks\" }, { \"name\": \"An adversary may jail break into a mobile device and gain elevated privileges\", \"id\": \"25\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may jail break into a mobile device and gain elevated privileges\" }, { \"name\": \"An adversary may gain unauthorized access to Web API due to poor access control checks\", \"id\": \"26\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may gain unauthorized access to Web API due to poor access control checks\" }, { \"name\": \"An adversary may spoof an Azure administrator and gain access to Azure subscription portal\", \"id\": \"69\", \"categories\": [ \"Spoofing\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may spoof an Azure administrator and gain access to Azure subscription portal if the administrator's credentials are compromised\" }, { \"name\": \"An adversary can gain access to sensitive information from an API through error messages\", \"id\": \"28\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to sensitive data such as the following, through verbose error messages - Server names - Connection strings - Usernames - Passwords - SQL procedures - Details of dynamic SQL failures - Stack trace and lines of code - Variables stored in memory - Drive and folder locations - Application install points - Host configuration settings - Other internal application details\" }, { \"name\": \"An adversary can gain access to sensitive data by sniffing traffic from Mobile client\", \"id\": \"29\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to sensitive data by sniffing traffic from Mobile client\" }, { \"name\": \"An adversary can gain access to sensitive data by sniffing traffic to Web API\", \"id\": \"30\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to sensitive data by sniffing traffic to Web API\" }, { \"name\": \"An adversary can gain sensitive data from mobile device\", \"id\": \"31\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"If application saves sensitive PII or HBI data on phone SD card or local storage, then it ay get stolen\" }, { \"name\": \"An adversary can gain access to sensitive data stored in Web API's config files\", \"id\": \"32\", \"categories\": [ \"Information Disclosure\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain access to the config files. and if sensitive data is stored in it, it would be compromised\" }, { \"name\": \"Attacker can deny a malicious act on an API leading to repudiation issues\", \"id\": \"33\", \"categories\": [ \"Repudiation\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"Attacker can deny a malicious act on an API leading to repudiation issues\" }, { \"name\": \"An adversary can gain unauthorized access to resources in an Azure subscription\", \"id\": \"68\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain unauthorized access to resources in Azure subscription. The adversary can be either a disgruntled internal user, or someone who has stolen the credentials of an Azure subscription\" }, { \"name\": \"An adversary obtains refresh or access tokens from Mobile Client and uses them to obtain access to the Public API v2 API\", \"id\": \"35\", \"categories\": [ \"Spoofing\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"On a public client (e.g. a mobile device), refresh tokens may be stolen and used by an attacker to obtain access to the API. Depending on the client type, there are different ways that tokens may be revealed to an attacker and therefore different ways to protect them, some involving how the software using the tokens requests, stores and refreshes them\" }, { \"name\": \"An adversary may spoof Mobile Client and gain access to Web API\", \"id\": \"36\", \"categories\": [ \"Spoofing\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"If proper authentication is not in place, an adversary can spoof a source process or external entity and gain unauthorized access to the Web Application\" }, { \"name\": \"An adversary may inject malicious inputs into an API and affect downstream processes\", \"id\": \"37\", \"categories\": [ \"Tampering\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may inject malicious inputs into an API and affect downstream processes\" }, { \"name\": \"An adversary can reverse engineer and tamper binaries\", \"id\": \"38\", \"categories\": [ \"Tampering\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can use various tools, reverse engineer binaries and abuse them by tampering\" }, { \"name\": \"An adversary can gain access to sensitive data by performing SQL injection through Web API\", \"id\": \"39\", \"categories\": [ \"Tampering\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"SQL injection is an attack in which malicious code is inserted into strings that are later passed to an instance of SQL Server for parsing and execution. The primary form of SQL injection consists of direct insertion of code into user-input variables that are concatenated with SQL commands and executed. A less direct attack injects malicious code into strings that are destined for storage in a table or as metadata. When the stored strings are subsequently concatenated into a dynamic SQL command, the malicious code is executed\" }, { \"name\": \"An adversary may spoof an Azure administrator and gain access to Azure subscription portal\", \"id\": \"67\", \"categories\": [ \"Spoofing\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary may spoof an Azure administrator and gain access to Azure subscription portal if the administrator's credentials are compromised\" }, { \"name\": \"An adversary can gain unauthorized access to resources in an Azure subscription\", \"id\": \"66\", \"categories\": [ \"Elevation of Privileges\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"An adversary can gain unauthorized access to resources in Azure subscription. The adversary can be either a disgruntled internal user, or someone who has stolen the credentials of an Azure subscription\" }, { \"name\": \"An adversary can gain access to sensitive data by performing SQL injection through Web API\", \"id\": \"63\", \"categories\": [ \"Tampering\" ], \"risk\": { \"likelihood\": 100, \"impact\": 100 }, \"description\": \"SQL injection is an attack in which malicious code is inserted into strings that are later passed to an instance of SQL Server for parsing and execution. The primary form of SQL injection consists of direct insertion of code into user-input variables that are concatenated with SQL commands and executed. A less direct attack injects malicious code into strings that are destined for storage in a table or as metadata. When the stored strings are subsequently concatenated into a dynamic SQL command, the malicious code is executed\" } ], \"mitigations\": [ { \"name\": \"Restrict access to Azure Postgres DB instances by configuring server-level firewall rules to only permit connections from selected IP addresses where possible\", \"id\": \"55\", \"riskReduction\": 100, \"description\": \"Restrict access to Azure Postgres DB instances by configuring server-level firewall rules to only permit connections from selected IP addresses where possible. Refer: <a href=\\\"https://aka.ms/tmt-th153\\\">https://aka.ms/tmt-th153</a>\" }, { \"name\": \"Enforce communication between clients and Azure Postgres DB to be over SSL/TLS by enabling the Enforce SSL connection feature on the server\", \"id\": \"1\", \"riskReduction\": 100, \"description\": \"Enforce communication between clients and Azure Postgres DB to be over SSL/TLS by enabling the Enforce SSL connection feature on the server. Check that the connection strings used to connect to MySQL databases have the right configuration (e.g. ssl = true or sslmode=require or sslmode=true are set). Refer: <a href=\\\"https://aka.ms/tmt-th154a\\\">https://aka.ms/tmt-th154a</a> Configure MySQL server to use a verifiable SSL certificate (needed for SSL/TLS communication). Refer: <a href=\\\"https://aka.ms/tmt-th154b\\\">https://aka.ms/tmt-th154b</a>\" }, { \"name\": \"It is recommended to rotate user account passwords (e\", \"id\": \"2\", \"riskReduction\": 100, \"description\": \"It is recommended to rotate user account passwords (e.g. those used in connection strings) regularly, in accordance with your organization's policies. Store secrets in a secret storage solution (e.g. Azure Key Vault)\" }, { \"name\": \"Implement proper authorization mechanism in ASP\", \"id\": \"3\", \"riskReduction\": 100, \"description\": \"Implement proper authorization mechanism in ASP.NET Web API. Refer: <a href=\\\"https://aka.ms/tmtauthz#authz-aspnet\\\">https://aka.ms/tmtauthz#authz-aspnet</a>\" }, { \"name\": \"Ensure that proper exception handling is done in ASP\", \"id\": \"4\", \"riskReduction\": 100, \"description\": \"Ensure that proper exception handling is done in ASP.NET Web API. Refer: <a href=\\\"https://aka.ms/tmtxmgmt#exception\\\">https://aka.ms/tmtxmgmt#exception</a>\" }, { \"name\": \"Force all traffic to Web APIs over HTTPS connection\", \"id\": \"5\", \"riskReduction\": 100, \"description\": \"Force all traffic to Web APIs over HTTPS connection. Refer: <a href=\\\"https://aka.ms/tmtcommsec#webapi-https\\\">https://aka.ms/tmtcommsec#webapi-https</a>\" }, { \"name\": \"Encrypt sections of Web API's configuration files that contain sensitive data\", \"id\": \"6\", \"riskReduction\": 100, \"description\": \"Encrypt sections of Web API's configuration files that contain sensitive data. Refer: <a href=\\\"https://aka.ms/tmtconfigmgmt#config-sensitive\\\">https://aka.ms/tmtconfigmgmt#config-sensitive</a>\" }, { \"name\": \"Ensure that auditing and logging is enforced on Web API\", \"id\": \"7\", \"riskReduction\": 100, \"description\": \"Ensure that auditing and logging is enforced on Web API. Refer: <a href=\\\"https://aka.ms/tmtauditlog#logging-web-api\\\">https://aka.ms/tmtauditlog#logging-web-api</a>\" }, { \"name\": \"Ensure that standard authentication techniques are used to secure Web APIs\", \"id\": \"8\", \"riskReduction\": 100, \"description\": \"Ensure that standard authentication techniques are used to secure Web APIs. Refer: <a href=\\\"https://aka.ms/tmtauthn#authn-secure-api\\\">https://aka.ms/tmtauthn#authn-secure-api</a>\" }, { \"name\": \"Ensure that model validation is done on Web API methods\", \"id\": \"9\", \"riskReduction\": 100, \"description\": \"Ensure that model validation is done on Web API methods. Refer: <a href=\\\"https://aka.ms/tmtinputval#validation-api\\\">https://aka.ms/tmtinputval#validation-api</a> Implement input validation on all string type parameters accepted by Web API methods. Refer: <a href=\\\"https://aka.ms/tmtinputval#string-api\\\">https://aka.ms/tmtinputval#string-api</a>\" }, { \"name\": \"Ensure that type-safe parameters are used in Web API for data access\", \"id\": \"10\", \"riskReduction\": 100, \"description\": \"Ensure that type-safe parameters are used in Web API for data access. Refer: <a href=\\\"https://aka.ms/tmtinputval#typesafe-api\\\">https://aka.ms/tmtinputval#typesafe-api</a>\" }, { \"name\": \"Grant limited access to objects in Azure Storage using SAS or SAP\", \"id\": \"11\", \"riskReduction\": 100, \"description\": \"Grant limited access to objects in Azure Storage using SAS or SAP. It is recommended to scope SAS and SAP to permit only the necessary permissions over a short period of time. Refer: <a href=\\\"https://aka.ms/tmt-th17a\\\">https://aka.ms/tmt-th17a</a> and <a href=\\\"https://aka.ms/tmt-th17b\\\">https://aka.ms/tmt-th17b</a>\" }, { \"name\": \"It is recommended to restrict access to Azure Storage instances to selected networks where possible\", \"id\": \"12\", \"riskReduction\": 100, \"description\": \"It is recommended to restrict access to Azure Storage instances to selected networks where possible. <a href=\\\"https://aka.ms/tmt-th140\\\">https://aka.ms/tmt-th140</a>\" }, { \"name\": \"Assign the appropriate Role-Based Access Control (RBAC) role to users, groups and applications at the right scope for the Azure Storage instance\", \"id\": \"13\", \"riskReduction\": 100, \"description\": \"Assign the appropriate Role-Based Access Control (RBAC) role to users, groups and applications at the right scope for the Azure Storage instance. Refer: <a href=\\\"https://aka.ms/tmt-th67\\\">https://aka.ms/tmt-th67</a>\" }, { \"name\": \"Ensure secure management and storage of Azure storage access keys\", \"id\": \"14\", \"riskReduction\": 100, \"description\": \"Ensure secure management and storage of Azure storage access keys. It is recommended to rotate storage access keys regularly, in accordance with organizational policies. Refer: <a href=\\\"https://aka.ms/tmt-th63\\\">https://aka.ms/tmt-th63</a>\" }, { \"name\": \"Ensure that communication to Azure Storage is over HTTPS\", \"id\": \"15\", \"riskReduction\": 100, \"description\": \"Ensure that communication to Azure Storage is over HTTPS. It is recommended to enable the secure transfer required option to force communication with Azure Storage to be over HTTPS. Use Client-Side Encryption to store sensitive data in Azure Storage. Refer: <a href=\\\"https://aka.ms/tmt-th65\\\">https://aka.ms/tmt-th65</a>\" }, { \"name\": \"Use Azure Storage Analytics to audit access of Azure Storage\", \"id\": \"16\", \"riskReduction\": 100, \"description\": \"Use Azure Storage Analytics to audit access of Azure Storage. If possible, audit the calls to the Azure Storage instance at the source of the call. Refer: <a href=\\\"https://aka.ms/tmt-th20\\\">https://aka.ms/tmt-th20</a>\" }, { \"name\": \"Ensure that only specific, trusted origins are allowed\", \"id\": \"17\", \"riskReduction\": 100, \"description\": \"Ensure that only specific, trusted origins are allowed. Refer: <a href=\\\"https://aka.ms/tmt-th21\\\">https://aka.ms/tmt-th21</a>\" }, { \"name\": \"Ensure that model validation is done on Web API methods\", \"id\": \"62\", \"riskReduction\": 100, \"description\": \"Ensure that model validation is done on Web API methods. Refer: <a href=\\\"https://aka.ms/tmtinputval#validation-api\\\">https://aka.ms/tmtinputval#validation-api</a> Implement input validation on all string type parameters accepted by Web API methods. Refer: <a href=\\\"https://aka.ms/tmtinputval#string-api\\\">https://aka.ms/tmtinputval#string-api</a>\" }, { \"name\": \"Ensure that standard authentication techniques are used to secure Web APIs\", \"id\": \"61\", \"riskReduction\": 100, \"description\": \"Ensure that standard authentication techniques are used to secure Web APIs. Refer: <a href=\\\"https://aka.ms/tmtauthn#authn-secure-api\\\">https://aka.ms/tmtauthn#authn-secure-api</a>\" }, { \"name\": \"Ensure that auditing and logging is enforced on Web API\", \"id\": \"60\", \"riskReduction\": 100, \"description\": \"Ensure that auditing and logging is enforced on Web API. Refer: <a href=\\\"https://aka.ms/tmtauditlog#logging-web-api\\\">https://aka.ms/tmtauditlog#logging-web-api</a>\" }, { \"name\": \"Encrypt sections of Web API's configuration files that contain sensitive data\", \"id\": \"59\", \"riskReduction\": 100, \"description\": \"Encrypt sections of Web API's configuration files that contain sensitive data. Refer: <a href=\\\"https://aka.ms/tmtconfigmgmt#config-sensitive\\\">https://aka.ms/tmtconfigmgmt#config-sensitive</a>\" }, { \"name\": \"Force all traffic to Web APIs over HTTPS connection\", \"id\": \"58\", \"riskReduction\": 100, \"description\": \"Force all traffic to Web APIs over HTTPS connection. Refer: <a href=\\\"https://aka.ms/tmtcommsec#webapi-https\\\">https://aka.ms/tmtcommsec#webapi-https</a>\" }, { \"name\": \"Ensure that proper exception handling is done in ASP\", \"id\": \"57\", \"riskReduction\": 100, \"description\": \"Ensure that proper exception handling is done in ASP.NET Web API. Refer: <a href=\\\"https://aka.ms/tmtxmgmt#exception\\\">https://aka.ms/tmtxmgmt#exception</a>\" }, { \"name\": \"Implement proper authorization mechanism in ASP\", \"id\": \"56\", \"riskReduction\": 100, \"description\": \"Implement proper authorization mechanism in ASP.NET Web API. Refer: <a href=\\\"https://aka.ms/tmtauthz#authz-aspnet\\\">https://aka.ms/tmtauthz#authz-aspnet</a>\" }, { \"name\": \"Implement implicit jailbreak or rooting detection\", \"id\": \"25\", \"riskReduction\": 100, \"description\": \"Implement implicit jailbreak or rooting detection. Refer: <a href=\\\"https://aka.ms/tmtauthz#rooting-detection\\\">https://aka.ms/tmtauthz#rooting-detection</a>\" }, { \"name\": \"Implement proper authorization mechanism in ASP\", \"id\": \"26\", \"riskReduction\": 100, \"description\": \"Implement proper authorization mechanism in ASP.NET Web API. Refer: <a href=\\\"https://aka.ms/tmtauthz#authz-aspnet\\\">https://aka.ms/tmtauthz#authz-aspnet</a>\" }, { \"name\": \"Enable fine-grained access management to Azure Subscription using RBAC\", \"id\": \"69\", \"riskReduction\": 100, \"description\": \"Enable fine-grained access management to Azure Subscription using RBAC. Refer: <a href=\\\"https://aka.ms/tmtauthz#grained-rbac\\\">https://aka.ms/tmtauthz#grained-rbac</a> Enable Azure Multi-Factor Authentication for Azure Administrators. Refer: <a href=\\\"https://aka.ms/tmtauthn#multi-factor-azure-admin\\\">https://aka.ms/tmtauthn#multi-factor-azure-admin</a>\" }, { \"name\": \"Ensure that proper exception handling is done in ASP\", \"id\": \"28\", \"riskReduction\": 100, \"description\": \"Ensure that proper exception handling is done in ASP.NET Web API. Refer: <a href=\\\"https://aka.ms/tmtxmgmt#exception\\\">https://aka.ms/tmtxmgmt#exception</a>\" }, { \"name\": \"Implement Certificate Pinning\", \"id\": \"29\", \"riskReduction\": 100, \"description\": \"Implement Certificate Pinning. Refer: <a href=\\\"https://aka.ms/tmtcommsec#cert-pinning\\\">https://aka.ms/tmtcommsec#cert-pinning</a>\" }, { \"name\": \"Force all traffic to Web APIs over HTTPS connection\", \"id\": \"30\", \"riskReduction\": 100, \"description\": \"Force all traffic to Web APIs over HTTPS connection. Refer: <a href=\\\"https://aka.ms/tmtcommsec#webapi-https\\\">https://aka.ms/tmtcommsec#webapi-https</a>\" }, { \"name\": \"Encrypt sensitive or PII data written to phones local storage\", \"id\": \"31\", \"riskReduction\": 100, \"description\": \"Encrypt sensitive or PII data written to phones local storage. Refer: <a href=\\\"https://aka.ms/tmtdata#pii-phones\\\">https://aka.ms/tmtdata#pii-phones</a>\" }, { \"name\": \"Encrypt sections of Web API's configuration files that contain sensitive data\", \"id\": \"32\", \"riskReduction\": 100, \"description\": \"Encrypt sections of Web API's configuration files that contain sensitive data. Refer: <a href=\\\"https://aka.ms/tmtconfigmgmt#config-sensitive\\\">https://aka.ms/tmtconfigmgmt#config-sensitive</a>\" }, { \"name\": \"Ensure that auditing and logging is enforced on Web API\", \"id\": \"33\", \"riskReduction\": 100, \"description\": \"Ensure that auditing and logging is enforced on Web API. Refer: <a href=\\\"https://aka.ms/tmtauditlog#logging-web-api\\\">https://aka.ms/tmtauditlog#logging-web-api</a>\" }, { \"name\": \"Enable fine-grained access management to Azure Subscription using RBAC\", \"id\": \"68\", \"riskReduction\": 100, \"description\": \"Enable fine-grained access management to Azure Subscription using RBAC. Refer: <a href=\\\"https://aka.ms/tmtauthz#grained-rbac\\\">https://aka.ms/tmtauthz#grained-rbac</a>\" }, { \"name\": \"Use ADAL libraries to manage token requests from OAuth2 clients to AAD (or on-premises AD)\", \"id\": \"35\", \"riskReduction\": 100, \"description\": \"Use ADAL libraries to manage token requests from OAuth2 clients to AAD (or on-premises AD). Refer: <a href=\\\"https://aka.ms/tmtauthn#adal-oauth2\\\">https://aka.ms/tmtauthn#adal-oauth2</a>\" }, { \"name\": \"Ensure that standard authentication techniques are used to secure Web APIs\", \"id\": \"36\", \"riskReduction\": 100, \"description\": \"Ensure that standard authentication techniques are used to secure Web APIs. Refer: <a href=\\\"https://aka.ms/tmtauthn#authn-secure-api\\\">https://aka.ms/tmtauthn#authn-secure-api</a>\" }, { \"name\": \"Ensure that model validation is done on Web API methods\", \"id\": \"37\", \"riskReduction\": 100, \"description\": \"Ensure that model validation is done on Web API methods. Refer: <a href=\\\"https://aka.ms/tmtinputval#validation-api\\\">https://aka.ms/tmtinputval#validation-api</a> Implement input validation on all string type parameters accepted by Web API methods. Refer: <a href=\\\"https://aka.ms/tmtinputval#string-api\\\">https://aka.ms/tmtinputval#string-api</a>\" }, { \"name\": \"Obfuscate generated binaries before distributing to end users\", \"id\": \"38\", \"riskReduction\": 100, \"description\": \"Obfuscate generated binaries before distributing to end users. Refer: <a href=\\\"https://aka.ms/tmtdata#binaries-end\\\">https://aka.ms/tmtdata#binaries-end</a>\" }, { \"name\": \"Ensure that type-safe parameters are used in Web API for data access\", \"id\": \"39\", \"riskReduction\": 100, \"description\": \"Ensure that type-safe parameters are used in Web API for data access. Refer: <a href=\\\"https://aka.ms/tmtinputval#typesafe-api\\\">https://aka.ms/tmtinputval#typesafe-api</a>\" }, { \"name\": \"Enable fine-grained access management to Azure Subscription using RBAC\", \"id\": \"67\", \"riskReduction\": 100, \"description\": \"Enable fine-grained access management to Azure Subscription using RBAC. Refer: <a href=\\\"https://aka.ms/tmtauthz#grained-rbac\\\">https://aka.ms/tmtauthz#grained-rbac</a> Enable Azure Multi-Factor Authentication for Azure Administrators. Refer: <a href=\\\"https://aka.ms/tmtauthn#multi-factor-azure-admin\\\">https://aka.ms/tmtauthn#multi-factor-azure-admin</a>\" }, { \"name\": \"Enable fine-grained access management to Azure Subscription using RBAC\", \"id\": \"66\", \"riskReduction\": 100, \"description\": \"Enable fine-grained access management to Azure Subscription using RBAC. Refer: <a href=\\\"https://aka.ms/tmtauthz#grained-rbac\\\">https://aka.ms/tmtauthz#grained-rbac</a>\" }, { \"name\": \"Ensure that type-safe parameters are used in Web API for data access\", \"id\": \"63\", \"riskReduction\": 100, \"description\": \"Ensure that type-safe parameters are used in Web API for data access. Refer: <a href=\\\"https://aka.ms/tmtinputval#typesafe-api\\\">https://aka.ms/tmtinputval#typesafe-api</a>\" } ] }","title":"Open Threat Model examples"},{"location":"Open-Threat-Model-%28OTM%29/#open-threat-model-parsing","text":"","title":"Open Threat Model parsing"},{"location":"Open-Threat-Model-%28OTM%29/#how-to-create-a-new-startleft-processor","text":"It is possible to use StartLeft for parsing different formats to OTM, or even creating a new StartLeft Processor for formats that are not currently supported. There is an in depth tutorial explaining what is a StartLeft Processor and how to create one from scratch in the following link: Create a new StartLeft Processor Creating a StartLeft Processor allows you to focus on the parsing logic, while StartLeft takes care of building and validating the OTM and exposing an API or CLI for ease of operation. How to create an OTM Parser without using StartLeft Although creating a new StartLeft Processor is the preferred method of supporting new formats, it is also possible to develop your own OTM parser. An example of how to create it is detailed in the following link: https://www.iriusrisk.com/resources-blog/how-to-create-an-open-threat-model-parser","title":"How to create a new StartLeft Processor"},{"location":"Quickstart-Guide-for-Beginners/","text":"Quickstart Guide for Beginners The aim of this page is enabling you to get the StartLeft application installed in your machine so that you can execute some commands, set up the REST API and, in summary, familiarize yourself with the usage of the tool. Prerequisites Install the latest version of Python . Install pip3 . Install git . Install graphviz and graphviz-dev . During this guide some files will be downloaded or generated, so you can optionally create a folder to keep them organized. Linux-based OS are recommended to run StartLeft Extra requisites for Windows/OSX users StartLeft uses python-magic interface to the libmagic file type identification library for validating file types. Prerequisites for Windows \"You'll need DLLs for libmagic usage on Windows. @julian-r maintains a pypi package with the DLLs, you can fetch it with:\" pip install python-magic-bin Prerequisites for OSX When using Homebrew: brew install libmagic When using macports: port install file Install StartLeft Install the last stable version of the tool using pip: pip install git+https://github.com/iriusrisk/startleft.git Check your installation with the command: startleft --version That should return something like: startleft, version <your-installed-version> The parse command The parse is the main command of the StartLeft CLI that enables you to perform the whole process of conversion to OTM by providing one or multiple source files and a mapping file. It presents slight variations depending on the type of input source that you can check in the CLI section or in each specific processor documentation, but, to get an idea of its behavior, you can perform a conversion from an IaC file: First of all, let's download one of the examples contained in the StartLeft's examples/terraform folder: wget https://raw.githubusercontent.com/iriusrisk/startleft/main/examples/terraform/multinetwork_security_groups_with_lb.tf This is a rich example where you can see in action some capabilities of StartLeft. It represents the Threat Model for an architecture with two TrustZones and several VPCs which contain many types of AWS components. Now, we need to download the mapping file where the configuration for parsing this source is located. In this case, we will download an example that maps to IriusRisk components. It is placed in the same examples/terraform folder: wget https://raw.githubusercontent.com/iriusrisk/startleft/main/examples/terraform/iriusrisk-tf-aws-mapping.yaml With this two files we are ready to execute the parse command in order to generate the Threat Model in OTM format: startleft parse \\ --iac-type TERRAFORM \\ --mapping-file iriusrisk-tf-aws-mapping.yaml \\ --output-file multinetwork_security_groups_with_lb.otm \\ --project-name \"Terraform MN Security Groups with LB\" \\ --project-id \"tf-mn-sg-lb\" \\ multinetwork_security_groups_with_lb.tf Finally, you can open the generated multinetwork_security_groups_with_lb.otm with your favourite text editor and check how a Threat Model has been automatically generated from the Terraform file. The server command Using StartLeft as a service is the most useful strategy for integrate it with other tools. The different ways of configuring this service are deeply described in the Quickstart guide for Integrations and REST API sections. However, you can begin to familiarize yourself with this mode by setting up the server through the CLI using the command: startleft server Then open a web browser, in http://localhost:5000/docs you will find a Swagger page with the documentation of the API. It is completely functional, so you can just send requests from there to get used to the tool. Auxiliary commands In addition to parse , the CLI provides you with a group of utility commands that simplify a lot of the work with the files involved in the OTM conversions performed by StartLeft. help Undoubtedly the most insightful command, it gives you information about everything you have available through the CLI. It can be used in general: startleft --help Or for specific commands: startleft parse --help validate This command is able to perform validations over several types of files: IaC mapping files Described in depth in each processor's docs, they are used to create relationships between types in the source and their expected equivalent in the OTM (i.e: an aws_instance type in Terraform matches the ec2 type in IriusRisk). If we take the same mapping file we have downloaded for the parse command, we can execute: Terraform example startleft validate --mapping-file iriusrisk-tf-aws-mapping.yaml --mapping-type TERRAFORM Cloudformation example startleft validate --mapping-file iriusrisk-cft-mapping.yaml --mapping-type CLOUDFORMATION Diagram mapping files Also described in the processors' documentation, allows you to validate the format of mapping files used for diagram conversions as Visio and Lucidchart. Let's download the IriusRisk's Visio mapping file located in the examples/visio folder: wget https://raw.githubusercontent.com/iriusrisk/startleft/main/examples/visio/iriusrisk-visio-aws-mapping.yaml Now we can validate it using the following StartLeft command: Visio example startleft validate --mapping-file iriusrisk-visio-aws-mapping.yaml --mapping-type VISIO You can also validate Lucidchart mapping files like it is shown in this example: Lucidchart example startleft validate --mapping-file iriusrisk-lucid-aws-mapping.yaml --mapping-type LUCID External Threat Model mapping files The last type of mapping file we can validate is External Threat Model. This allows you to validate the format of mapping files used for External Threat Model conversions as MTMT (Microsoft Threat Modeling Tool): MTMT example startleft validate --mapping-file mtmt_default_mapping_example.yaml --mapping-type MTMT OTM These files may have been generated by StartLeft or handcrafted by any user. To see how to validate an OTM file, we can download an example from the examples/otm folder. wget https://raw.githubusercontent.com/iriusrisk/startleft/main/examples/otm/manual_threat_model.otm And then validate it by executing: OTM example startleft validate --otm-file manual_threat_model.otm Mapping file and otm validation Notice that parameters --mapping-file and --otm-file are mutually exclusive, so we can only validate one file at once. search This is an auxiliary utility only supported currently for IaC mapping files. Due to the complexity of these files, sometimes it is useful to test some expressions directly before including them in the final mapping file. For example, let's use the same Terraform file that we have downloaded for the parse command and perform a simple query: startleft search \\ --iac-type TERRAFORM \\ --query \"resource|get(@, 'aws_synthetics_canary')\" \\ multinetwork_security_groups_with_lb.tf","title":"Quickstart Guide for Beginners"},{"location":"Quickstart-Guide-for-Beginners/#quickstart-guide-for-beginners","text":"The aim of this page is enabling you to get the StartLeft application installed in your machine so that you can execute some commands, set up the REST API and, in summary, familiarize yourself with the usage of the tool.","title":"Quickstart Guide for Beginners"},{"location":"Quickstart-Guide-for-Beginners/#prerequisites","text":"Install the latest version of Python . Install pip3 . Install git . Install graphviz and graphviz-dev . During this guide some files will be downloaded or generated, so you can optionally create a folder to keep them organized. Linux-based OS are recommended to run StartLeft Extra requisites for Windows/OSX users StartLeft uses python-magic interface to the libmagic file type identification library for validating file types. Prerequisites for Windows \"You'll need DLLs for libmagic usage on Windows. @julian-r maintains a pypi package with the DLLs, you can fetch it with:\" pip install python-magic-bin Prerequisites for OSX When using Homebrew: brew install libmagic When using macports: port install file","title":"Prerequisites"},{"location":"Quickstart-Guide-for-Beginners/#install-startleft","text":"Install the last stable version of the tool using pip: pip install git+https://github.com/iriusrisk/startleft.git Check your installation with the command: startleft --version That should return something like: startleft, version <your-installed-version>","title":"Install StartLeft"},{"location":"Quickstart-Guide-for-Beginners/#the-parse-command","text":"The parse is the main command of the StartLeft CLI that enables you to perform the whole process of conversion to OTM by providing one or multiple source files and a mapping file. It presents slight variations depending on the type of input source that you can check in the CLI section or in each specific processor documentation, but, to get an idea of its behavior, you can perform a conversion from an IaC file: First of all, let's download one of the examples contained in the StartLeft's examples/terraform folder: wget https://raw.githubusercontent.com/iriusrisk/startleft/main/examples/terraform/multinetwork_security_groups_with_lb.tf This is a rich example where you can see in action some capabilities of StartLeft. It represents the Threat Model for an architecture with two TrustZones and several VPCs which contain many types of AWS components. Now, we need to download the mapping file where the configuration for parsing this source is located. In this case, we will download an example that maps to IriusRisk components. It is placed in the same examples/terraform folder: wget https://raw.githubusercontent.com/iriusrisk/startleft/main/examples/terraform/iriusrisk-tf-aws-mapping.yaml With this two files we are ready to execute the parse command in order to generate the Threat Model in OTM format: startleft parse \\ --iac-type TERRAFORM \\ --mapping-file iriusrisk-tf-aws-mapping.yaml \\ --output-file multinetwork_security_groups_with_lb.otm \\ --project-name \"Terraform MN Security Groups with LB\" \\ --project-id \"tf-mn-sg-lb\" \\ multinetwork_security_groups_with_lb.tf Finally, you can open the generated multinetwork_security_groups_with_lb.otm with your favourite text editor and check how a Threat Model has been automatically generated from the Terraform file.","title":"The parse command"},{"location":"Quickstart-Guide-for-Beginners/#the-server-command","text":"Using StartLeft as a service is the most useful strategy for integrate it with other tools. The different ways of configuring this service are deeply described in the Quickstart guide for Integrations and REST API sections. However, you can begin to familiarize yourself with this mode by setting up the server through the CLI using the command: startleft server Then open a web browser, in http://localhost:5000/docs you will find a Swagger page with the documentation of the API. It is completely functional, so you can just send requests from there to get used to the tool.","title":"The server command"},{"location":"Quickstart-Guide-for-Beginners/#auxiliary-commands","text":"In addition to parse , the CLI provides you with a group of utility commands that simplify a lot of the work with the files involved in the OTM conversions performed by StartLeft.","title":"Auxiliary commands"},{"location":"Quickstart-Guide-for-Beginners/#help","text":"Undoubtedly the most insightful command, it gives you information about everything you have available through the CLI. It can be used in general: startleft --help Or for specific commands: startleft parse --help","title":"help"},{"location":"Quickstart-Guide-for-Beginners/#validate","text":"This command is able to perform validations over several types of files:","title":"validate"},{"location":"Quickstart-Guide-for-Beginners/#iac-mapping-files","text":"Described in depth in each processor's docs, they are used to create relationships between types in the source and their expected equivalent in the OTM (i.e: an aws_instance type in Terraform matches the ec2 type in IriusRisk). If we take the same mapping file we have downloaded for the parse command, we can execute: Terraform example startleft validate --mapping-file iriusrisk-tf-aws-mapping.yaml --mapping-type TERRAFORM Cloudformation example startleft validate --mapping-file iriusrisk-cft-mapping.yaml --mapping-type CLOUDFORMATION","title":"IaC mapping files"},{"location":"Quickstart-Guide-for-Beginners/#diagram-mapping-files","text":"Also described in the processors' documentation, allows you to validate the format of mapping files used for diagram conversions as Visio and Lucidchart. Let's download the IriusRisk's Visio mapping file located in the examples/visio folder: wget https://raw.githubusercontent.com/iriusrisk/startleft/main/examples/visio/iriusrisk-visio-aws-mapping.yaml Now we can validate it using the following StartLeft command: Visio example startleft validate --mapping-file iriusrisk-visio-aws-mapping.yaml --mapping-type VISIO You can also validate Lucidchart mapping files like it is shown in this example: Lucidchart example startleft validate --mapping-file iriusrisk-lucid-aws-mapping.yaml --mapping-type LUCID","title":"Diagram mapping files"},{"location":"Quickstart-Guide-for-Beginners/#external-threat-model-mapping-files","text":"The last type of mapping file we can validate is External Threat Model. This allows you to validate the format of mapping files used for External Threat Model conversions as MTMT (Microsoft Threat Modeling Tool): MTMT example startleft validate --mapping-file mtmt_default_mapping_example.yaml --mapping-type MTMT","title":"External Threat Model mapping files"},{"location":"Quickstart-Guide-for-Beginners/#otm","text":"These files may have been generated by StartLeft or handcrafted by any user. To see how to validate an OTM file, we can download an example from the examples/otm folder. wget https://raw.githubusercontent.com/iriusrisk/startleft/main/examples/otm/manual_threat_model.otm And then validate it by executing: OTM example startleft validate --otm-file manual_threat_model.otm Mapping file and otm validation Notice that parameters --mapping-file and --otm-file are mutually exclusive, so we can only validate one file at once.","title":"OTM"},{"location":"Quickstart-Guide-for-Beginners/#search","text":"This is an auxiliary utility only supported currently for IaC mapping files. Due to the complexity of these files, sometimes it is useful to test some expressions directly before including them in the final mapping file. For example, let's use the same Terraform file that we have downloaded for the parse command and perform a simple query: startleft search \\ --iac-type TERRAFORM \\ --query \"resource|get(@, 'aws_synthetics_canary')\" \\ multinetwork_security_groups_with_lb.tf","title":"search"},{"boost":3,"location":"Troubleshooting/","text":"This is a list of common pitfalls on using StartLeft, and how to avoid them. ImportError: failed to find libmagic. When using Windows or OSX OS, there is the requirement to manually install the corresponding python-magic library as indicated in the prerequisites section . \"glightbox\" package is not installed When trying to launch StartLeft documentation by mkdocs serve using IntelliJ, you may get an error stating that the glightbox package is not installed. This requires re-running the pip install -e \".[doc]\" command and restarting the IDE. Cannot open include file: 'graphviz/cgraph.h' When using Windows, it is sometimes required to set up some extra configurations. Install Graphviz in your OS using the following command: choco install graphviz Adding the Graphviz binaries to the PATH echo \"C:\\Program Files\\Graphviz\\bin\" >> $PATH Installing the pygraphviz lib setting the OS files location: pip install --global-option = build_ext --global-option = \"-IC:\\Program files\\Graphviz\\include\" --global-option = \"-LC:\\Program files\\Graphviz\\lib\" pygraphviz pygraphviz/graphviz_wrap.c:154:11: fatal error: Python.h: No such file or directory Looks like you haven't properly installed the header files and static libraries for python dev. You need to add a PPA offered by the \u201cdeadsnakes\u201d team to get the old archived Python versions easily. sudo apt install software-properties-common sudo add-apt-repository ppa:deadsnakes/ppa After you need to install the required library for your python dev version: sudo apt install python3.x-dev","title":"Troubleshooting"},{"boost":3,"location":"Troubleshooting/#importerror-failed-to-find-libmagic","text":"When using Windows or OSX OS, there is the requirement to manually install the corresponding python-magic library as indicated in the prerequisites section .","title":"ImportError: failed to find libmagic."},{"boost":3,"location":"Troubleshooting/#glightbox-package-is-not-installed","text":"When trying to launch StartLeft documentation by mkdocs serve using IntelliJ, you may get an error stating that the glightbox package is not installed. This requires re-running the pip install -e \".[doc]\" command and restarting the IDE.","title":"\"glightbox\" package is not installed"},{"boost":3,"location":"Troubleshooting/#cannot-open-include-file-graphvizcgraphh","text":"When using Windows, it is sometimes required to set up some extra configurations. Install Graphviz in your OS using the following command: choco install graphviz Adding the Graphviz binaries to the PATH echo \"C:\\Program Files\\Graphviz\\bin\" >> $PATH Installing the pygraphviz lib setting the OS files location: pip install --global-option = build_ext --global-option = \"-IC:\\Program files\\Graphviz\\include\" --global-option = \"-LC:\\Program files\\Graphviz\\lib\" pygraphviz","title":"Cannot open include file: 'graphviz/cgraph.h'"},{"boost":3,"location":"Troubleshooting/#pygraphvizgraphviz_wrapc15411-fatal-error-pythonh-no-such-file-or-directory","text":"Looks like you haven't properly installed the header files and static libraries for python dev. You need to add a PPA offered by the \u201cdeadsnakes\u201d team to get the old archived Python versions easily. sudo apt install software-properties-common sudo add-apt-repository ppa:deadsnakes/ppa After you need to install the required library for your python dev version: sudo apt install python3.x-dev","title":"pygraphviz/graphviz_wrap.c:154:11: fatal error: Python.h: No such file or directory"},{"location":"Versioning/","text":"Versioning All StartLeft versions and their release notes can be found here . StartLeft uses Semantic Versioning as versioning strategy. To summarize, the version is composed by three parts following this format: {major}.{minor}.{patch} (i.e.: 1.5.0 ) Where: The {major} part changes when there is a retro-compatibility breaking change. The {minor} part changes with each new release of the application. The {patch} part changes when a hotfix is delivered over the current release of the application. Versions management StartLeft versions are managed through git tags. For each release, a new tag for that version is created along with its release notes . During the installation, the latest version tag from the current branch is retrieved. Thus, if you query the version through the CLI command or the REST API endpoint, you will know what is the version of the StartLeft's code that is being executing. Versions table There are different types of branches in the StartLeft repository that correspond to different stages of the software life cycle. If we suppose that the current version is 1.5.0 , that is, the last tag in the release page is 1.5.0 , we should expect to get the following version for each branch type: branch description expected version example main Latest stable version 1.5.0 hotfix/* Urgent fixes over main version 1.5.1.dev1+ge7812ca release/1.6.0 Specific version release branch 1.6.0rc1 bugfix/* Fixes during a release process 1.6.0rc1.dev1+g6cda015 dev Features under development for the next version 1.7.0.dev19+g17d9f68 feature/* Specific developmnet ongoing 1.7.0.dev3+g52d796a Getting the installed version Once you have StartLeft installed , there are two ways of getting the version of StartLeft you are executing. Through the CLI it is as simple as executing the command: startleft --version The REST API also exposes an endpoint for retrieving the version that can be invoked with this cURL command: curl http://localhost:5000/health","title":"Versioning"},{"location":"Versioning/#versioning","text":"All StartLeft versions and their release notes can be found here . StartLeft uses Semantic Versioning as versioning strategy. To summarize, the version is composed by three parts following this format: {major}.{minor}.{patch} (i.e.: 1.5.0 ) Where: The {major} part changes when there is a retro-compatibility breaking change. The {minor} part changes with each new release of the application. The {patch} part changes when a hotfix is delivered over the current release of the application.","title":"Versioning"},{"location":"Versioning/#versions-management","text":"StartLeft versions are managed through git tags. For each release, a new tag for that version is created along with its release notes . During the installation, the latest version tag from the current branch is retrieved. Thus, if you query the version through the CLI command or the REST API endpoint, you will know what is the version of the StartLeft's code that is being executing. Versions table There are different types of branches in the StartLeft repository that correspond to different stages of the software life cycle. If we suppose that the current version is 1.5.0 , that is, the last tag in the release page is 1.5.0 , we should expect to get the following version for each branch type: branch description expected version example main Latest stable version 1.5.0 hotfix/* Urgent fixes over main version 1.5.1.dev1+ge7812ca release/1.6.0 Specific version release branch 1.6.0rc1 bugfix/* Fixes during a release process 1.6.0rc1.dev1+g6cda015 dev Features under development for the next version 1.7.0.dev19+g17d9f68 feature/* Specific developmnet ongoing 1.7.0.dev3+g52d796a","title":"Versions management"},{"location":"Versioning/#getting-the-installed-version","text":"Once you have StartLeft installed , there are two ways of getting the version of StartLeft you are executing. Through the CLI it is as simple as executing the command: startleft --version The REST API also exposes an endpoint for retrieving the version that can be invoked with this cURL command: curl http://localhost:5000/health","title":"Getting the installed version"},{"location":"development/Architecture/","text":"Architecture Context StartLeft is a modularized application that groups a set of processors that are able to convert different formats to OTM . It can be used through a CLI, and it also exposes a REST API. However, the point of access is indifferent as, under the hood, both make use of the same conversion logic, that is implemented in a special type of modules called SLPs (StartLeft Processor), described below in this page. If we take as a reference the big picture of the usage that IriusRisk makes of StartLeft, it plays the role of a service consumed by the IriusRisk core through the REST API. For instance, this is a general view of project importing in IriusRisk: Module Based Architecture The internal architecture of the StartLeft application is based on a set of modules with well-defined responsibilities and dependencies. The diagram above shows the different modules currently implemented in StartLeft. The main considerations about them are: All the dependencies are fixed and unidirectional and the project is configured to raise a \"compile time\" exception in case some module tries to do a forbidden import . StartLeft does not directly import any specific processor, but relies on the configuration located in _sl_build and on slp_base logic to choose the right implementation for each case. This means that new processors can be added without modifying any preexisting module . The OTM does not have the sl or slp prefixes because it is intended to be released as a general lib for general definitions and logic related with the standard that could be imported independently of StartLeft. Repository Structure All the modules are located just under the root folder in the StartLeft's repo and must also fit the following common structure: Since a general Python standard for modularizing projects does not exist, the chosen one is based on the one used by several Open Source projects as well as by the StartLeft project itself before the modularization. It is important to notice that, with this structure, each module is being isolated as if it was an independent project. The goal of this is to facilitate a future migration to independent repositories. Module Structure Note: _sl_build is an internal module with configuration and building purposes that does not fit the structure explained below. In the root package of each module, there are only two subpackages, and a resources folder. The first subpackage has the same name as the module itself and contains the production code. The other one is called tests and contains specific tests for that module. The resources folder contains the resources needed by each module, for example, the schemas used for validating mapping files. The root folder of each module represents its main boundary and may be understood as the main project folder if the modules where migrated to independent repositories. However, instead of being simply folders, they need to be python regular packages with their own __init.py__ file, which is an important nuance to consider. This file contains, for each module, a call to a function defined in the _sl_build packages that overrides the native python\u2019s import function with a custom one that avoids forbidden imports between modules. In case new modules are added to StartLeft, this call must be added to their main package\u2019s __init.py__ file. ###################################################################### # This folder is not actually intended to be a regular package # # HOWEVER, we need to keep this __init.py__ file in order to # # make it visible by other modules. # # In future versions, this package should be moved to a lib so # # that it will be an independent module instead of a \"false\" package # ###################################################################### # DON'T REMOVE: Module importer overwritten to prevent bidirectional dependencies from _sl_build.secure_importer import override_module_importer override_module_importer () Production Code Package The name of this package must match the main package . This is the place where the actual business logic code of the module is located. The structure inside it is completely free, and it depends only on the needs of the logic implemented in the module. Test Code Package As has been already stated along this document, each module is a completely independent piece of software. Of course, this also includes that it must also contain its own test code. Since each module has specific responsibilities, these are the only ones that need to be tested from both a unitary and integration perspective. For example, every SLP must have unitary tests for the classes implemented there, but also integration tests that verifies that the whole conversion to OTM process works for every identified casuistic. Regarding the structure of the whole test code package, there is no a hard constraint about it, but, for readability reasons, it is recommended to follow a common one for every module. The one chosen is split in the following packages: Note : Please don\u2019t be fanatic with the definition of unitary and integration. There are not always clear boundaries, but common sense is the best way to identify what needs to be mocked or not. unit . For unitary tests. integration . For integration tests. resources . It is also recommended to place here a test_resource_paths.py to have a unique point of access to the actual testing resources. util . In case some general utilities need to be developed for being used in the tests, this package is the right place for them.** Main Tests Package Note: It is necessary to evaluate the convenience to have this package, but, at least for now, it is important to keep these tests to guarantee the quality of the code. At the root level of the StartLeft repository (the same as the other modules) a general tests package is located. Unlike the test packages located inside each module, this one is generic to the entire the StartLeft project and contains integration tests that involves logic belonging to all the modules. By definition, this package can only contain integration tests. So, when a new processor or a new important behavior is added to StartLeft, we need to create their associated integration tests at the project level in this package . Modules Description startleft This is the main module whose origin is the initial StartLeft project that used to contain all the processing logic for the first conversion formats. As part of the modularization process, it was lightened so that it does no longer implements any conversion logic, and it simply exposes the CLI and REST API and makes the connection with the SLPs where the conversion itself takes place. Main responsibilities : Expose a CLI and a REST API to enable the access to the conversion to OTM logic. Imported by : Not imported. Imports : _sl_build , slp_base , sl_util , otm . It also imports slp_cft and slp_tf to support the search function, whose future is under evaluation. sl_util This is currently the only module that contains common utilities for the rest of the modules of StartLeft. The sl prefix means that it is not intended to be a very generic module like the Apache Commons in Java, but a module to place useful functions for the StartLeft scope (including some OTM related utilities, for example). However, it is not a mixed bag to place common logic related, for instance, with the SLPs . Business logic or domain classes should fit one of the other modules or, if not, maybe a new one should be created. Main responsibilities : Offer general (not processor specific) utilities related to StartLeft. Imported by : startleft , slp_base , SLPs, otm . Imports : No imports. SLPs The StartLeft processors are the key modules of StartLeft. They contain the specific logic for converting each format to OTM. Each one is focused on converting from one and only one input format (CFT, TF, Visio, etc.). One important thing to notice is that the integration tests for these modules are the most important ones in the application since they validate behavior for the main purpose and responsibility of StartLeft as a whole. slp_base This is a critical module where the whole process of conversion is defined, including all the interfaces for each step of the conversion process (from loading files to the OTM validation) as well as definition of the errors that the process may potentially arise. Main responsibilities : Defining the main conversion process using a template pattern in the class OTMProcessor . Defining a set of interfaces for each step of the process (source and mapping files loading and validating, OTM conversion process and OTM validation) that must be implemented by the specific SLPs. Defining all the possible errors that may arise through the conversion process. Defining a ProviderResolver class to dynamically retrieve the right SLP based on the source type (CFT, TF, etc.). Imported by : startleft , SLPs. Imports : sl_util , otm . Concrete Implementations Each supported provider (CFT, TF, etc.) must have its own processor in order to perform the OTM conversion. They are completely independent modules and imports among them are forbidden. The goal is that they can be work in isolation so their evolution is also completely independent. In case some duplication appears between two processors, the first option is to duplicate the code instead of prematurely creating abstractions. Only after these duplications were consolidated, and we could identify a really common casuistic, we may think about creating a common module grouping, for instance, logic related with one provider type (IaC, diagram or threat modeling). Anyway, this common logic should be placed in a new dedicated module and never in the sl_util module . Current implementations : slp_cft for Cloudformation (IaC). slp_tf for Terraform (IaC). slp_visio for MS Visio (Diagram). slp_mtmt for MS Threat Modeling Tool (Threat model). Main responsibilities : Implementing the interfaces defined in slp_base in order to actually perform the conversion process from the origin provider formats to OTM. Imported by : No statically imported by any module. They are dynamically instanced by the slp_base based on the module configuration placed in _sl_build . Imports : Each processor is an independent module that may import different modules. However, in general: Must import: otm and slp_base . May import: sl_util . Cannot import: startleft . otm Currently, we have the only public release specifically focused on the OTM standard here , that simply contains a README.md file with a natural language description of the components of the standard. It would be interesting to extend the resources associated with the standard and share them with the community (a JSON schema, some kind of validator, etc.). This module is intended to be the seed for that public resources' library. This means that it has not to be understood as a part of StartLeft itself (notice the absence of the sl prefix), but as a more generic library exclusively oriented to general OTM concerns. Main responsibilities : Defining a set of entities that represent the OTM standard as well as providing a standard building to simplify the generation of OTM instances. Imported by : startleft , slp_base , SLPs. Imports : Currently, it imports sl_util , but, for the reasons explained above, it should not import any StartLeft module. Thus, we should be careful about creating new dependencies between these two modules. _sl_build This is a special module whose existence is due to the current structure of the project. Since the multimodule management is not being done by any external tool (like Maven/Gradle in Java), it is necessary to develop some ad hoc features in order to manage the interaction between modules. Main responsibilities : Defining the main configuration for the modules in a configuration class. Name of the module. Type of module ( general or processor ). Forbidden dependencies. Provider type supported by each SLP. Managing the imports between modules to raise an error when trying to import a forbidden dependency. Note : The imports for this module are not constrained as in the other ones because this is the module that manages these constraints, so it is important to be careful with the imports that are performed here. Imported by : startleft to read configuration and for all the rest of the modules to override the import system. Imports : No imports allowed. Building All the modules inside StartLeft are, at the end of the day, Python modules, so pip does not have any problem to install a project based on them. For this reason, the installation of the StartLeft project can be simply done by executing this command inside the StartLeft repository's root folder: pip install . About the entrypoints for the application, it is important to difference between the startleft whole project and the startleft module inside it. This means that, to reference some class or module inside it, it is needed to put the name two times ( startleft.startleft ). For example, in the docker-compose command or the docker ENTRYPOINT , the FastAPI webapp entry point must be referenced in this way: Testing As stated before in this document, each module is an independent software unit with their own tests set. This means that the tests can only be executed module by module. In PyCharm, for example, a run configuration must be created for executing the tests in each module: For executing them from the terminal, pytest needs to know what is the module that is under testing: pytest slp_base It is also possible to execute tests for several modules at the same time: pytest slp_base otm startleft However, from the point of view of CI/CD, it is undesirable to include in the pipelines configuration the name of all the modules that are required to be tested because this implies that every modification in the module structure or even the addition of a new module will provoke the modification of all the pipelines. For this reason, a run_tests.py has been created in the root of the StartLeft project. It contains the logic for retrieving all the modules in the application and calling pytest with all of them generating a unique report. So, the command that the pipelines must include for executing the StartLeft\u2019s tests is: python run_tests.py From a development point of view, the most common scenario is that only the module under development is needed to be frequently tested. However, there is no problem about executing all the tests on demand by creating a run configuration that runs that run_tests.py file in PyCharm and execute all the tests.","title":"Architecture"},{"location":"development/Architecture/#architecture","text":"","title":"Architecture"},{"location":"development/Architecture/#context","text":"StartLeft is a modularized application that groups a set of processors that are able to convert different formats to OTM . It can be used through a CLI, and it also exposes a REST API. However, the point of access is indifferent as, under the hood, both make use of the same conversion logic, that is implemented in a special type of modules called SLPs (StartLeft Processor), described below in this page. If we take as a reference the big picture of the usage that IriusRisk makes of StartLeft, it plays the role of a service consumed by the IriusRisk core through the REST API. For instance, this is a general view of project importing in IriusRisk:","title":"Context"},{"location":"development/Architecture/#module-based-architecture","text":"The internal architecture of the StartLeft application is based on a set of modules with well-defined responsibilities and dependencies. The diagram above shows the different modules currently implemented in StartLeft. The main considerations about them are: All the dependencies are fixed and unidirectional and the project is configured to raise a \"compile time\" exception in case some module tries to do a forbidden import . StartLeft does not directly import any specific processor, but relies on the configuration located in _sl_build and on slp_base logic to choose the right implementation for each case. This means that new processors can be added without modifying any preexisting module . The OTM does not have the sl or slp prefixes because it is intended to be released as a general lib for general definitions and logic related with the standard that could be imported independently of StartLeft.","title":"Module Based Architecture"},{"location":"development/Architecture/#repository-structure","text":"All the modules are located just under the root folder in the StartLeft's repo and must also fit the following common structure: Since a general Python standard for modularizing projects does not exist, the chosen one is based on the one used by several Open Source projects as well as by the StartLeft project itself before the modularization. It is important to notice that, with this structure, each module is being isolated as if it was an independent project. The goal of this is to facilitate a future migration to independent repositories.","title":"Repository Structure"},{"location":"development/Architecture/#module-structure","text":"Note: _sl_build is an internal module with configuration and building purposes that does not fit the structure explained below. In the root package of each module, there are only two subpackages, and a resources folder. The first subpackage has the same name as the module itself and contains the production code. The other one is called tests and contains specific tests for that module. The resources folder contains the resources needed by each module, for example, the schemas used for validating mapping files. The root folder of each module represents its main boundary and may be understood as the main project folder if the modules where migrated to independent repositories. However, instead of being simply folders, they need to be python regular packages with their own __init.py__ file, which is an important nuance to consider. This file contains, for each module, a call to a function defined in the _sl_build packages that overrides the native python\u2019s import function with a custom one that avoids forbidden imports between modules. In case new modules are added to StartLeft, this call must be added to their main package\u2019s __init.py__ file. ###################################################################### # This folder is not actually intended to be a regular package # # HOWEVER, we need to keep this __init.py__ file in order to # # make it visible by other modules. # # In future versions, this package should be moved to a lib so # # that it will be an independent module instead of a \"false\" package # ###################################################################### # DON'T REMOVE: Module importer overwritten to prevent bidirectional dependencies from _sl_build.secure_importer import override_module_importer override_module_importer ()","title":"Module Structure"},{"location":"development/Architecture/#production-code-package","text":"The name of this package must match the main package . This is the place where the actual business logic code of the module is located. The structure inside it is completely free, and it depends only on the needs of the logic implemented in the module.","title":"Production Code Package"},{"location":"development/Architecture/#test-code-package","text":"As has been already stated along this document, each module is a completely independent piece of software. Of course, this also includes that it must also contain its own test code. Since each module has specific responsibilities, these are the only ones that need to be tested from both a unitary and integration perspective. For example, every SLP must have unitary tests for the classes implemented there, but also integration tests that verifies that the whole conversion to OTM process works for every identified casuistic. Regarding the structure of the whole test code package, there is no a hard constraint about it, but, for readability reasons, it is recommended to follow a common one for every module. The one chosen is split in the following packages: Note : Please don\u2019t be fanatic with the definition of unitary and integration. There are not always clear boundaries, but common sense is the best way to identify what needs to be mocked or not. unit . For unitary tests. integration . For integration tests. resources . It is also recommended to place here a test_resource_paths.py to have a unique point of access to the actual testing resources. util . In case some general utilities need to be developed for being used in the tests, this package is the right place for them.**","title":"Test Code Package"},{"location":"development/Architecture/#main-tests-package","text":"Note: It is necessary to evaluate the convenience to have this package, but, at least for now, it is important to keep these tests to guarantee the quality of the code. At the root level of the StartLeft repository (the same as the other modules) a general tests package is located. Unlike the test packages located inside each module, this one is generic to the entire the StartLeft project and contains integration tests that involves logic belonging to all the modules. By definition, this package can only contain integration tests. So, when a new processor or a new important behavior is added to StartLeft, we need to create their associated integration tests at the project level in this package .","title":"Main Tests Package"},{"location":"development/Architecture/#modules-description","text":"","title":"Modules Description"},{"location":"development/Architecture/#startleft","text":"This is the main module whose origin is the initial StartLeft project that used to contain all the processing logic for the first conversion formats. As part of the modularization process, it was lightened so that it does no longer implements any conversion logic, and it simply exposes the CLI and REST API and makes the connection with the SLPs where the conversion itself takes place. Main responsibilities : Expose a CLI and a REST API to enable the access to the conversion to OTM logic. Imported by : Not imported. Imports : _sl_build , slp_base , sl_util , otm . It also imports slp_cft and slp_tf to support the search function, whose future is under evaluation.","title":"startleft"},{"location":"development/Architecture/#sl_util","text":"This is currently the only module that contains common utilities for the rest of the modules of StartLeft. The sl prefix means that it is not intended to be a very generic module like the Apache Commons in Java, but a module to place useful functions for the StartLeft scope (including some OTM related utilities, for example). However, it is not a mixed bag to place common logic related, for instance, with the SLPs . Business logic or domain classes should fit one of the other modules or, if not, maybe a new one should be created. Main responsibilities : Offer general (not processor specific) utilities related to StartLeft. Imported by : startleft , slp_base , SLPs, otm . Imports : No imports.","title":"sl_util"},{"location":"development/Architecture/#slps","text":"The StartLeft processors are the key modules of StartLeft. They contain the specific logic for converting each format to OTM. Each one is focused on converting from one and only one input format (CFT, TF, Visio, etc.). One important thing to notice is that the integration tests for these modules are the most important ones in the application since they validate behavior for the main purpose and responsibility of StartLeft as a whole.","title":"SLPs"},{"location":"development/Architecture/#slp_base","text":"This is a critical module where the whole process of conversion is defined, including all the interfaces for each step of the conversion process (from loading files to the OTM validation) as well as definition of the errors that the process may potentially arise. Main responsibilities : Defining the main conversion process using a template pattern in the class OTMProcessor . Defining a set of interfaces for each step of the process (source and mapping files loading and validating, OTM conversion process and OTM validation) that must be implemented by the specific SLPs. Defining all the possible errors that may arise through the conversion process. Defining a ProviderResolver class to dynamically retrieve the right SLP based on the source type (CFT, TF, etc.). Imported by : startleft , SLPs. Imports : sl_util , otm .","title":"slp_base"},{"location":"development/Architecture/#concrete-implementations","text":"Each supported provider (CFT, TF, etc.) must have its own processor in order to perform the OTM conversion. They are completely independent modules and imports among them are forbidden. The goal is that they can be work in isolation so their evolution is also completely independent. In case some duplication appears between two processors, the first option is to duplicate the code instead of prematurely creating abstractions. Only after these duplications were consolidated, and we could identify a really common casuistic, we may think about creating a common module grouping, for instance, logic related with one provider type (IaC, diagram or threat modeling). Anyway, this common logic should be placed in a new dedicated module and never in the sl_util module . Current implementations : slp_cft for Cloudformation (IaC). slp_tf for Terraform (IaC). slp_visio for MS Visio (Diagram). slp_mtmt for MS Threat Modeling Tool (Threat model). Main responsibilities : Implementing the interfaces defined in slp_base in order to actually perform the conversion process from the origin provider formats to OTM. Imported by : No statically imported by any module. They are dynamically instanced by the slp_base based on the module configuration placed in _sl_build . Imports : Each processor is an independent module that may import different modules. However, in general: Must import: otm and slp_base . May import: sl_util . Cannot import: startleft .","title":"Concrete Implementations"},{"location":"development/Architecture/#otm","text":"Currently, we have the only public release specifically focused on the OTM standard here , that simply contains a README.md file with a natural language description of the components of the standard. It would be interesting to extend the resources associated with the standard and share them with the community (a JSON schema, some kind of validator, etc.). This module is intended to be the seed for that public resources' library. This means that it has not to be understood as a part of StartLeft itself (notice the absence of the sl prefix), but as a more generic library exclusively oriented to general OTM concerns. Main responsibilities : Defining a set of entities that represent the OTM standard as well as providing a standard building to simplify the generation of OTM instances. Imported by : startleft , slp_base , SLPs. Imports : Currently, it imports sl_util , but, for the reasons explained above, it should not import any StartLeft module. Thus, we should be careful about creating new dependencies between these two modules.","title":"otm"},{"location":"development/Architecture/#_sl_build","text":"This is a special module whose existence is due to the current structure of the project. Since the multimodule management is not being done by any external tool (like Maven/Gradle in Java), it is necessary to develop some ad hoc features in order to manage the interaction between modules. Main responsibilities : Defining the main configuration for the modules in a configuration class. Name of the module. Type of module ( general or processor ). Forbidden dependencies. Provider type supported by each SLP. Managing the imports between modules to raise an error when trying to import a forbidden dependency. Note : The imports for this module are not constrained as in the other ones because this is the module that manages these constraints, so it is important to be careful with the imports that are performed here. Imported by : startleft to read configuration and for all the rest of the modules to override the import system. Imports : No imports allowed.","title":"_sl_build"},{"location":"development/Architecture/#building","text":"All the modules inside StartLeft are, at the end of the day, Python modules, so pip does not have any problem to install a project based on them. For this reason, the installation of the StartLeft project can be simply done by executing this command inside the StartLeft repository's root folder: pip install . About the entrypoints for the application, it is important to difference between the startleft whole project and the startleft module inside it. This means that, to reference some class or module inside it, it is needed to put the name two times ( startleft.startleft ). For example, in the docker-compose command or the docker ENTRYPOINT , the FastAPI webapp entry point must be referenced in this way:","title":"Building"},{"location":"development/Architecture/#testing","text":"As stated before in this document, each module is an independent software unit with their own tests set. This means that the tests can only be executed module by module. In PyCharm, for example, a run configuration must be created for executing the tests in each module: For executing them from the terminal, pytest needs to know what is the module that is under testing: pytest slp_base It is also possible to execute tests for several modules at the same time: pytest slp_base otm startleft However, from the point of view of CI/CD, it is undesirable to include in the pipelines configuration the name of all the modules that are required to be tested because this implies that every modification in the module structure or even the addition of a new module will provoke the modification of all the pipelines. For this reason, a run_tests.py has been created in the root of the StartLeft project. It contains the logic for retrieving all the modules in the application and calling pytest with all of them generating a unique report. So, the command that the pipelines must include for executing the StartLeft\u2019s tests is: python run_tests.py From a development point of view, the most common scenario is that only the module under development is needed to be frequently tested. However, there is no problem about executing all the tests on demand by creating a run configuration that runs that run_tests.py file in PyCharm and execute all the tests.","title":"Testing"},{"location":"development/Create-a-new-StartLeft-Processor/","text":"Create a new StartLeft Processor (SLP) As you can see in the architecture page StartLeft Processors (SLPs) are a special kind of modules where the conversion into OTM logic is actually implemented. All of them are based on the same interfaces, defined in the slp_base module. So, if you want to create a new SLP, you simply have to: Create your module extending slp_base . Implement the parsing logic in your module. Configure StartLeft to use your module. Below you have a guided tutorial for easily performing this steps and creating a new SLP for a very basic invented input format that you can use as a base for building your own. Defining a sample input format (for demo purposes) Note : The SLPs are classified in IaC, Diagram or External Threat Model (ETM). However, it is only a logical division and the instructions defined in this tutorial are valid for creating SLPs of any kind. To guide this tutorial, let's imagine a fictitious Infrastructure as Code format, that we will call My Awesome Infrastructure Source (MAIS) . A sample file of this format could be something like: { \"resources\" : [ { \"id\" : 1 , \"name\" : \"My Server\" , \"type\" : \"server\" } ] } We need to define a format for the mappings between the source file and OTM. An example of this mapping file could be: Note : Remind that the OTM standard forces each component to have a parent. This is the reason we include this default TrustZone for this example. trustZones : - id : public-cloud name : Public Cloud default : true components : - source_type : server otm_type : otm-server So the resulting OTM for this example should be something like: { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"My Project\" , \"id\" : \"my-project\" }, \"representations\" : [ { \"name\" : \"My Awesome Infrastructure Source\" , \"id\" : \"My Awesome Infrastructure Source\" , \"type\" : \"code\" } ], \"trustZones\" : [ { \"id\" : \"public-cloud\" , \"name\" : \"Public Cloud\" , \"risk\" : { \"trustRating\" : 10 } } ], \"components\" : [ { \"id\" : \"1\" , \"name\" : \"My Server\" , \"type\" : \"otm-server\" , \"parent\" : { \"trustZone\" : \"public-cloud\" } } ], \"dataflows\" : [] } Understanding the slp_base interfaces The OTMProcessor class inside the slp_base module defines the conversion process using a template method, whose behavior depends on the implementations of the rest of the interfaces in the module. In order to implement our sample processor, we need to know the structure of the provided interfaces, which looks like this. Creating the module For this tutorial, we are going to create a new SLP for parsing My awesome input source (MAIS) files which is going to be called slp_mais . First, we need to set up our development environment as explained in the Quickstart Guide for Developers . Build the module structure Note : Do not worry if at this point you get some errors from the IDE. We will create some required modules and classes later. Every module must have a common structure and minimum files to work. So let's start by creating them. Create the module folder slp_mais under the root startleft repo folder: Override the module importer for the module (for preventing forbidden imports among modules) by creating a slp_mais/__init__.py file with this content: ###################################################################### # This folder is not actually intended to be a regular package # # HOWEVER, we need to keep this __init.py__ file in order to # # make it visible by other modules. # # In future versions, this package should be moved to a lib so # # that it will be an independent module instead of a \"false\" package # ###################################################################### # DON'T REMOVE: Module importer overwritten to prevent bidirectional dependencies from _sl_build.secure_importer import override_module_importer override_module_importer () from .slp_mais import * Create the production code package, creating a folder slp_mais/slp_mais with an __init__.py file that exports the processor we are going to create in the next steps: from .mais_processor import MAISProcessor Create the test code module as a slp_mais/tests folder with an empty __init__.py inside it. Create packages for unit and integration tests: slp_mais/tests/unit with an empty __init__.py file inside it. slp_mais/tests/integration with an empty __init__.py file inside it. Create an empty slp_mais/tests/resources folder. After following these steps, your module should like this: Add the MAIS type to the Provider types Every source type supported by StartLeft must be included in the enums contained in slp_base/slp_base/provider_type.py . As we have stated before, MAIS is a fictitious IaC source, so we will add it to the IacType enum. from otm.otm.provider import Provider class IacType ( str , Provider ): # [...] MAIS = ( \"MAIS\" , \"My Awesome Infrastructure Source\" , \"code\" ) Implement slp_base interfaces Note : In order to simplify this tutorial, we will not implement any validation nor process loading or processing errors, but, for a real implementation, you must read the errors management page to know the errors you should raise in each stage of the conversion process. We already know the main structure of the conversion process, so we can create our own implementation classes in the production code package ( slp_mais/slp_mais ). MAISValidator (ProviderValidator) Create the mais_validator.py file with the MAISValidator class implementing ProviderValidator . import logging from slp_base import ProviderValidator logger = logging . getLogger ( __name__ ) class MAISValidator ( ProviderValidator ): def __init__ ( self , mais_data ): super ( MAISValidator , self ) . __init__ () self . mais_data = mais_data def validate ( self ): logger . info ( 'Validating MAIS file' ) MAISLoader (ProviderLoader) Create the mais_loader.py file with the MAISLoader class implementing ProviderLoader : import json import logging from slp_base.slp_base.provider_loader import ProviderLoader logger = logging . getLogger ( __name__ ) class MAISLoader ( ProviderLoader ): def __init__ ( self , mais_source ): self . mais_source = mais_source self . mais = {} def load ( self ): logging . getLogger ( 'Loading MAIS source...' ) self . mais = json . loads ( self . mais_source ) def get_mais ( self ) -> {}: return self . mais MAISMappingValidator (MappingValidator) Create the mais_mapping_validator.py file with the MAISMappingValidator class implementing MappingValidator : import logging from slp_base import MappingValidator logger = logging . getLogger ( __name__ ) class MAISMappingValidator ( MappingValidator ): def __init__ ( self , mais_mapping_file ): self . mais_mapping_file = mais_mapping_file def validate ( self ): logger . info ( 'Validating MAIS mapping file' ) MAISMappingLoader (MAISMappingLoader) Create the mais_mapping_loader.py file with the MAISMappingLoader class implementing MAISMappingLoader : import yaml import logging from slp_base import MappingLoader logger = logging . getLogger ( __name__ ) class MAISMappingLoader ( MappingLoader ): def __init__ ( self , mapping_data : bytes ): self . mapping_data = mapping_data self . mais_mapping = {} def load ( self ): logger . info ( \"Loading MAIS mapping file...\" ) self . mais_mapping = yaml . load ( self . mapping_data , Loader = yaml . SafeLoader ) def get_mais_mapping ( self ): return self . mais_mapping MAISParser (ProviderParser) Create mais_parser.py file with the MAISParser class implementing ProviderParser . It will need to contain, at least, the minimum information to parse the source and create the OTM, this is: The ID of the OTM project. The name of the OTM project. The MAIS source. The MAIS mappings. For this example, almost trivial logic for processing our imaginary format is included, but this is the class where you would need to actually implement your custom conversion process. from otm.otm.entity.component import Component from otm.otm.entity.otm import OTM from otm.otm.entity.trustzone import Trustzone from otm.otm.otm_builder import OTMBuilder from slp_base.slp_base.provider_parser import ProviderParser from slp_base.slp_base.provider_type import IacType class MAISParser ( ProviderParser ): def __init__ ( self , project_id : str , project_name : str , source , mais_mapping ): self . project_id = project_id self . project_name = project_name self . source = source self . mais_mapping = mais_mapping def build_otm ( self ) -> OTM : return OTMBuilder ( self . project_id , self . project_name , IacType . MAIS ) . add_components ( self . __parse_components ()) . add_trustzones ( self . __parse_trustzones ()) . build () def __parse_trustzones ( self ) -> [ Trustzone ]: default_trustzone = self . __get_default_trustzone () return [ Trustzone ( default_trustzone [ 'id' ], default_trustzone [ 'name' ])] def __parse_components ( self ) -> [ Component ]: component_mappings = self . mais_mapping [ 'components' ] types_mappings = dict ( zip ( [ cm [ 'source_type' ] for cm in component_mappings ], component_mappings )) otm_components = [] for mais_component in self . source [ 'resources' ]: source_type = mais_component [ 'type' ] if source_type not in types_mappings : continue otm_components . append ( Component ( id = str ( mais_component [ 'id' ]), name = mais_component [ 'name' ], type = types_mappings [ source_type ][ 'otm_type' ], parent = self . __get_default_trustzone ()[ 'id' ], parent_type = 'trustZone' )) return otm_components def __get_default_trustzone ( self ) -> dict : return next ( filter ( lambda tz : 'default' in tz and tz [ 'default' ], self . mais_mapping [ 'trustZones' ])) MAISProcessor (OTMProcessor) Finally, we are going to create the main class, the MAISProcessor , in a mais_processor.py file for implementing the OTMProcessor interface. This class must implement methods for retrieving instances of all the other classes created above: from slp_base import MappingLoader , MappingValidator from slp_base import OTMProcessor from slp_base import ProviderValidator from slp_base.slp_base.provider_loader import ProviderLoader from slp_base.slp_base.provider_parser import ProviderParser from slp_mais.slp_mais.mais_loader import MAISLoader from slp_mais.slp_mais.mais_mapping_loader import MAISMappingLoader from slp_mais.slp_mais.mais_mapping_validator import MAISMappingValidator from slp_mais.slp_mais.mais_parser import MAISParser from slp_mais.slp_mais.mais_validator import MAISValidator class MAISProcessor ( OTMProcessor ): def __init__ ( self , project_id : str , project_name : str , sources : [ bytes ], mappings : [ bytes ]): self . project_id = project_id self . project_name = project_name self . source = sources [ 0 ] self . mappings = mappings [ 0 ] self . loader = None self . mapping_loader = None def get_provider_validator ( self ) -> ProviderValidator : return MAISValidator ( self . source ) def get_provider_loader ( self ) -> ProviderLoader : self . loader = MAISLoader ( self . source ) return self . loader def get_mapping_validator ( self ) -> MappingValidator : return MAISMappingValidator ( self . mappings ) def get_mapping_loader ( self ) -> MappingLoader : self . mapping_loader = MAISMappingLoader ( self . mappings ) return self . mapping_loader def get_provider_parser ( self ) -> ProviderParser : mais = self . loader . get_mais () mais_mapping = self . mapping_loader . get_mais_mapping () return MAISParser ( self . project_id , self . project_name , mais , mais_mapping ) Once you have created all the implementations, your slp_module package should appear like this: Testing the SLP We have already implemented all the necessary classes to perform the conversion from MAIS to OTM, so let's create a test to verify that they are working fine. Create the test resources We are going to create a single happy path test using the resources from the section where the MAIS format is defined. So, inside the slp_mais/tests/resources folder: Copy the MAIS source file with the name mais-sample.json . Copy the mapping file with the name mapping-sample.yaml . Copy the expected OTM resulting file with the name expected-otm.otm . Implement the test Now we can create a simple test that verifies that the conversion process is working fine for the basic files created above. For that, create a test_mais_processor.py file inside the slp_mais/slp_mais/tests/integration folder: import os from sl_util.sl_util.file_utils import get_data from slp_base.tests.util.otm import validate_and_compare from slp_mais.slp_mais.mais_processor import MAISProcessor SAMPLE_PROJECT_ID = 'my-project' SAMPLE_PROJECT_NAME = 'My Project' resources_path = f ' { os . path . dirname ( __file__ ) } /../resources' class TestMAISProcessor : def test_single_component_mais_file_ok ( self ): # GIVEN a simple MAIS file with a single component mais_file = get_data ( f ' { resources_path } /mais-sample.json' ) # AND a MAIS mapping file that defines a mapping for that component mapping_file = get_data ( f ' { resources_path } /mapping-sample.yaml' ) # AND an expected OTM result expected_otm = f ' { resources_path } /expected-otm.otm' # WHEN MAISProcessor::process is invoked otm = MAISProcessor ( project_id = SAMPLE_PROJECT_ID , project_name = SAMPLE_PROJECT_NAME , sources = [ mais_file ], mappings = [ mapping_file ] ) . process () # THEN a valid OTM file matching expected is generated result , expected = validate_and_compare ( otm , expected_otm , []) assert result == expected The whole module appears now like this: You are done! Execute the test and verify that the conversion process is happily performed! Configuring and exposing the SLP At this point we already have our processor up and running, so it is time to expose it. For that, no code is needed, and you only need to perform the configuration steps below. Configure the module Go to the _sl_build/modules.py class, where you can find the modules' configuration. In the PROCESSORS variable, add slp_mais as forbidden_dependency for all the existent SLP modules. Create a new entry in the array with the configuration for our slp_mais module: { 'name' : 'slp_mais' , 'type' : 'processor' , 'provider_type' : 'MAIS' , 'forbidden_dependencies' : [ 'startleft' , 'slp_cft' , 'slp_tf' , 'slp_visio' , 'slp_mtmt' ] } Update the Swagger schema Open the file startleft/resources/api/v1/swagger.yaml where the API is defined. Add the new MAIS type to the iac_type description and to the IacType enum: # Reduced for simplicity components : schemas : Body_iac_api_v1_startleft_iac_post : properties : iac_type : description : 'Type of IaC File: CLOUDFORMATION, TERRAFORM, MAIS' # Reduced for simplicity components : schemas : IacType : title : IacType enum : - CLOUDFORMATION - TERRAFORM - MAIS type : string description : Type of IaC file Try it on the REST API Launch the REST API as explained in the Quickstart Guide for Developers and check the Swagger page in http://localhost:5000/docs . You can see that the MAIS IaC type is already available in the POST /iac endpoint: If you try to perform the request with the sample source and mapping files used across this tutorial, you can see that the server is returning the expected OTM as a response.","title":"Create a new SLP"},{"location":"development/Create-a-new-StartLeft-Processor/#create-a-new-startleft-processor-slp","text":"As you can see in the architecture page StartLeft Processors (SLPs) are a special kind of modules where the conversion into OTM logic is actually implemented. All of them are based on the same interfaces, defined in the slp_base module. So, if you want to create a new SLP, you simply have to: Create your module extending slp_base . Implement the parsing logic in your module. Configure StartLeft to use your module. Below you have a guided tutorial for easily performing this steps and creating a new SLP for a very basic invented input format that you can use as a base for building your own.","title":"Create a new StartLeft Processor (SLP)"},{"location":"development/Create-a-new-StartLeft-Processor/#defining-a-sample-input-format-for-demo-purposes","text":"Note : The SLPs are classified in IaC, Diagram or External Threat Model (ETM). However, it is only a logical division and the instructions defined in this tutorial are valid for creating SLPs of any kind. To guide this tutorial, let's imagine a fictitious Infrastructure as Code format, that we will call My Awesome Infrastructure Source (MAIS) . A sample file of this format could be something like: { \"resources\" : [ { \"id\" : 1 , \"name\" : \"My Server\" , \"type\" : \"server\" } ] } We need to define a format for the mappings between the source file and OTM. An example of this mapping file could be: Note : Remind that the OTM standard forces each component to have a parent. This is the reason we include this default TrustZone for this example. trustZones : - id : public-cloud name : Public Cloud default : true components : - source_type : server otm_type : otm-server So the resulting OTM for this example should be something like: { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"My Project\" , \"id\" : \"my-project\" }, \"representations\" : [ { \"name\" : \"My Awesome Infrastructure Source\" , \"id\" : \"My Awesome Infrastructure Source\" , \"type\" : \"code\" } ], \"trustZones\" : [ { \"id\" : \"public-cloud\" , \"name\" : \"Public Cloud\" , \"risk\" : { \"trustRating\" : 10 } } ], \"components\" : [ { \"id\" : \"1\" , \"name\" : \"My Server\" , \"type\" : \"otm-server\" , \"parent\" : { \"trustZone\" : \"public-cloud\" } } ], \"dataflows\" : [] }","title":"Defining a sample input format (for demo purposes)"},{"location":"development/Create-a-new-StartLeft-Processor/#understanding-the-slp_base-interfaces","text":"The OTMProcessor class inside the slp_base module defines the conversion process using a template method, whose behavior depends on the implementations of the rest of the interfaces in the module. In order to implement our sample processor, we need to know the structure of the provided interfaces, which looks like this.","title":"Understanding the slp_base interfaces"},{"location":"development/Create-a-new-StartLeft-Processor/#creating-the-module","text":"For this tutorial, we are going to create a new SLP for parsing My awesome input source (MAIS) files which is going to be called slp_mais . First, we need to set up our development environment as explained in the Quickstart Guide for Developers .","title":"Creating the module"},{"location":"development/Create-a-new-StartLeft-Processor/#build-the-module-structure","text":"Note : Do not worry if at this point you get some errors from the IDE. We will create some required modules and classes later. Every module must have a common structure and minimum files to work. So let's start by creating them. Create the module folder slp_mais under the root startleft repo folder: Override the module importer for the module (for preventing forbidden imports among modules) by creating a slp_mais/__init__.py file with this content: ###################################################################### # This folder is not actually intended to be a regular package # # HOWEVER, we need to keep this __init.py__ file in order to # # make it visible by other modules. # # In future versions, this package should be moved to a lib so # # that it will be an independent module instead of a \"false\" package # ###################################################################### # DON'T REMOVE: Module importer overwritten to prevent bidirectional dependencies from _sl_build.secure_importer import override_module_importer override_module_importer () from .slp_mais import * Create the production code package, creating a folder slp_mais/slp_mais with an __init__.py file that exports the processor we are going to create in the next steps: from .mais_processor import MAISProcessor Create the test code module as a slp_mais/tests folder with an empty __init__.py inside it. Create packages for unit and integration tests: slp_mais/tests/unit with an empty __init__.py file inside it. slp_mais/tests/integration with an empty __init__.py file inside it. Create an empty slp_mais/tests/resources folder. After following these steps, your module should like this:","title":"Build the module structure"},{"location":"development/Create-a-new-StartLeft-Processor/#add-the-mais-type-to-the-provider-types","text":"Every source type supported by StartLeft must be included in the enums contained in slp_base/slp_base/provider_type.py . As we have stated before, MAIS is a fictitious IaC source, so we will add it to the IacType enum. from otm.otm.provider import Provider class IacType ( str , Provider ): # [...] MAIS = ( \"MAIS\" , \"My Awesome Infrastructure Source\" , \"code\" )","title":"Add the MAIS type to the Provider types"},{"location":"development/Create-a-new-StartLeft-Processor/#implement-slp_base-interfaces","text":"Note : In order to simplify this tutorial, we will not implement any validation nor process loading or processing errors, but, for a real implementation, you must read the errors management page to know the errors you should raise in each stage of the conversion process. We already know the main structure of the conversion process, so we can create our own implementation classes in the production code package ( slp_mais/slp_mais ).","title":"Implement slp_base interfaces"},{"location":"development/Create-a-new-StartLeft-Processor/#maisvalidator-providervalidator","text":"Create the mais_validator.py file with the MAISValidator class implementing ProviderValidator . import logging from slp_base import ProviderValidator logger = logging . getLogger ( __name__ ) class MAISValidator ( ProviderValidator ): def __init__ ( self , mais_data ): super ( MAISValidator , self ) . __init__ () self . mais_data = mais_data def validate ( self ): logger . info ( 'Validating MAIS file' )","title":"MAISValidator (ProviderValidator)"},{"location":"development/Create-a-new-StartLeft-Processor/#maisloader-providerloader","text":"Create the mais_loader.py file with the MAISLoader class implementing ProviderLoader : import json import logging from slp_base.slp_base.provider_loader import ProviderLoader logger = logging . getLogger ( __name__ ) class MAISLoader ( ProviderLoader ): def __init__ ( self , mais_source ): self . mais_source = mais_source self . mais = {} def load ( self ): logging . getLogger ( 'Loading MAIS source...' ) self . mais = json . loads ( self . mais_source ) def get_mais ( self ) -> {}: return self . mais","title":"MAISLoader (ProviderLoader)"},{"location":"development/Create-a-new-StartLeft-Processor/#maismappingvalidator-mappingvalidator","text":"Create the mais_mapping_validator.py file with the MAISMappingValidator class implementing MappingValidator : import logging from slp_base import MappingValidator logger = logging . getLogger ( __name__ ) class MAISMappingValidator ( MappingValidator ): def __init__ ( self , mais_mapping_file ): self . mais_mapping_file = mais_mapping_file def validate ( self ): logger . info ( 'Validating MAIS mapping file' )","title":"MAISMappingValidator (MappingValidator)"},{"location":"development/Create-a-new-StartLeft-Processor/#maismappingloader-maismappingloader","text":"Create the mais_mapping_loader.py file with the MAISMappingLoader class implementing MAISMappingLoader : import yaml import logging from slp_base import MappingLoader logger = logging . getLogger ( __name__ ) class MAISMappingLoader ( MappingLoader ): def __init__ ( self , mapping_data : bytes ): self . mapping_data = mapping_data self . mais_mapping = {} def load ( self ): logger . info ( \"Loading MAIS mapping file...\" ) self . mais_mapping = yaml . load ( self . mapping_data , Loader = yaml . SafeLoader ) def get_mais_mapping ( self ): return self . mais_mapping","title":"MAISMappingLoader (MAISMappingLoader)"},{"location":"development/Create-a-new-StartLeft-Processor/#maisparser-providerparser","text":"Create mais_parser.py file with the MAISParser class implementing ProviderParser . It will need to contain, at least, the minimum information to parse the source and create the OTM, this is: The ID of the OTM project. The name of the OTM project. The MAIS source. The MAIS mappings. For this example, almost trivial logic for processing our imaginary format is included, but this is the class where you would need to actually implement your custom conversion process. from otm.otm.entity.component import Component from otm.otm.entity.otm import OTM from otm.otm.entity.trustzone import Trustzone from otm.otm.otm_builder import OTMBuilder from slp_base.slp_base.provider_parser import ProviderParser from slp_base.slp_base.provider_type import IacType class MAISParser ( ProviderParser ): def __init__ ( self , project_id : str , project_name : str , source , mais_mapping ): self . project_id = project_id self . project_name = project_name self . source = source self . mais_mapping = mais_mapping def build_otm ( self ) -> OTM : return OTMBuilder ( self . project_id , self . project_name , IacType . MAIS ) . add_components ( self . __parse_components ()) . add_trustzones ( self . __parse_trustzones ()) . build () def __parse_trustzones ( self ) -> [ Trustzone ]: default_trustzone = self . __get_default_trustzone () return [ Trustzone ( default_trustzone [ 'id' ], default_trustzone [ 'name' ])] def __parse_components ( self ) -> [ Component ]: component_mappings = self . mais_mapping [ 'components' ] types_mappings = dict ( zip ( [ cm [ 'source_type' ] for cm in component_mappings ], component_mappings )) otm_components = [] for mais_component in self . source [ 'resources' ]: source_type = mais_component [ 'type' ] if source_type not in types_mappings : continue otm_components . append ( Component ( id = str ( mais_component [ 'id' ]), name = mais_component [ 'name' ], type = types_mappings [ source_type ][ 'otm_type' ], parent = self . __get_default_trustzone ()[ 'id' ], parent_type = 'trustZone' )) return otm_components def __get_default_trustzone ( self ) -> dict : return next ( filter ( lambda tz : 'default' in tz and tz [ 'default' ], self . mais_mapping [ 'trustZones' ]))","title":"MAISParser (ProviderParser)"},{"location":"development/Create-a-new-StartLeft-Processor/#maisprocessor-otmprocessor","text":"Finally, we are going to create the main class, the MAISProcessor , in a mais_processor.py file for implementing the OTMProcessor interface. This class must implement methods for retrieving instances of all the other classes created above: from slp_base import MappingLoader , MappingValidator from slp_base import OTMProcessor from slp_base import ProviderValidator from slp_base.slp_base.provider_loader import ProviderLoader from slp_base.slp_base.provider_parser import ProviderParser from slp_mais.slp_mais.mais_loader import MAISLoader from slp_mais.slp_mais.mais_mapping_loader import MAISMappingLoader from slp_mais.slp_mais.mais_mapping_validator import MAISMappingValidator from slp_mais.slp_mais.mais_parser import MAISParser from slp_mais.slp_mais.mais_validator import MAISValidator class MAISProcessor ( OTMProcessor ): def __init__ ( self , project_id : str , project_name : str , sources : [ bytes ], mappings : [ bytes ]): self . project_id = project_id self . project_name = project_name self . source = sources [ 0 ] self . mappings = mappings [ 0 ] self . loader = None self . mapping_loader = None def get_provider_validator ( self ) -> ProviderValidator : return MAISValidator ( self . source ) def get_provider_loader ( self ) -> ProviderLoader : self . loader = MAISLoader ( self . source ) return self . loader def get_mapping_validator ( self ) -> MappingValidator : return MAISMappingValidator ( self . mappings ) def get_mapping_loader ( self ) -> MappingLoader : self . mapping_loader = MAISMappingLoader ( self . mappings ) return self . mapping_loader def get_provider_parser ( self ) -> ProviderParser : mais = self . loader . get_mais () mais_mapping = self . mapping_loader . get_mais_mapping () return MAISParser ( self . project_id , self . project_name , mais , mais_mapping ) Once you have created all the implementations, your slp_module package should appear like this:","title":"MAISProcessor (OTMProcessor)"},{"location":"development/Create-a-new-StartLeft-Processor/#testing-the-slp","text":"We have already implemented all the necessary classes to perform the conversion from MAIS to OTM, so let's create a test to verify that they are working fine.","title":"Testing the SLP"},{"location":"development/Create-a-new-StartLeft-Processor/#create-the-test-resources","text":"We are going to create a single happy path test using the resources from the section where the MAIS format is defined. So, inside the slp_mais/tests/resources folder: Copy the MAIS source file with the name mais-sample.json . Copy the mapping file with the name mapping-sample.yaml . Copy the expected OTM resulting file with the name expected-otm.otm .","title":"Create the test resources"},{"location":"development/Create-a-new-StartLeft-Processor/#implement-the-test","text":"Now we can create a simple test that verifies that the conversion process is working fine for the basic files created above. For that, create a test_mais_processor.py file inside the slp_mais/slp_mais/tests/integration folder: import os from sl_util.sl_util.file_utils import get_data from slp_base.tests.util.otm import validate_and_compare from slp_mais.slp_mais.mais_processor import MAISProcessor SAMPLE_PROJECT_ID = 'my-project' SAMPLE_PROJECT_NAME = 'My Project' resources_path = f ' { os . path . dirname ( __file__ ) } /../resources' class TestMAISProcessor : def test_single_component_mais_file_ok ( self ): # GIVEN a simple MAIS file with a single component mais_file = get_data ( f ' { resources_path } /mais-sample.json' ) # AND a MAIS mapping file that defines a mapping for that component mapping_file = get_data ( f ' { resources_path } /mapping-sample.yaml' ) # AND an expected OTM result expected_otm = f ' { resources_path } /expected-otm.otm' # WHEN MAISProcessor::process is invoked otm = MAISProcessor ( project_id = SAMPLE_PROJECT_ID , project_name = SAMPLE_PROJECT_NAME , sources = [ mais_file ], mappings = [ mapping_file ] ) . process () # THEN a valid OTM file matching expected is generated result , expected = validate_and_compare ( otm , expected_otm , []) assert result == expected The whole module appears now like this: You are done! Execute the test and verify that the conversion process is happily performed!","title":"Implement the test"},{"location":"development/Create-a-new-StartLeft-Processor/#configuring-and-exposing-the-slp","text":"At this point we already have our processor up and running, so it is time to expose it. For that, no code is needed, and you only need to perform the configuration steps below.","title":"Configuring and exposing the SLP"},{"location":"development/Create-a-new-StartLeft-Processor/#configure-the-module","text":"Go to the _sl_build/modules.py class, where you can find the modules' configuration. In the PROCESSORS variable, add slp_mais as forbidden_dependency for all the existent SLP modules. Create a new entry in the array with the configuration for our slp_mais module: { 'name' : 'slp_mais' , 'type' : 'processor' , 'provider_type' : 'MAIS' , 'forbidden_dependencies' : [ 'startleft' , 'slp_cft' , 'slp_tf' , 'slp_visio' , 'slp_mtmt' ] }","title":"Configure the module"},{"location":"development/Create-a-new-StartLeft-Processor/#update-the-swagger-schema","text":"Open the file startleft/resources/api/v1/swagger.yaml where the API is defined. Add the new MAIS type to the iac_type description and to the IacType enum: # Reduced for simplicity components : schemas : Body_iac_api_v1_startleft_iac_post : properties : iac_type : description : 'Type of IaC File: CLOUDFORMATION, TERRAFORM, MAIS' # Reduced for simplicity components : schemas : IacType : title : IacType enum : - CLOUDFORMATION - TERRAFORM - MAIS type : string description : Type of IaC file","title":"Update the Swagger schema"},{"location":"development/Create-a-new-StartLeft-Processor/#try-it-on-the-rest-api","text":"Launch the REST API as explained in the Quickstart Guide for Developers and check the Swagger page in http://localhost:5000/docs . You can see that the MAIS IaC type is already available in the POST /iac endpoint: If you try to perform the request with the sample source and mapping files used across this tutorial, you can see that the server is returning the expected OTM as a response.","title":"Try it on the REST API"},{"location":"development/Errors-Management/","text":"Errors management Steps The management of errors on StartLeft is handled on four separated steps: Provider selection. Source file processing. Mapping file processing. OTM generation. Error types Step 1: Provider error: Provider resolver could not find a provider for the given type. ProviderNotFoundError . Step 2: Validation error: The file is not valid due to wrong mime type, maxsize, etc. IacNotValidFileError . DiagramNotValidFileError . SourceFileNotValidError . Loading error: We are unable to load the file due to the wrong type being specified or any error inside the file that does not permit loading its content. LoadingIacFileError . LoadingDiagramFileError . LoadingSourceFileError . Step 3: Validation error: The file is not valid due to wrong mime type, maxsize, etc. MappingFileNotValidError . Loading error: We are unable to load the file due to the wrong type being specified or any error inside the file that does not permit loading its content. LoadingMappingFileError . Step 4: OTM generation related errors: OTMBuildingError . We are unable to generate the OTM with the given files. OTMResultError . We are able to generate the OTM but the OTM is invalid (e.g: inconsistent IDs). OTMGenerationError . There was any unexpected error. HTTP statuses and exit codes Error code HTTP Status CLI exit code LoadingIacFileError 400 1 IacFileNotValidError 400 2 LoadingDiagramFileError 400 11 DiagramNotValidFileError 400 12 LoadingSourceFileError 400 51 SourceFileNotValidError 400 52 LoadingMappingFileError 400 21 MappingFileNotValidError 400 22 OTMBuildingError 400 41 OTMResultError 400 42 OTMGenerationError 500 45 ProviderNotFoundError 400 60 HTTP response body The response body on any of this cases will be a JSON with this structure: { \"status\" : \"the numeric http status code\" , \"error_type\" : \"<The error type>\" , \"title\" : \"<The error on human readable form>\" , \"detail\" : \"<The detail of the error>\" , \"errors\" : [ { \"errorMessage\" : \"<The reason of the error>\" } ] } When calling StartLeft through IriusRisk, the most important field here is error_type because it is the code that the IriusRisk core is going to read to match the error type, manage the StartLeft error response and send its own response on the core API.","title":"Errors management"},{"location":"development/Errors-Management/#errors-management","text":"","title":"Errors management"},{"location":"development/Errors-Management/#steps","text":"The management of errors on StartLeft is handled on four separated steps: Provider selection. Source file processing. Mapping file processing. OTM generation.","title":"Steps"},{"location":"development/Errors-Management/#error-types","text":"Step 1: Provider error: Provider resolver could not find a provider for the given type. ProviderNotFoundError . Step 2: Validation error: The file is not valid due to wrong mime type, maxsize, etc. IacNotValidFileError . DiagramNotValidFileError . SourceFileNotValidError . Loading error: We are unable to load the file due to the wrong type being specified or any error inside the file that does not permit loading its content. LoadingIacFileError . LoadingDiagramFileError . LoadingSourceFileError . Step 3: Validation error: The file is not valid due to wrong mime type, maxsize, etc. MappingFileNotValidError . Loading error: We are unable to load the file due to the wrong type being specified or any error inside the file that does not permit loading its content. LoadingMappingFileError . Step 4: OTM generation related errors: OTMBuildingError . We are unable to generate the OTM with the given files. OTMResultError . We are able to generate the OTM but the OTM is invalid (e.g: inconsistent IDs). OTMGenerationError . There was any unexpected error.","title":"Error types"},{"location":"development/Errors-Management/#http-statuses-and-exit-codes","text":"Error code HTTP Status CLI exit code LoadingIacFileError 400 1 IacFileNotValidError 400 2 LoadingDiagramFileError 400 11 DiagramNotValidFileError 400 12 LoadingSourceFileError 400 51 SourceFileNotValidError 400 52 LoadingMappingFileError 400 21 MappingFileNotValidError 400 22 OTMBuildingError 400 41 OTMResultError 400 42 OTMGenerationError 500 45 ProviderNotFoundError 400 60","title":"HTTP statuses and exit codes"},{"location":"development/Errors-Management/#http-response-body","text":"The response body on any of this cases will be a JSON with this structure: { \"status\" : \"the numeric http status code\" , \"error_type\" : \"<The error type>\" , \"title\" : \"<The error on human readable form>\" , \"detail\" : \"<The detail of the error>\" , \"errors\" : [ { \"errorMessage\" : \"<The reason of the error>\" } ] } When calling StartLeft through IriusRisk, the most important field here is error_type because it is the code that the IriusRisk core is going to read to match the error type, manage the StartLeft error response and send its own response on the core API.","title":"HTTP response body"},{"location":"development/Quickstart-Guide-for-Developers/","text":"Quickstart Guide for Developers StartLeft is an Open Source project that welcomes collaborators to extend or improve its functionality. Despite the fact that it was born as an internal IriusRisk project, there are some characteristic that makes it specially suitable to grow through the contributions of the community: The nature of the project, whose natural functional escalation is based on the support of new, independent, source formats. The conversion into OTM is based on configuration files that can also be created independently depending on the expected OTM use. The modularized architecture enables collaborators to contribute to each format's processor without conflicts. How to contribute? The IriusRisk team is currently the coordinator of the project and, ultimately, the responsible for validating the Pull Requests created by the collaborators. All you need to know before you start contributing is in the CONTRIBUTING.md file . Anyway, it is important to consider that, before creating your own fork or PR, you should check the open issues to ensure that there is none related with what you intend to do. Set up the environment There are no special requirements about a specific IDE or special steps to perform that make StartLeft different from any Python project. However, as PyCharm (or IntelliJ with the python plugin) is one of the most common python IDEs, some related utilities are provided. Basic configuration Regardless of the IDE you use, we can generalize the cloning of the project and the creation and configuration of the python virtual environment. First, we need to clone the project and move to its project: git clone https://github.com/iriusrisk/startleft.git cd startleft Then, let's create and activate a virtual environment for StartLeft: python3 -m venv ./venv source venv/bin/activate Now, install all the required dependencies, including the ones required for setup and test, in this virtual environment: pip install -e \".[setup,test]\" If everything worked fine, you should be able to start the server inside this virtual environment and with no errors shown in the logs: startleft server At this point, you have the project completely configured to start working with the IDE or editor you prefer. PyCharm/IntelliJ setup Open the project The project is already cloned and configured, so simply go to File > Open... and select the project folder. Configure the python interpreter As we have already configured a virtual environment, PyCharm will recognize it and propose it as the project interpreter: We only need to click on Configure a Python interpreter... and accept the proposed one. Import the run configurations Since StartLeft is a quite complex project with different commands and test sets that can be launched independently, a set of portable and preconfigured run configurations are provided. So, the final configuration step is to import them following the instructions detailed here and assure that you can execute StartLeft from your PyCharm. Architecture With your development environment ready, it is strongly advised to take a look to the architecture page to familiarize yourself with the different modules, including their relationships and common internal structure. This is specially relevant considering that forbidden imports between modules will remain in python collect errors that prevent StartLeft to start which can lead to confusion. Errors management In spite of the modularized architecture of StartLeft, the process of reading and parsing an input source and convert it into OTM has a set of fixed stages defined in the slp_base module. For each of these stages, there are a set of predefined errors that must be used in order to get coherent and descriptive errors in the REST API or CLI responses. All you need to know about the errors management is explained in the errors management page . Creating a new StartLeft Processor Once you have the environment in place and a general idea about the organization of the code, we can already take a look to the most common use cases for StartLeft contributions through the documented tutorials. A very interesting situation is when the user wants to make StartLeft support a new format. In that case, you will need to know the interfaces you need to implement and the minimal configuration to expose it through the CLI and the REST API. You can easily go through this creation process in this tutorial page .","title":"Quickstart Guide for Developers"},{"location":"development/Quickstart-Guide-for-Developers/#quickstart-guide-for-developers","text":"StartLeft is an Open Source project that welcomes collaborators to extend or improve its functionality. Despite the fact that it was born as an internal IriusRisk project, there are some characteristic that makes it specially suitable to grow through the contributions of the community: The nature of the project, whose natural functional escalation is based on the support of new, independent, source formats. The conversion into OTM is based on configuration files that can also be created independently depending on the expected OTM use. The modularized architecture enables collaborators to contribute to each format's processor without conflicts.","title":"Quickstart Guide for Developers"},{"location":"development/Quickstart-Guide-for-Developers/#how-to-contribute","text":"The IriusRisk team is currently the coordinator of the project and, ultimately, the responsible for validating the Pull Requests created by the collaborators. All you need to know before you start contributing is in the CONTRIBUTING.md file . Anyway, it is important to consider that, before creating your own fork or PR, you should check the open issues to ensure that there is none related with what you intend to do.","title":"How to contribute?"},{"location":"development/Quickstart-Guide-for-Developers/#set-up-the-environment","text":"There are no special requirements about a specific IDE or special steps to perform that make StartLeft different from any Python project. However, as PyCharm (or IntelliJ with the python plugin) is one of the most common python IDEs, some related utilities are provided.","title":"Set up the environment"},{"location":"development/Quickstart-Guide-for-Developers/#basic-configuration","text":"Regardless of the IDE you use, we can generalize the cloning of the project and the creation and configuration of the python virtual environment. First, we need to clone the project and move to its project: git clone https://github.com/iriusrisk/startleft.git cd startleft Then, let's create and activate a virtual environment for StartLeft: python3 -m venv ./venv source venv/bin/activate Now, install all the required dependencies, including the ones required for setup and test, in this virtual environment: pip install -e \".[setup,test]\" If everything worked fine, you should be able to start the server inside this virtual environment and with no errors shown in the logs: startleft server At this point, you have the project completely configured to start working with the IDE or editor you prefer.","title":"Basic configuration"},{"location":"development/Quickstart-Guide-for-Developers/#pycharmintellij-setup","text":"","title":"PyCharm/IntelliJ setup"},{"location":"development/Quickstart-Guide-for-Developers/#open-the-project","text":"The project is already cloned and configured, so simply go to File > Open... and select the project folder.","title":"Open the project"},{"location":"development/Quickstart-Guide-for-Developers/#configure-the-python-interpreter","text":"As we have already configured a virtual environment, PyCharm will recognize it and propose it as the project interpreter: We only need to click on Configure a Python interpreter... and accept the proposed one.","title":"Configure the python interpreter"},{"location":"development/Quickstart-Guide-for-Developers/#import-the-run-configurations","text":"Since StartLeft is a quite complex project with different commands and test sets that can be launched independently, a set of portable and preconfigured run configurations are provided. So, the final configuration step is to import them following the instructions detailed here and assure that you can execute StartLeft from your PyCharm.","title":"Import the run configurations"},{"location":"development/Quickstart-Guide-for-Developers/#architecture","text":"With your development environment ready, it is strongly advised to take a look to the architecture page to familiarize yourself with the different modules, including their relationships and common internal structure. This is specially relevant considering that forbidden imports between modules will remain in python collect errors that prevent StartLeft to start which can lead to confusion.","title":"Architecture"},{"location":"development/Quickstart-Guide-for-Developers/#errors-management","text":"In spite of the modularized architecture of StartLeft, the process of reading and parsing an input source and convert it into OTM has a set of fixed stages defined in the slp_base module. For each of these stages, there are a set of predefined errors that must be used in order to get coherent and descriptive errors in the REST API or CLI responses. All you need to know about the errors management is explained in the errors management page .","title":"Errors management"},{"location":"development/Quickstart-Guide-for-Developers/#creating-a-new-startleft-processor","text":"Once you have the environment in place and a general idea about the organization of the code, we can already take a look to the most common use cases for StartLeft contributions through the documented tutorials. A very interesting situation is when the user wants to make StartLeft support a new format. In that case, you will need to know the interfaces you need to implement and the minimal configuration to expose it through the CLI and the REST API. You can easily go through this creation process in this tutorial page .","title":"Creating a new StartLeft Processor"},{"location":"development/Run-Configurations/","text":"Run configurations Warning : This page only applies if you are using PyCharm or IntelliJ as IDE The easiest way to develop and test StartLeft is by using PyCharm\u2019s Run & debug configurations that references our IaC, diagrams and mapping files inside /examples project file. How to import? Since there are a bunch of different commands, modules and ways of using and testing StartLeft, you can import the run_configurations.zip file placed on the root of the repository. For that, manually unzip the file or, in Linux, execute the following command: unzip run_configurations.zip Then, a .run folder should be created in the root of the project with a bunch of xml files corresponding to each run configuration. The IDE should automatically process this folder and load all the configurations. Check the upper right corner of the window: How to use? Before going in depth into the different types of configurations and its organization, let's try a couple of basic commands. Execute version > [VERSION] and verify that something like this is shown: cli.py, version development-version Now, set up the server with the [SERVER] configuration, you should see the starting logs and be able to see the API docs in http://localhost:5000/docs . Finally, let's try the run configuration for running all the application tests executing the [ALL TESTS] run configuration. Then, the console must show all the tests which are being executed. How are they organized? Once imported all the run configuration will be available organized in the different levels explained below. Command launching The first group of run configurations that appears in the dropdown box is for launching the production code through the different commands supported by StartLeft. It is organized as follows. [SERVER] This is the most common used run/debug configuration, since it is the one used for launching the StartLeft\u2019s web service that exposes the REST API. It basically launches the StartLeft\u2019s server command. CLI commands Each CLI supported command has its own folder with several examples to be run with different parameters. The format for the name of these configurations is: [COMMAND][PROVIDER][USE CASE NAME] For example, to launch the parse command with the Cloudformation example for security groups, the run configuration is called: [PARSE][CFT][SECURITY GROUPS] [ALL TESTS] This is a special case of the run configurations. Since StartLeft contains a group of independent modules, the only way to launch all the tests for all the modules in a single command is having a python script with the logic to retrieve all these tests. This run configuration runs that script in order to execute all the tests for the whole repo. Test launching Tests have their own specific section of run configurations with the following subsections. Module tests Each StartLeft module has a run configuration to launch its tests. The naming for this run configurations is: [MODULE_NAME][TESTS] For instance, if we want to launch the tests for the Cloudformation SLP module, the run configuration is [SLP_CFT][TESTS] . [GLOBAL][TESTS] Apart from the module-specific tests, there is a group of global integration tests for the whole StartLeft that has its own launcher, called [GLOBAL][TESTS] . Do not confuse this run configuration with [ALL TESTS] , that runs all the tests, including the global ones as well as the tests for each module. Example files The provided run configurations contain only relative paths to files existent inside the StartLeft repository, so you should not need to change any parameter in the given run configurations. If so, this would be probably because some file has been renamed or deleted from the repository.","title":"Run Configurations"},{"location":"development/Run-Configurations/#run-configurations","text":"Warning : This page only applies if you are using PyCharm or IntelliJ as IDE The easiest way to develop and test StartLeft is by using PyCharm\u2019s Run & debug configurations that references our IaC, diagrams and mapping files inside /examples project file.","title":"Run configurations"},{"location":"development/Run-Configurations/#how-to-import","text":"Since there are a bunch of different commands, modules and ways of using and testing StartLeft, you can import the run_configurations.zip file placed on the root of the repository. For that, manually unzip the file or, in Linux, execute the following command: unzip run_configurations.zip Then, a .run folder should be created in the root of the project with a bunch of xml files corresponding to each run configuration. The IDE should automatically process this folder and load all the configurations. Check the upper right corner of the window:","title":"How to import?"},{"location":"development/Run-Configurations/#how-to-use","text":"Before going in depth into the different types of configurations and its organization, let's try a couple of basic commands. Execute version > [VERSION] and verify that something like this is shown: cli.py, version development-version Now, set up the server with the [SERVER] configuration, you should see the starting logs and be able to see the API docs in http://localhost:5000/docs . Finally, let's try the run configuration for running all the application tests executing the [ALL TESTS] run configuration. Then, the console must show all the tests which are being executed.","title":"How to use?"},{"location":"development/Run-Configurations/#how-are-they-organized","text":"Once imported all the run configuration will be available organized in the different levels explained below.","title":"How are they organized?"},{"location":"development/Run-Configurations/#command-launching","text":"The first group of run configurations that appears in the dropdown box is for launching the production code through the different commands supported by StartLeft. It is organized as follows.","title":"Command launching"},{"location":"development/Run-Configurations/#server","text":"This is the most common used run/debug configuration, since it is the one used for launching the StartLeft\u2019s web service that exposes the REST API. It basically launches the StartLeft\u2019s server command.","title":"[SERVER]"},{"location":"development/Run-Configurations/#cli-commands","text":"Each CLI supported command has its own folder with several examples to be run with different parameters. The format for the name of these configurations is: [COMMAND][PROVIDER][USE CASE NAME] For example, to launch the parse command with the Cloudformation example for security groups, the run configuration is called: [PARSE][CFT][SECURITY GROUPS]","title":"CLI commands"},{"location":"development/Run-Configurations/#all-tests","text":"This is a special case of the run configurations. Since StartLeft contains a group of independent modules, the only way to launch all the tests for all the modules in a single command is having a python script with the logic to retrieve all these tests. This run configuration runs that script in order to execute all the tests for the whole repo.","title":"[ALL TESTS]"},{"location":"development/Run-Configurations/#test-launching","text":"Tests have their own specific section of run configurations with the following subsections.","title":"Test launching"},{"location":"development/Run-Configurations/#module-tests","text":"Each StartLeft module has a run configuration to launch its tests. The naming for this run configurations is: [MODULE_NAME][TESTS] For instance, if we want to launch the tests for the Cloudformation SLP module, the run configuration is [SLP_CFT][TESTS] .","title":"Module tests"},{"location":"development/Run-Configurations/#globaltests","text":"Apart from the module-specific tests, there is a group of global integration tests for the whole StartLeft that has its own launcher, called [GLOBAL][TESTS] . Do not confuse this run configuration with [ALL TESTS] , that runs all the tests, including the global ones as well as the tests for each module.","title":"[GLOBAL][TESTS]"},{"location":"development/Run-Configurations/#example-files","text":"The provided run configurations contain only relative paths to files existent inside the StartLeft repository, so you should not need to change any parameter in the given run configurations. If so, this would be probably because some file has been renamed or deleted from the repository.","title":"Example files"},{"location":"integration/Quickstart-Guide-for-Integrations/","text":"Quickstart Guide for Integrations The final goal of StartLeft is being integrated within processes that requires the generation of a Threat Model. Examples of this are: A CI/CD pipeline for modifications in IaC files. A process for creating standardized Threat Models from infrastructure diagrams. A process for migrating Threat Models from one threat modeling tool to another. The more common scenario for these use cases is that they are automatized. For that, it is necessary that StartLeft can be used by another services or applications in a smooth way. The different ways of doing this are explained along this page. As a service This type of integration fits specially well when we need to integrate StartLeft with some application that requires OTM conversion features. For instance, IriusRisk provides importing endpoints for different sources that internally rely on a StartLeft service for generating an OTM as a common intermediate state: Notice that StartLeft is a stateless service. It requires neither authentication nor authorization since it does not access or stores personal information nor access other services. For this reason, the service is quite simple to deploy and operate. Deploy locally If you only want to experiment with the API, this is probably the simplest way. For that, you need to have StartLeft installed in your machine as explained in the Quickstart Guide for Beginners and execute the command: startleft server The server is started by default in the port 5000 , but you can configure it with the --port / -p modifier. startleft server --port 8080 Once you have your service started, you can check the API documentation in http://localhost:5000/docs . Deploy dockerized This is the most logical option for integration purposes, since it enables the service to be portable to any infrastructure. In the same StartLeft repository a ready-to-use Dockerfile is provided, so you already have what you need to set up your dockerized service. For trying it, let's clone the StartLeft repository: git clone https://github.com/iriusrisk/startleft.git Jump into the repo folder: cd startleft Optionally you can build the image for a specific version doing checkout of the correspondant release branch. For example, to generate an image for the version 1.5.0, you may execute: git checkout release/1.5.0 Now, we can create the StartLeft image: docker build . -f deployment/Dockerfile.docs.application.application -t startleft And, finally, we can run the docker container for the image we have just generated. Notice that you can select the port where the service is exposed in a standard Docker way. docker run -p 5000 :5000 startleft If everything works, you should see a log like this: INFO: Started server process [ 1 ] INFO: Waiting for application startup. INFO: Application startup complete. INFO: Uvicorn running on http://0.0.0.0:5000 ( Press CTRL+C to quit ) As in the local deployment, we can check that the service documentation is correctly located in http://localhost:5000/docs . Another way to verify the availability of the service is performing a request to the health endpoint, which can be done through a curl command like: curl localhost:5000/health This command should return: { \"status\" : \"OK\" , \"version\" : \"development-version\" , \"components\" : { \"StartLeft\" : \"OK\" } } For more details about how to use the StartLeft API, you can check the REST API page . Custom Dockerfile The Dockerfile provided should be enough for the most common integration scenarios, but, of course, it is possible to create a custom docker image for StartLeft. For that, you can take the existent Dockerfile available in the root of the StartLeft repository as a base. However, you must bear in mind that every official python image from the Docker Hub for versions over 3.6 should work, but: Depending on the base image, you may need to install additional libraries. Debian/Ubuntu based python official images present security vulnerabilities . This is the reason we decided to use the Alpine based one despite the fact it is significantly slower than others at building time. In batch processes The Command Line Interface enables users to easily create scripts for converting from different sources to OTM in batch, but also to perform other operations like validating files. To do that, you simply need to install StartLeft on your machine or create a StartLeft docker image able to read the scripts you want to process. Regarding the different functionalities available through the CLI and the REST API, it is important to consider that they do not have to necessarily match . For example, OTM or mappings validations are available through the validate command, but there are no REST endpoint for them. On the other hand, not all the formats can be converted into OTM through the parse CLI command, but all of them are supported in the REST API. These inconsistencies are expected to be solved in the short/medium term with a small impact, since the transformation logic and the access interfaces are already decoupled. Thus, if you have special interest in having some feature available through some interface, please raise an issue or create a fork following the Quickstart guide for developers . As modules as library (For future) StartLeft is a complete tool that exposes OTM conversion functionalities through different interfaces. However, it would be very useful for some customers to create their own python tools for parsing different formats to OTM without having to install and use a CLI or set up a REST API. As you can see in the Architecture page , each StartLeft module is an independent piece of software. Thus, releasing useful modules as the SLPs or the OTM module is currently under study . However, even though an advanced user could manage to install and use StartLeft as a library, it is not recommended because some related changes (like modules' visibility) that could break retro compatibility will probably need to be done. The final goal would be that, in the future , you could do something like this in your own python script: from slp_visio import VisioProcessor visio_processor = VisioProcessor ( project_id = 'sample-project-id' , project_name = 'sample-project-name' , source = open ( 'visio.vsdx' , 'r' ), mappings = [ open ( 'mapping.yaml' , 'r' )]) otm = visio_processor . process ()","title":"Quickstart Guide for Integrations"},{"location":"integration/Quickstart-Guide-for-Integrations/#quickstart-guide-for-integrations","text":"The final goal of StartLeft is being integrated within processes that requires the generation of a Threat Model. Examples of this are: A CI/CD pipeline for modifications in IaC files. A process for creating standardized Threat Models from infrastructure diagrams. A process for migrating Threat Models from one threat modeling tool to another. The more common scenario for these use cases is that they are automatized. For that, it is necessary that StartLeft can be used by another services or applications in a smooth way. The different ways of doing this are explained along this page.","title":"Quickstart Guide for Integrations"},{"location":"integration/Quickstart-Guide-for-Integrations/#as-a-service","text":"This type of integration fits specially well when we need to integrate StartLeft with some application that requires OTM conversion features. For instance, IriusRisk provides importing endpoints for different sources that internally rely on a StartLeft service for generating an OTM as a common intermediate state: Notice that StartLeft is a stateless service. It requires neither authentication nor authorization since it does not access or stores personal information nor access other services. For this reason, the service is quite simple to deploy and operate.","title":"As a service"},{"location":"integration/Quickstart-Guide-for-Integrations/#deploy-locally","text":"If you only want to experiment with the API, this is probably the simplest way. For that, you need to have StartLeft installed in your machine as explained in the Quickstart Guide for Beginners and execute the command: startleft server The server is started by default in the port 5000 , but you can configure it with the --port / -p modifier. startleft server --port 8080 Once you have your service started, you can check the API documentation in http://localhost:5000/docs .","title":"Deploy locally"},{"location":"integration/Quickstart-Guide-for-Integrations/#deploy-dockerized","text":"This is the most logical option for integration purposes, since it enables the service to be portable to any infrastructure. In the same StartLeft repository a ready-to-use Dockerfile is provided, so you already have what you need to set up your dockerized service. For trying it, let's clone the StartLeft repository: git clone https://github.com/iriusrisk/startleft.git Jump into the repo folder: cd startleft Optionally you can build the image for a specific version doing checkout of the correspondant release branch. For example, to generate an image for the version 1.5.0, you may execute: git checkout release/1.5.0 Now, we can create the StartLeft image: docker build . -f deployment/Dockerfile.docs.application.application -t startleft And, finally, we can run the docker container for the image we have just generated. Notice that you can select the port where the service is exposed in a standard Docker way. docker run -p 5000 :5000 startleft If everything works, you should see a log like this: INFO: Started server process [ 1 ] INFO: Waiting for application startup. INFO: Application startup complete. INFO: Uvicorn running on http://0.0.0.0:5000 ( Press CTRL+C to quit ) As in the local deployment, we can check that the service documentation is correctly located in http://localhost:5000/docs . Another way to verify the availability of the service is performing a request to the health endpoint, which can be done through a curl command like: curl localhost:5000/health This command should return: { \"status\" : \"OK\" , \"version\" : \"development-version\" , \"components\" : { \"StartLeft\" : \"OK\" } } For more details about how to use the StartLeft API, you can check the REST API page .","title":"Deploy dockerized"},{"location":"integration/Quickstart-Guide-for-Integrations/#custom-dockerfile","text":"The Dockerfile provided should be enough for the most common integration scenarios, but, of course, it is possible to create a custom docker image for StartLeft. For that, you can take the existent Dockerfile available in the root of the StartLeft repository as a base. However, you must bear in mind that every official python image from the Docker Hub for versions over 3.6 should work, but: Depending on the base image, you may need to install additional libraries. Debian/Ubuntu based python official images present security vulnerabilities . This is the reason we decided to use the Alpine based one despite the fact it is significantly slower than others at building time.","title":"Custom Dockerfile"},{"location":"integration/Quickstart-Guide-for-Integrations/#in-batch-processes","text":"The Command Line Interface enables users to easily create scripts for converting from different sources to OTM in batch, but also to perform other operations like validating files. To do that, you simply need to install StartLeft on your machine or create a StartLeft docker image able to read the scripts you want to process. Regarding the different functionalities available through the CLI and the REST API, it is important to consider that they do not have to necessarily match . For example, OTM or mappings validations are available through the validate command, but there are no REST endpoint for them. On the other hand, not all the formats can be converted into OTM through the parse CLI command, but all of them are supported in the REST API. These inconsistencies are expected to be solved in the short/medium term with a small impact, since the transformation logic and the access interfaces are already decoupled. Thus, if you have special interest in having some feature available through some interface, please raise an issue or create a fork following the Quickstart guide for developers .","title":"In batch processes"},{"location":"integration/Quickstart-Guide-for-Integrations/#as-modules-as-library-for-future","text":"StartLeft is a complete tool that exposes OTM conversion functionalities through different interfaces. However, it would be very useful for some customers to create their own python tools for parsing different formats to OTM without having to install and use a CLI or set up a REST API. As you can see in the Architecture page , each StartLeft module is an independent piece of software. Thus, releasing useful modules as the SLPs or the OTM module is currently under study . However, even though an advanced user could manage to install and use StartLeft as a library, it is not recommended because some related changes (like modules' visibility) that could break retro compatibility will probably need to be done. The final goal would be that, in the future , you could do something like this in your own python script: from slp_visio import VisioProcessor visio_processor = VisioProcessor ( project_id = 'sample-project-id' , project_name = 'sample-project-name' , source = open ( 'visio.vsdx' , 'r' ), mappings = [ open ( 'mapping.yaml' , 'r' )]) otm = visio_processor . process ()","title":"As modules as library (For future)"},{"location":"startleft-processors/diagram/Lucidchart-support/","text":"What is Lucidchart? From official Lucidchart page : Lucidchart is the intelligent diagramming application that brings teams together to make better decisions and build the future. Parsing particularities Lucidchart does not have its own extension for exporting. Instead of that, it enables their users to download their diagrams in several ways. One of them is VSDX, which is the Microsoft Visio format supported by StartLeft. All the Visio documentation about mapping and parsing logic applies for Lucidchart . However, there are a couple of considerations that are important to know. About the mappings: The structure of the mapping file is exactly the same that for the Microsoft Visio files. The stencils are different in Microsoft Visio and Lucidchart, so you need to compose different mappings for each of them. The internal name of the Lucidchart stencil shapes does not match the one shown in the application. In the mapping file provided in the StartLeft examples folder, you can find a list of AWS components' internal names. About the parsing logic: Boundary TrustZones are not currently supported for Lucidchart. Dataflows are calculated based on their position, what means that they do not necessarily need to touch origin or target shapes, but they have some tolerance. An example In this example, we can see a Lucidchart diagram which includes different types of elements. Generic shapes like the Internet TrustZone or the Custom VPC . Generic stencil shapes like the Client and the Mobile client . AWS stencil shapes like the Amazon CloudWatch or the Amazon EC2 . Azure stencil shapes like the SQLDatabaseAzure2021 . Several dataflows among the shapes. Notice also that all the components in the diagram are nested inside others. All of them belong to a TrustZone, but, for example, the Amazon EC2 is also nested inside the Custom VPC . This hierarchy, as is done for Microsoft Visio, will be respected in the resultant OTM. If we compose a default mapping file for all the stencil shapes: default-mapping.yaml trustzones : - label : Public Cloud type : Public Cloud id : b61d6911-338d-46a8-9f39-8dcd24abfe91 - label : Private Secured Cloud type : Private Secured id : 2ab4effa-40b7-4cd2-ba81-8247d29a6f2d - label : AWSCloudAWS2021 type : Public Cloud id : b61d6911-338d-46a8-9f39-8dcd24abfe91 components : ## Visio Lucid names - label : ClientAWS19 type : generic-client - label : AmazonCognitoAWS19 type : cognito - label : AmazonEC2AWS2021 type : ec2 - label : SQLDatabaseAzure2021 type : CD-MICROSOFT-AZURE-SQL-DB - label : DatabaseBlock type : other-database - label : AmazonSimpleStorageServiceS3AWS19 type : s3 - label : AWSIdentityandAccessManagement_IAMAWS19 type : iam - label : AWSCloudTrailAWS19 type : cloudtrail - label : AWSCloudTrailAWS2021 type : cloudtrail - label : AmazonAPIGateway_purpleAWS19 type : api-gateway - label : AWSGeneral_UserAWS19 type : empty-component - label : ImageSearchBlock2 type : empty-component - label : ElasticLoadBalancingELLoadBalancer2017 type : empty-component - label : AmazonEC2AutoScalingAWS2021 type : empty-component - label : AWSFargateAWS19 type : empty-component - label : AmazonDynamoDBAWS19 type : empty-component - label : AWSCertificateManagerAWS19 type : empty-component - label : AWSCodePipelineAWS19 type : empty-component - label : AWSCodeBuildAWS19 type : empty-component - label : AmazonCloudWatchAWS19 type : cloudwatch - label : AmazonCloudWatchAWS2021 type : cloudwatch - label : AWSCodeStarAWS19 type : empty-component - label : AmazonECR2017 type : empty-component dataflows : [ ] Then, we can map the generic shapes by name in a custom mapping file: custom-mapping.yaml trustzones : - label : Internet type : internet id : f0ba7722-39b6-4c81-8290-a30a248bb8d9 components : - label : Web browser type : generic-client - label : Android type : android-device-client dataflows : [] The expected result for this case should be an OTM like this: lucidchart.otm { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"Lucid Example\" , \"id\" : \"lucid-example\" }, \"representations\" : [{ \"name\" : \"Visio\" , \"id\" : \"Visio\" , \"type\" : \"diagram\" , \"size\" : { \"width\" : 1000 , \"height\" : 1000 } }], \"trustZones\" : [{ \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"name\" : \"Public Cloud\" , \"risk\" : { \"trustRating\" : 10 } }, { \"id\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" , \"name\" : \"Private Secured Cloud\" , \"risk\" : { \"trustRating\" : 10 } }, { \"id\" : \"f0ba7722-39b6-4c81-8290-a30a248bb8d9\" , \"name\" : \"Internet\" , \"risk\" : { \"trustRating\" : 10 } }], \"components\" : [{ \"id\" : \"7\" , \"name\" : \"Custom VPC\" , \"type\" : \"empty-component\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\" : \"9\" , \"name\" : \"My EC2\" , \"type\" : \"ec2\" , \"parent\" : { \"component\" : \"7\" } }, { \"id\" : \"12\" , \"name\" : \"My CloudWatch\" , \"type\" : \"cloudwatch\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\" : \"17\" , \"name\" : \"My API Gateway\" , \"type\" : \"api-gateway\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\" : \"26\" , \"name\" : \"My CloudTrail\" , \"type\" : \"cloudtrail\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\" : \"29\" , \"name\" : \"My Simple Storage Service (S3)\" , \"type\" : \"s3\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\" : \"38\" , \"name\" : \"Web browser\" , \"type\" : \"generic-client\" , \"parent\" : { \"trustZone\" : \"f0ba7722-39b6-4c81-8290-a30a248bb8d9\" } }, { \"id\" : \"44\" , \"name\" : \"Android\" , \"type\" : \"android-device-client\" , \"parent\" : { \"trustZone\" : \"f0ba7722-39b6-4c81-8290-a30a248bb8d9\" } }, { \"id\" : \"47\" , \"name\" : \"SQL Database\" , \"type\" : \"CD-MICROSOFT-AZURE-SQL-DB\" , \"parent\" : { \"trustZone\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" } }, { \"id\" : \"53\" , \"name\" : \"My DynamoDB\" , \"type\" : \"dynamodb\" , \"parent\" : { \"trustZone\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" } }], \"dataflows\" : [{ \"id\" : \"32\" , \"name\" : \"EC2 Logs\" , \"source\" : \"9\" , \"destination\" : \"12\" }, { \"id\" : \"33\" , \"name\" : \"GW/EC2\" , \"source\" : \"17\" , \"destination\" : \"9\" }, { \"id\" : \"34\" , \"name\" : \"Log trace\" , \"source\" : \"17\" , \"destination\" : \"26\" }, { \"id\" : \"35\" , \"name\" : \"Customer data\" , \"source\" : \"17\" , \"destination\" : \"29\" }, { \"id\" : \"43\" , \"name\" : \"f7ef1b0f-2a7a-4822-9aa8-59affc9bf309\" , \"source\" : \"38\" , \"destination\" : \"17\" }, { \"id\" : \"46\" , \"name\" : \"114deaf6-bb2d-407a-a68a-1fccb3d56ed7\" , \"source\" : \"44\" , \"destination\" : \"17\" }, { \"id\" : \"56\" , \"name\" : \"User data\" , \"source\" : \"17\" , \"destination\" : \"53\" }, { \"id\" : \"57\" , \"name\" : \"App data\" , \"source\" : \"17\" , \"destination\" : \"47\" }] } That imported in a tool like IriusRisk looks like this: cURL To try this example on your machine, first, you need to put in place the necessary files: Download the Lucidchart example above from here . Save the default mapping above with the name default-mapping.yaml . Save the custom mapping above with the name custom-mapping.yaml . Finally, execute the following command to retrieve the OTM file: curl --location --request POST localhost:5000/api/v1/startleft/diagram \\ --header \"Content-Type: multipart/form-data\" \\ --header \"Accept: application/json\" \\ --form diag_type = \"LUCID\" \\ --form diag_file = @ \"./lucid-aws-with-tz-and-vpc.vsdx\" \\ --form default_mapping_file = @ \"./default-mapping.yaml\" \\ --form custom_mapping_file = @ \"./custom-mapping.yaml\" \\ --form id = \"my-lucidchart-example\" \\ --form name = \"My Lucidchart Example\" Command line usage You can also use the Command Line option for this example, with the files downloaded in the previous section. Make sure StartLeft is properly installed and execute the following command: startleft parse \\ --diagram-type LUCID \\ --default-mapping-file ./default-mapping.yaml \\ --custom-mapping-file ./custom-mapping.yaml \\ --output-file my-lucidchart-cli-example.otm \\ --project-name \"My Lucidchart CLI Example\" \\ --project-id \"my-lucidchart-cli-example\" \\ ./lucid-aws-with-tz-and-vpc.vsdx","title":"Lucidchart Support"},{"location":"startleft-processors/diagram/Lucidchart-support/#what-is-lucidchart","text":"From official Lucidchart page : Lucidchart is the intelligent diagramming application that brings teams together to make better decisions and build the future.","title":"What is Lucidchart?"},{"location":"startleft-processors/diagram/Lucidchart-support/#parsing-particularities","text":"Lucidchart does not have its own extension for exporting. Instead of that, it enables their users to download their diagrams in several ways. One of them is VSDX, which is the Microsoft Visio format supported by StartLeft. All the Visio documentation about mapping and parsing logic applies for Lucidchart . However, there are a couple of considerations that are important to know. About the mappings: The structure of the mapping file is exactly the same that for the Microsoft Visio files. The stencils are different in Microsoft Visio and Lucidchart, so you need to compose different mappings for each of them. The internal name of the Lucidchart stencil shapes does not match the one shown in the application. In the mapping file provided in the StartLeft examples folder, you can find a list of AWS components' internal names. About the parsing logic: Boundary TrustZones are not currently supported for Lucidchart. Dataflows are calculated based on their position, what means that they do not necessarily need to touch origin or target shapes, but they have some tolerance.","title":"Parsing particularities"},{"location":"startleft-processors/diagram/Lucidchart-support/#an-example","text":"In this example, we can see a Lucidchart diagram which includes different types of elements. Generic shapes like the Internet TrustZone or the Custom VPC . Generic stencil shapes like the Client and the Mobile client . AWS stencil shapes like the Amazon CloudWatch or the Amazon EC2 . Azure stencil shapes like the SQLDatabaseAzure2021 . Several dataflows among the shapes. Notice also that all the components in the diagram are nested inside others. All of them belong to a TrustZone, but, for example, the Amazon EC2 is also nested inside the Custom VPC . This hierarchy, as is done for Microsoft Visio, will be respected in the resultant OTM. If we compose a default mapping file for all the stencil shapes: default-mapping.yaml trustzones : - label : Public Cloud type : Public Cloud id : b61d6911-338d-46a8-9f39-8dcd24abfe91 - label : Private Secured Cloud type : Private Secured id : 2ab4effa-40b7-4cd2-ba81-8247d29a6f2d - label : AWSCloudAWS2021 type : Public Cloud id : b61d6911-338d-46a8-9f39-8dcd24abfe91 components : ## Visio Lucid names - label : ClientAWS19 type : generic-client - label : AmazonCognitoAWS19 type : cognito - label : AmazonEC2AWS2021 type : ec2 - label : SQLDatabaseAzure2021 type : CD-MICROSOFT-AZURE-SQL-DB - label : DatabaseBlock type : other-database - label : AmazonSimpleStorageServiceS3AWS19 type : s3 - label : AWSIdentityandAccessManagement_IAMAWS19 type : iam - label : AWSCloudTrailAWS19 type : cloudtrail - label : AWSCloudTrailAWS2021 type : cloudtrail - label : AmazonAPIGateway_purpleAWS19 type : api-gateway - label : AWSGeneral_UserAWS19 type : empty-component - label : ImageSearchBlock2 type : empty-component - label : ElasticLoadBalancingELLoadBalancer2017 type : empty-component - label : AmazonEC2AutoScalingAWS2021 type : empty-component - label : AWSFargateAWS19 type : empty-component - label : AmazonDynamoDBAWS19 type : empty-component - label : AWSCertificateManagerAWS19 type : empty-component - label : AWSCodePipelineAWS19 type : empty-component - label : AWSCodeBuildAWS19 type : empty-component - label : AmazonCloudWatchAWS19 type : cloudwatch - label : AmazonCloudWatchAWS2021 type : cloudwatch - label : AWSCodeStarAWS19 type : empty-component - label : AmazonECR2017 type : empty-component dataflows : [ ] Then, we can map the generic shapes by name in a custom mapping file: custom-mapping.yaml trustzones : - label : Internet type : internet id : f0ba7722-39b6-4c81-8290-a30a248bb8d9 components : - label : Web browser type : generic-client - label : Android type : android-device-client dataflows : [] The expected result for this case should be an OTM like this: lucidchart.otm { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"Lucid Example\" , \"id\" : \"lucid-example\" }, \"representations\" : [{ \"name\" : \"Visio\" , \"id\" : \"Visio\" , \"type\" : \"diagram\" , \"size\" : { \"width\" : 1000 , \"height\" : 1000 } }], \"trustZones\" : [{ \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"name\" : \"Public Cloud\" , \"risk\" : { \"trustRating\" : 10 } }, { \"id\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" , \"name\" : \"Private Secured Cloud\" , \"risk\" : { \"trustRating\" : 10 } }, { \"id\" : \"f0ba7722-39b6-4c81-8290-a30a248bb8d9\" , \"name\" : \"Internet\" , \"risk\" : { \"trustRating\" : 10 } }], \"components\" : [{ \"id\" : \"7\" , \"name\" : \"Custom VPC\" , \"type\" : \"empty-component\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\" : \"9\" , \"name\" : \"My EC2\" , \"type\" : \"ec2\" , \"parent\" : { \"component\" : \"7\" } }, { \"id\" : \"12\" , \"name\" : \"My CloudWatch\" , \"type\" : \"cloudwatch\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\" : \"17\" , \"name\" : \"My API Gateway\" , \"type\" : \"api-gateway\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\" : \"26\" , \"name\" : \"My CloudTrail\" , \"type\" : \"cloudtrail\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\" : \"29\" , \"name\" : \"My Simple Storage Service (S3)\" , \"type\" : \"s3\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\" : \"38\" , \"name\" : \"Web browser\" , \"type\" : \"generic-client\" , \"parent\" : { \"trustZone\" : \"f0ba7722-39b6-4c81-8290-a30a248bb8d9\" } }, { \"id\" : \"44\" , \"name\" : \"Android\" , \"type\" : \"android-device-client\" , \"parent\" : { \"trustZone\" : \"f0ba7722-39b6-4c81-8290-a30a248bb8d9\" } }, { \"id\" : \"47\" , \"name\" : \"SQL Database\" , \"type\" : \"CD-MICROSOFT-AZURE-SQL-DB\" , \"parent\" : { \"trustZone\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" } }, { \"id\" : \"53\" , \"name\" : \"My DynamoDB\" , \"type\" : \"dynamodb\" , \"parent\" : { \"trustZone\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" } }], \"dataflows\" : [{ \"id\" : \"32\" , \"name\" : \"EC2 Logs\" , \"source\" : \"9\" , \"destination\" : \"12\" }, { \"id\" : \"33\" , \"name\" : \"GW/EC2\" , \"source\" : \"17\" , \"destination\" : \"9\" }, { \"id\" : \"34\" , \"name\" : \"Log trace\" , \"source\" : \"17\" , \"destination\" : \"26\" }, { \"id\" : \"35\" , \"name\" : \"Customer data\" , \"source\" : \"17\" , \"destination\" : \"29\" }, { \"id\" : \"43\" , \"name\" : \"f7ef1b0f-2a7a-4822-9aa8-59affc9bf309\" , \"source\" : \"38\" , \"destination\" : \"17\" }, { \"id\" : \"46\" , \"name\" : \"114deaf6-bb2d-407a-a68a-1fccb3d56ed7\" , \"source\" : \"44\" , \"destination\" : \"17\" }, { \"id\" : \"56\" , \"name\" : \"User data\" , \"source\" : \"17\" , \"destination\" : \"53\" }, { \"id\" : \"57\" , \"name\" : \"App data\" , \"source\" : \"17\" , \"destination\" : \"47\" }] } That imported in a tool like IriusRisk looks like this:","title":"An example"},{"location":"startleft-processors/diagram/Lucidchart-support/#curl","text":"To try this example on your machine, first, you need to put in place the necessary files: Download the Lucidchart example above from here . Save the default mapping above with the name default-mapping.yaml . Save the custom mapping above with the name custom-mapping.yaml . Finally, execute the following command to retrieve the OTM file: curl --location --request POST localhost:5000/api/v1/startleft/diagram \\ --header \"Content-Type: multipart/form-data\" \\ --header \"Accept: application/json\" \\ --form diag_type = \"LUCID\" \\ --form diag_file = @ \"./lucid-aws-with-tz-and-vpc.vsdx\" \\ --form default_mapping_file = @ \"./default-mapping.yaml\" \\ --form custom_mapping_file = @ \"./custom-mapping.yaml\" \\ --form id = \"my-lucidchart-example\" \\ --form name = \"My Lucidchart Example\"","title":"cURL"},{"location":"startleft-processors/diagram/Lucidchart-support/#command-line-usage","text":"You can also use the Command Line option for this example, with the files downloaded in the previous section. Make sure StartLeft is properly installed and execute the following command: startleft parse \\ --diagram-type LUCID \\ --default-mapping-file ./default-mapping.yaml \\ --custom-mapping-file ./custom-mapping.yaml \\ --output-file my-lucidchart-cli-example.otm \\ --project-name \"My Lucidchart CLI Example\" \\ --project-id \"my-lucidchart-cli-example\" \\ ./lucid-aws-with-tz-and-vpc.vsdx","title":"Command line usage"},{"location":"startleft-processors/diagram/Visio-Mapping/","text":"The greatest challenge when mapping Microsoft Visio files is that it is a completely open format where the user can place whatever they want. For that reason, the slp_visio works with some premises in order to build an OTM file with only the necessary information: There are different ways of parsing TrustZones, but only the default TrustZone will be generated if no Trustzone appears in any of the mapping files. The only shapes that will be parsed into the OTM components are the ones whose name or type matches some label in the mapping file. The rest of them will be ignored. There is no need to create mappings for the DataFlows, they will be generated from those Visio connectors that link components that have also been mapped into the OTM. Nested shapes are automatically processed and parsed to the OTM components and TrustZones. There is no need to define parent relationships in the mapping files. Mapping hierarchy The StartLeft's Visio SLP support two types of mapping files. They both have exactly the same structure and behavior, but are intended to be used for different types of mappings. Default mapping file As stated in the Visio Quickstart , stencils are a powerful Visio feature. From the point of view of StartLeft, those users that use them in their diagrams may reduce a lot the work they have to do in order to build their mappings. This is because the mappings for the stencils can be reused across every request to StartLeft and does not need to be created each time. Other potential case or mappings reuse are the generic TrustZones. Even if you may have some diagrams with specific TrustZones, it is a common case to have a fistful of them that tend to be present in most of your diagrams. Thus, you should not need to map them again and again. In conclusion, for all those elements that you do not want to map in each request because are common and reusable, you can build a default mapping file. Indeed, if you are going to use StartLeft in a script or pipeline, you can simply save the default mapping file and inject it in every StartLeft request. That is, for example, how IriusRisk's import processes work. Custom mapping file This file is used to cover the rest of elements that are not generic, but specific to a concrete diagram. Remember that only the shapes whose type or name are in the mapping file will be parsed into the OTM so, everything you need to be processed in a Visio file should be in the default or in the custom mapping file. In case the same mapping appears in both mapping files, the one in the custom file takes preference . Mapping file structure The Visio mapping file is expected to be a YAML file whose structure is exactly defined by its json schema . It is divided in three great blocks described in depth below. So, the root structure of the file is composed by three arrays for the mappings of each type of element: trustzones : [] components : [] dataflows : [] Each of these arrays contains the information for mapping shapes into TrustZones, Components or Dataflows, respectively. Also note that all three are mandatory and have to be included in each mapping file, even if they only contain an empty array. Mapping TrustZones The OTM standard defines that every component in the threat model must have a parent, so you must make sure that the mapping file contains a mapping entry for all the TrustZones present in the diagram as well as a default one so, if no parent can be calculated for a component, it can fall into this default TrustZone. trustzones : - label : My Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 When a shape is found in the Visio file whose name matches the mapping's label , then a TrustZone is created with these OTM Trustzone fields: - id is the original id in the Visio file - name is the original name in the Visio file - type is the type in the mapping file For example, for this TrustZone in the Visio file and the previous mapping: The resultant OTM would contain a TrustZone like this: { \"trustZones\" : [ { \"id\" : \"47\" , \"name\" : \"My Public Cloud\" , \"type\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"risk\" : { \"trustRating\" : 10 } } ] } Default Trustzone The components in the Visio file that there aren't inside a trust zone will be assigned to the default trust zone. We can define the default trust zone in the mapping file by this way: trustzones : - label : My Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 - label : My Private Secured type : 2ab4effa-40b7-4cd2-ba81-8247d29a6f2d - label : Internet type : f0ba7722-39b6-4c81-8290-a30a248bb8d9 default : true Let's see an example In this example \"My EC2\" will have \"My Public Cloud\" as parent, \"My DynamoDB\" will have \"My Private Secured\" as parent, and the \"Android Client\" will have the \"Internet\" parent defined in the mapping file as default trust zone. So the OTM would be like this: { \"trustZones\" : [ { \"id\" : \"47\" , \"name\" : \"My Public Cloud\" , \"type\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"risk\" : { \"trustRating\" : 10 } }, { \"id\" : \"48\" , \"name\" : \"My Private Secured\" , \"type\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" , \"risk\" : { \"trustRating\" : 10 } }, { \"id\" : \"39388080-e23b-4e16-976a-27f2f086dc0e\" , \"name\" : \"Internet\" , \"type\" : \"f0ba7722-39b6-4c81-8290-a30a248bb8d9\" , \"risk\" : { \"trustRating\" : 10 }, \"properties\" : { \"default\" : true } } ], \"components\" : [ { \"id\" : \"54\" , \"name\" : \"My EC2\" , \"type\" : \"ec2\" , \"parent\" : { \"trustZone\" : \"47\" } }, { \"id\" : \"59\" , \"name\" : \"My DynamoDB\" , \"type\" : \"dynamodb\" , \"parent\" : { \"trustZone\" : \"48\" } }, { \"id\" : \"66\" , \"name\" : \"Android Client\" , \"type\" : \"android-client\" , \"parent\" : { \"trustZone\" : \"39388080-e23b-4e16-976a-27f2f086dc0e\" } } ], \"dataflows\" : [] } Note that the Internet id is autogenerated unlike the other trust zones present in the Visio file, which id comes from the id in the Visio file Due to a backward compatibility StartLeft accepts as well the legacy mapping file format. Please read Legacy-Mapping-File-Format Default TrustZone not defined Since it must necessarily have one trust zone, if any trust zone is defined as default in the mapping file the Public Cloud will always be the default one . These are the basics for the TrustZone mapping behavior, but TrustZones may be defined in different and more complex ways that are explained in deep in the TrustZones mapping's page . Mapping Components Components mappings' structure is similar to the TrustZones. For example, we can have a mapping like this: components : - label : Shape's name type : OTM's type However, its behavior presents the particularity that the label may refer to the type or the name of the shape. For instance, suppose we have this diagram: Considering that the My EC2 shape belongs to the AWS stencils, the more logical scenario is mapping it by type in the default mapping file. For that, you have to use its name in the stencil, that is the one you can see in Visio when you select the shape: With this, you may compose a mapping like this: components : - label : Amazon EC2 type : ec2 That will result in an OTM component like this: { // The ID is the unique id got from the Visio file \"id\" : \"1\" , \"name\" : \"My EC2\" , \"type\" : \"ec2\" , \"parent\" : { // The parent is the default TrustZone \"component\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } } For the My Custom Machine component, you need to map by name instead of type, so we can create a custom mapping file with this content: components : - label : My Custom Machine type : empty-component The resulting OTM would be: { // The ID is the unique id got from the Visio file \"id\" : \"2\" , \"name\" : \"My Custom Machine\" , \"type\" : \"empty-component\" , \"parent\" : { // The parent is the default TrustZone \"component\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } } It is important to notice that mapping by name has priority over mapping by type . So if you include mappings in both mapping files for the My EC2 component like this: // In the default mapping file components : - label : Amazon EC2 type : ec2 // In the custom mapping file components : - label : My EC2 type : empty-component It would result in a OTM like this: { // The ID is the unique id got from the Visio file \"id\" : \"1\" , \"name\" : \"My EC2\" , \"type\" : \"empty-component\" , \"parent\" : { // The parent is the default TrustZone \"component\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } } Finally, as seen in the following picture, there are certain stencils that, despite representing different components, share the same type. In this example, one is Amazon Redshift for AWS Analytics, and the other one for AWS Databases. In case both stencils appear in the diagram, an internal identifier called UniqueID can optionally be used to differentiate them. This way, they can be mapped to different components in the following manner: components : - label : Amazon Redshift id : 0508F4C7-001F-0000-8E40-00608CF305B2 type : redshift - label : Amazon Redshift id : 0509DF75-001B-0000-8E40-00608CF305B2 type : empty-component Note Note that mapping by UniqueID has priority over both, mapping by name and mapping by type, but the label must still be correct. The resulting OTM will be as follows: { \"components\" : [ { \"id\" : \"1\" , \"name\" : \"Amazon Redshift\" , \"type\" : \"empty-component\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\" : \"13\" , \"name\" : \"Amazon Redshift\" , \"type\" : \"redshift\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } } ] } How to find the UniqueID of a stencil Being UniqueID an internal property, finding the value for a specific component is not straightforward. The easiest way is creating a diagram with only the desired stencil, and extracting the contents of the .vsdx file with any file archiver that supports the ZIP format. From the root of the extracted files and folders, it is possible to navigate to the visio/masters subfolders and open the masters.xml file, where the name of the stencil and its UniqueID appears. More info in the official Microsoft documentation . Mapping DataFlows Despite the fact that a dataflows tag is already defined in the mapping file structure, and it is required by the schema, the DataFlows mapping process is fixed and not configurable. Basically, it takes all the arrows in the Visio source that connect components that are mapped and create a DataFlow for them. If some arrow connects shapes that are not mapped, the DataFlow is not created. This can be easily understood with the following picture:","title":"Visio Mapping"},{"location":"startleft-processors/diagram/Visio-Mapping/#mapping-hierarchy","text":"The StartLeft's Visio SLP support two types of mapping files. They both have exactly the same structure and behavior, but are intended to be used for different types of mappings.","title":"Mapping hierarchy"},{"location":"startleft-processors/diagram/Visio-Mapping/#default-mapping-file","text":"As stated in the Visio Quickstart , stencils are a powerful Visio feature. From the point of view of StartLeft, those users that use them in their diagrams may reduce a lot the work they have to do in order to build their mappings. This is because the mappings for the stencils can be reused across every request to StartLeft and does not need to be created each time. Other potential case or mappings reuse are the generic TrustZones. Even if you may have some diagrams with specific TrustZones, it is a common case to have a fistful of them that tend to be present in most of your diagrams. Thus, you should not need to map them again and again. In conclusion, for all those elements that you do not want to map in each request because are common and reusable, you can build a default mapping file. Indeed, if you are going to use StartLeft in a script or pipeline, you can simply save the default mapping file and inject it in every StartLeft request. That is, for example, how IriusRisk's import processes work.","title":"Default mapping file"},{"location":"startleft-processors/diagram/Visio-Mapping/#custom-mapping-file","text":"This file is used to cover the rest of elements that are not generic, but specific to a concrete diagram. Remember that only the shapes whose type or name are in the mapping file will be parsed into the OTM so, everything you need to be processed in a Visio file should be in the default or in the custom mapping file. In case the same mapping appears in both mapping files, the one in the custom file takes preference .","title":"Custom mapping file"},{"location":"startleft-processors/diagram/Visio-Mapping/#mapping-file-structure","text":"The Visio mapping file is expected to be a YAML file whose structure is exactly defined by its json schema . It is divided in three great blocks described in depth below. So, the root structure of the file is composed by three arrays for the mappings of each type of element: trustzones : [] components : [] dataflows : [] Each of these arrays contains the information for mapping shapes into TrustZones, Components or Dataflows, respectively. Also note that all three are mandatory and have to be included in each mapping file, even if they only contain an empty array.","title":"Mapping file structure"},{"location":"startleft-processors/diagram/Visio-Mapping/#mapping-trustzones","text":"The OTM standard defines that every component in the threat model must have a parent, so you must make sure that the mapping file contains a mapping entry for all the TrustZones present in the diagram as well as a default one so, if no parent can be calculated for a component, it can fall into this default TrustZone. trustzones : - label : My Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 When a shape is found in the Visio file whose name matches the mapping's label , then a TrustZone is created with these OTM Trustzone fields: - id is the original id in the Visio file - name is the original name in the Visio file - type is the type in the mapping file For example, for this TrustZone in the Visio file and the previous mapping: The resultant OTM would contain a TrustZone like this: { \"trustZones\" : [ { \"id\" : \"47\" , \"name\" : \"My Public Cloud\" , \"type\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"risk\" : { \"trustRating\" : 10 } } ] }","title":"Mapping TrustZones"},{"location":"startleft-processors/diagram/Visio-Mapping/#default-trustzone","text":"The components in the Visio file that there aren't inside a trust zone will be assigned to the default trust zone. We can define the default trust zone in the mapping file by this way: trustzones : - label : My Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 - label : My Private Secured type : 2ab4effa-40b7-4cd2-ba81-8247d29a6f2d - label : Internet type : f0ba7722-39b6-4c81-8290-a30a248bb8d9 default : true Let's see an example In this example \"My EC2\" will have \"My Public Cloud\" as parent, \"My DynamoDB\" will have \"My Private Secured\" as parent, and the \"Android Client\" will have the \"Internet\" parent defined in the mapping file as default trust zone. So the OTM would be like this: { \"trustZones\" : [ { \"id\" : \"47\" , \"name\" : \"My Public Cloud\" , \"type\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"risk\" : { \"trustRating\" : 10 } }, { \"id\" : \"48\" , \"name\" : \"My Private Secured\" , \"type\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" , \"risk\" : { \"trustRating\" : 10 } }, { \"id\" : \"39388080-e23b-4e16-976a-27f2f086dc0e\" , \"name\" : \"Internet\" , \"type\" : \"f0ba7722-39b6-4c81-8290-a30a248bb8d9\" , \"risk\" : { \"trustRating\" : 10 }, \"properties\" : { \"default\" : true } } ], \"components\" : [ { \"id\" : \"54\" , \"name\" : \"My EC2\" , \"type\" : \"ec2\" , \"parent\" : { \"trustZone\" : \"47\" } }, { \"id\" : \"59\" , \"name\" : \"My DynamoDB\" , \"type\" : \"dynamodb\" , \"parent\" : { \"trustZone\" : \"48\" } }, { \"id\" : \"66\" , \"name\" : \"Android Client\" , \"type\" : \"android-client\" , \"parent\" : { \"trustZone\" : \"39388080-e23b-4e16-976a-27f2f086dc0e\" } } ], \"dataflows\" : [] } Note that the Internet id is autogenerated unlike the other trust zones present in the Visio file, which id comes from the id in the Visio file Due to a backward compatibility StartLeft accepts as well the legacy mapping file format. Please read Legacy-Mapping-File-Format","title":"Default Trustzone"},{"location":"startleft-processors/diagram/Visio-Mapping/#default-trustzone-not-defined","text":"Since it must necessarily have one trust zone, if any trust zone is defined as default in the mapping file the Public Cloud will always be the default one . These are the basics for the TrustZone mapping behavior, but TrustZones may be defined in different and more complex ways that are explained in deep in the TrustZones mapping's page .","title":"Default TrustZone not defined"},{"location":"startleft-processors/diagram/Visio-Mapping/#mapping-components","text":"Components mappings' structure is similar to the TrustZones. For example, we can have a mapping like this: components : - label : Shape's name type : OTM's type However, its behavior presents the particularity that the label may refer to the type or the name of the shape. For instance, suppose we have this diagram: Considering that the My EC2 shape belongs to the AWS stencils, the more logical scenario is mapping it by type in the default mapping file. For that, you have to use its name in the stencil, that is the one you can see in Visio when you select the shape: With this, you may compose a mapping like this: components : - label : Amazon EC2 type : ec2 That will result in an OTM component like this: { // The ID is the unique id got from the Visio file \"id\" : \"1\" , \"name\" : \"My EC2\" , \"type\" : \"ec2\" , \"parent\" : { // The parent is the default TrustZone \"component\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } } For the My Custom Machine component, you need to map by name instead of type, so we can create a custom mapping file with this content: components : - label : My Custom Machine type : empty-component The resulting OTM would be: { // The ID is the unique id got from the Visio file \"id\" : \"2\" , \"name\" : \"My Custom Machine\" , \"type\" : \"empty-component\" , \"parent\" : { // The parent is the default TrustZone \"component\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } } It is important to notice that mapping by name has priority over mapping by type . So if you include mappings in both mapping files for the My EC2 component like this: // In the default mapping file components : - label : Amazon EC2 type : ec2 // In the custom mapping file components : - label : My EC2 type : empty-component It would result in a OTM like this: { // The ID is the unique id got from the Visio file \"id\" : \"1\" , \"name\" : \"My EC2\" , \"type\" : \"empty-component\" , \"parent\" : { // The parent is the default TrustZone \"component\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } } Finally, as seen in the following picture, there are certain stencils that, despite representing different components, share the same type. In this example, one is Amazon Redshift for AWS Analytics, and the other one for AWS Databases. In case both stencils appear in the diagram, an internal identifier called UniqueID can optionally be used to differentiate them. This way, they can be mapped to different components in the following manner: components : - label : Amazon Redshift id : 0508F4C7-001F-0000-8E40-00608CF305B2 type : redshift - label : Amazon Redshift id : 0509DF75-001B-0000-8E40-00608CF305B2 type : empty-component Note Note that mapping by UniqueID has priority over both, mapping by name and mapping by type, but the label must still be correct. The resulting OTM will be as follows: { \"components\" : [ { \"id\" : \"1\" , \"name\" : \"Amazon Redshift\" , \"type\" : \"empty-component\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\" : \"13\" , \"name\" : \"Amazon Redshift\" , \"type\" : \"redshift\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } } ] } How to find the UniqueID of a stencil Being UniqueID an internal property, finding the value for a specific component is not straightforward. The easiest way is creating a diagram with only the desired stencil, and extracting the contents of the .vsdx file with any file archiver that supports the ZIP format. From the root of the extracted files and folders, it is possible to navigate to the visio/masters subfolders and open the masters.xml file, where the name of the stencil and its UniqueID appears. More info in the official Microsoft documentation .","title":"Mapping Components"},{"location":"startleft-processors/diagram/Visio-Mapping/#mapping-dataflows","text":"Despite the fact that a dataflows tag is already defined in the mapping file structure, and it is required by the schema, the DataFlows mapping process is fixed and not configurable. Basically, it takes all the arrows in the Visio source that connect components that are mapped and create a DataFlow for them. If some arrow connects shapes that are not mapped, the DataFlow is not created. This can be easily understood with the following picture:","title":"Mapping DataFlows"},{"location":"startleft-processors/diagram/Visio-Quickstart/","text":"What is Microsoft Visio? Note : It is important to notice that the only supported Visio format is the VSDX format . If you want to import another format, you previously need to convert it to vsdx. Otherwise, you will get an error. Microsoft Visio is a tool that enables its users to freely draw diagrams of any kind from scratch or based on templates. From the point of view of StartLeft, it is a place where infrastructure or threat model diagrams can be created. Despite the fact that Visio gives their users complete freedom to build whatever they want in the diagram, architecture or threat modeling diagrams tend to share a more or less common structure and StartLeft pretends to take advantage of this in order to automatize the processing of the diagrams to create threat models in the OTM format. Microsoft Visio Stencils Visio Stencils are a specially interesting use case, because they are predefined Visio shapes that can be reused in every diagram. StartLeft is able to identify this kind of shapes so that their mappings can be also reused for converting different diagrams. This is the case, for example, of the Visio AWS stencils , that are prebuilt shapes which represent a bunch of reusable AWS components. This feature allows StartLeft clients like IriusRisk to define a default mapping file with all these stencils and inject it in every request to StartLeft so the user does not need to create the mappings each time. Other tools VSDX is a structure to represent diagrams based on XML files, but each diagramming tool can (and actually does) fill that structure in slightly different ways. This means that StartLeft cannot support out-of-the-box VSDX files generated by every tool. So, if you export to VSDX a diagram created in DrawIO, for example, some errors may appear during the StartLeft parsing process. Currently, apart from native Microsoft Visio diagrams, only Lucidchart exported diagrams are supported. The mappings and the main parsing process are almost equal in both cases, but you can check out the Lucidchart support page to best know about the parsing of diagrams created with that tool. The slp_visio module The slp_visio module is the StartLeft Processor responsible for converting Microsoft Visio files into OTM. Although not every diagram is susceptible to be parsed into OTM automatically, the fact is that there are many situations where the StartLeft process may be very useful. Mapping introduction Its operation is based on two types of mapping files hierarchically processed, that is, in case a shape is mapped in both mapping files, the mapping in the custom mapping file has preference over the default one : The default mapping file is expected to contain those mappings that may be potentially reused across different conversion requests. The typical use cases for this mapping file are predefined Visio Shapes like the AWS stencils mentioned before or more simple shapes like the database shape, for example. The custom mapping file is the file where the user can introduce the mappings for their own specific components. As mentioned above, the user has absolute freedom to draw and name shapes that may be relevant for the threat model. Only mapped shapes will be parsed into the OTM so this is the place where you need to place the mappings for everything you want to be processed. Further details about the mapping behavior may be found in the Visio-Mapping page . Regarding the usage of StartLeft to converting Visio files, you can check the manuals for the CLI and the REST API . Elements position and representation The Visio processor can process the Visio shapes and extract from them information about their representation. This data is then placed in the OTM RepresentationElement object . In the Representations parsing page you can find all the details about how the representation data is extracted from Visio, but, summarizing, these are the most important points: Position and size are parsed, but not the shape (circle, square, etc.). Representation information is extracted from Visio, but not calculated. This means that TrustZones generated by default or coming from a boundary line will not have representation data in the OTM. The position of the elements in the OTM is relative to its immediate parent. All representation information is given in integers with no decimals and rescaled to avoid losing information. A basic example Suppose you have an architecture diagram like the one below, that contains two TrustZones ( Public Cloud and Private Secured Cloud ), a VPC and components that may belong to Stencils ( My EC2 and Private Database ) or generic ones ( My Custom Machine ). You may want to upload it to a threat modeling tool like IriusRisk to build a threat model like this: The most usual configuration for performing this conversion is having two mapping files. On one hand, you would have your reusable default mapping file that contains mappings for the AWS stencils, with a content like this: trustzones : - label : Public Cloud type : Public Cloud id : b61d6911-338d-46a8-9f39-8dcd24abfe91 components : - label : Amazon EC2 type : ec2 - label : Database type : rds dataflows : [] On the other hand, for this specific request, you need to provide a custom mapping file which contains the mappings for the generic elements of the diagram ( My Custom VPC , My Custom Machine and the Private Secured Cloud TrustZone): trustzones : - label : Private Secured Cloud type : Private Secured id : 2ab4effa-40b7-4cd2-ba81-8247d29a6f2d components : - label : My Custom Machine type : empty-component - label : My Custom VPC type : empty-component dataflows : [] The result of sending to StartLeft this diagram with these mapping files would be an OTM with all the components we had in the original Visio source: basic-visio-example.otm { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"My Visio Basic Example\" , \"id\" : \"my-visio-basic-example\" }, \"representations\" : [ { \"name\" : \"Visio\" , \"id\" : \"Visio\" , \"type\" : \"diagram\" , \"size\" : { \"width\" : 1000 , \"height\" : 1000 } } ], \"trustZones\" : [ { \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"name\" : \"Public Cloud\" , \"risk\" : { \"trustRating\" : 10 } }, { \"id\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" , \"name\" : \"Private Secured\" , \"risk\" : { \"trustRating\" : 10 } } ], \"components\" : [ { \"id\" : \"67\" , \"name\" : \"My Custom VPC\" , \"type\" : \"empty-component\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\" : \"12\" , \"name\" : \"My EC2\" , \"type\" : \"ec2\" , \"parent\" : { \"component\" : \"67\" } }, { \"id\" : \"30\" , \"name\" : \"Private Database\" , \"type\" : \"rds\" , \"parent\" : { \"trustZone\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" } }, { \"id\" : \"68\" , \"name\" : \"My Custom Machine\" , \"type\" : \"empty-component\" , \"parent\" : { \"component\" : \"67\" } } ], \"dataflows\" : [ { \"id\" : \"34\" , \"name\" : \"0d61e659-90a3-450e-adca-65aa08382c68\" , \"source\" : \"12\" , \"destination\" : \"30\" }, { \"id\" : \"69\" , \"name\" : \"f6d209c4-a507-48ca-a9ed-7d10c1d0cc78\" , \"source\" : \"68\" , \"destination\" : \"12\" } ] } CLI Note : Before continue, make sure you have StartLeft properly installed in your machine. First of all, retrieve all the necessary files: Download the visio-basic-example.vsdx from here . Save the default mapping above with the name default-mapping.yaml . Save the custom mapping above with the name custom-mapping.yaml . Now we are going to execute StartLeft for these files so that an ec2.otm file will be generated in our working directory with identical contents to the one above. startleft parse \\ --diagram-type VISIO \\ --default-mapping-file default-mapping.yaml \\ --custom-mapping-file custom-mapping.yaml \\ --output-file basic-visio-example.otm \\ --project-id \"my-visio-basic-example\" \\ --project-name \"My Visio Basic Example\" \\ visio-basic-example.vsdx cURL You can get the same result if through the StartLeft's REST API. For that, in first place we need to set up the server with the command: startleft server If you want to run the server in a specific port, you can do: startleft server -p 8080 Then, execute the following command to retrieve the OTM file with your EC2 component: curl --location --request POST localhost:5000/api/v1/startleft/diagram \\ --header \"Content-Type: multipart/form-data\" \\ --header \"Accept: application/json\" \\ --form diag_type = \"VISIO\" \\ --form diag_file = @ \"./visio-basic-example.vsdx\" \\ --form default_mapping_file = @ \"./default-mapping.yaml\" \\ --form custom_mapping_file = @ \"./custom-mapping.yaml\" \\ --form id = \"my-visio-basic-example\" \\ --form name = \"My Visio Basic Example\"","title":"Visio Quickstart"},{"location":"startleft-processors/diagram/Visio-Quickstart/#what-is-microsoft-visio","text":"Note : It is important to notice that the only supported Visio format is the VSDX format . If you want to import another format, you previously need to convert it to vsdx. Otherwise, you will get an error. Microsoft Visio is a tool that enables its users to freely draw diagrams of any kind from scratch or based on templates. From the point of view of StartLeft, it is a place where infrastructure or threat model diagrams can be created. Despite the fact that Visio gives their users complete freedom to build whatever they want in the diagram, architecture or threat modeling diagrams tend to share a more or less common structure and StartLeft pretends to take advantage of this in order to automatize the processing of the diagrams to create threat models in the OTM format.","title":"What is Microsoft Visio?"},{"location":"startleft-processors/diagram/Visio-Quickstart/#microsoft-visio-stencils","text":"Visio Stencils are a specially interesting use case, because they are predefined Visio shapes that can be reused in every diagram. StartLeft is able to identify this kind of shapes so that their mappings can be also reused for converting different diagrams. This is the case, for example, of the Visio AWS stencils , that are prebuilt shapes which represent a bunch of reusable AWS components. This feature allows StartLeft clients like IriusRisk to define a default mapping file with all these stencils and inject it in every request to StartLeft so the user does not need to create the mappings each time.","title":"Microsoft Visio Stencils"},{"location":"startleft-processors/diagram/Visio-Quickstart/#other-tools","text":"VSDX is a structure to represent diagrams based on XML files, but each diagramming tool can (and actually does) fill that structure in slightly different ways. This means that StartLeft cannot support out-of-the-box VSDX files generated by every tool. So, if you export to VSDX a diagram created in DrawIO, for example, some errors may appear during the StartLeft parsing process. Currently, apart from native Microsoft Visio diagrams, only Lucidchart exported diagrams are supported. The mappings and the main parsing process are almost equal in both cases, but you can check out the Lucidchart support page to best know about the parsing of diagrams created with that tool.","title":"Other tools"},{"location":"startleft-processors/diagram/Visio-Quickstart/#the-slp_visio-module","text":"The slp_visio module is the StartLeft Processor responsible for converting Microsoft Visio files into OTM. Although not every diagram is susceptible to be parsed into OTM automatically, the fact is that there are many situations where the StartLeft process may be very useful.","title":"The slp_visio module"},{"location":"startleft-processors/diagram/Visio-Quickstart/#mapping-introduction","text":"Its operation is based on two types of mapping files hierarchically processed, that is, in case a shape is mapped in both mapping files, the mapping in the custom mapping file has preference over the default one : The default mapping file is expected to contain those mappings that may be potentially reused across different conversion requests. The typical use cases for this mapping file are predefined Visio Shapes like the AWS stencils mentioned before or more simple shapes like the database shape, for example. The custom mapping file is the file where the user can introduce the mappings for their own specific components. As mentioned above, the user has absolute freedom to draw and name shapes that may be relevant for the threat model. Only mapped shapes will be parsed into the OTM so this is the place where you need to place the mappings for everything you want to be processed. Further details about the mapping behavior may be found in the Visio-Mapping page . Regarding the usage of StartLeft to converting Visio files, you can check the manuals for the CLI and the REST API .","title":"Mapping introduction"},{"location":"startleft-processors/diagram/Visio-Quickstart/#elements-position-and-representation","text":"The Visio processor can process the Visio shapes and extract from them information about their representation. This data is then placed in the OTM RepresentationElement object . In the Representations parsing page you can find all the details about how the representation data is extracted from Visio, but, summarizing, these are the most important points: Position and size are parsed, but not the shape (circle, square, etc.). Representation information is extracted from Visio, but not calculated. This means that TrustZones generated by default or coming from a boundary line will not have representation data in the OTM. The position of the elements in the OTM is relative to its immediate parent. All representation information is given in integers with no decimals and rescaled to avoid losing information.","title":"Elements position and representation"},{"location":"startleft-processors/diagram/Visio-Quickstart/#a-basic-example","text":"Suppose you have an architecture diagram like the one below, that contains two TrustZones ( Public Cloud and Private Secured Cloud ), a VPC and components that may belong to Stencils ( My EC2 and Private Database ) or generic ones ( My Custom Machine ). You may want to upload it to a threat modeling tool like IriusRisk to build a threat model like this: The most usual configuration for performing this conversion is having two mapping files. On one hand, you would have your reusable default mapping file that contains mappings for the AWS stencils, with a content like this: trustzones : - label : Public Cloud type : Public Cloud id : b61d6911-338d-46a8-9f39-8dcd24abfe91 components : - label : Amazon EC2 type : ec2 - label : Database type : rds dataflows : [] On the other hand, for this specific request, you need to provide a custom mapping file which contains the mappings for the generic elements of the diagram ( My Custom VPC , My Custom Machine and the Private Secured Cloud TrustZone): trustzones : - label : Private Secured Cloud type : Private Secured id : 2ab4effa-40b7-4cd2-ba81-8247d29a6f2d components : - label : My Custom Machine type : empty-component - label : My Custom VPC type : empty-component dataflows : [] The result of sending to StartLeft this diagram with these mapping files would be an OTM with all the components we had in the original Visio source: basic-visio-example.otm { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"My Visio Basic Example\" , \"id\" : \"my-visio-basic-example\" }, \"representations\" : [ { \"name\" : \"Visio\" , \"id\" : \"Visio\" , \"type\" : \"diagram\" , \"size\" : { \"width\" : 1000 , \"height\" : 1000 } } ], \"trustZones\" : [ { \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"name\" : \"Public Cloud\" , \"risk\" : { \"trustRating\" : 10 } }, { \"id\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" , \"name\" : \"Private Secured\" , \"risk\" : { \"trustRating\" : 10 } } ], \"components\" : [ { \"id\" : \"67\" , \"name\" : \"My Custom VPC\" , \"type\" : \"empty-component\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\" : \"12\" , \"name\" : \"My EC2\" , \"type\" : \"ec2\" , \"parent\" : { \"component\" : \"67\" } }, { \"id\" : \"30\" , \"name\" : \"Private Database\" , \"type\" : \"rds\" , \"parent\" : { \"trustZone\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" } }, { \"id\" : \"68\" , \"name\" : \"My Custom Machine\" , \"type\" : \"empty-component\" , \"parent\" : { \"component\" : \"67\" } } ], \"dataflows\" : [ { \"id\" : \"34\" , \"name\" : \"0d61e659-90a3-450e-adca-65aa08382c68\" , \"source\" : \"12\" , \"destination\" : \"30\" }, { \"id\" : \"69\" , \"name\" : \"f6d209c4-a507-48ca-a9ed-7d10c1d0cc78\" , \"source\" : \"68\" , \"destination\" : \"12\" } ] }","title":"A basic example"},{"location":"startleft-processors/diagram/Visio-Quickstart/#cli","text":"Note : Before continue, make sure you have StartLeft properly installed in your machine. First of all, retrieve all the necessary files: Download the visio-basic-example.vsdx from here . Save the default mapping above with the name default-mapping.yaml . Save the custom mapping above with the name custom-mapping.yaml . Now we are going to execute StartLeft for these files so that an ec2.otm file will be generated in our working directory with identical contents to the one above. startleft parse \\ --diagram-type VISIO \\ --default-mapping-file default-mapping.yaml \\ --custom-mapping-file custom-mapping.yaml \\ --output-file basic-visio-example.otm \\ --project-id \"my-visio-basic-example\" \\ --project-name \"My Visio Basic Example\" \\ visio-basic-example.vsdx","title":"CLI"},{"location":"startleft-processors/diagram/Visio-Quickstart/#curl","text":"You can get the same result if through the StartLeft's REST API. For that, in first place we need to set up the server with the command: startleft server If you want to run the server in a specific port, you can do: startleft server -p 8080 Then, execute the following command to retrieve the OTM file with your EC2 component: curl --location --request POST localhost:5000/api/v1/startleft/diagram \\ --header \"Content-Type: multipart/form-data\" \\ --header \"Accept: application/json\" \\ --form diag_type = \"VISIO\" \\ --form diag_file = @ \"./visio-basic-example.vsdx\" \\ --form default_mapping_file = @ \"./default-mapping.yaml\" \\ --form custom_mapping_file = @ \"./custom-mapping.yaml\" \\ --form id = \"my-visio-basic-example\" \\ --form name = \"My Visio Basic Example\"","title":"cURL"},{"location":"startleft-processors/diagram/Visio-Representations/","text":"Visio diagrams contain visual information about your infrastructure or threat model that may be useful to keep. During the parsing of the vsdx file, the slp_visio processor is able to extract this representation data and include it in the resultant OTM. Where is the representation data located? We use two OTM structures to store the representation data: The Representation object is placed at the root level and contains information about the general representation of the Threat Model, for instance, its type or the size of the canvas. The RepresentationElement object is placed at Component or TrustZone level and contains representation info of that element as its position and size. What representation data is included? Position and size data extracted from the Visio file source are included. It is relevant to notice that no different types of shapes are supported and all Components and TrustZones will be represented in the OTM as rectangles . Position calculation In the case of TrustZones, the parent element is the limit of the Visio diagram itself. The position attribute of the OTM RepresentationElement object contains: x . Distance from the LEFT side of the parent element to the left side of the child element. y . Distance from the TOP of the parent element to the top of the child element. Size calculation The size attribute of the OTM RepresentationElement object contains: width . It is the difference between the right x value minus the left one. height . It is the difference between the bottom y value minus the top one. Excluded representations It is very important to consider that all the information included in the OTM is directly extracted from the Visio file and not calculated by the slp_visio . This means that some elements will never have representations in the OTM: The boundary TrustZones represents an ambiguous zone that is not explicitly defined in the source diagram, so they will not have a representation object. The default TrustZone may contain elements from different places of the diagram and neither has any representation info in the source Visio, so no representation object can be calculated. The Components without parent in the source Visio will be nested into the default TrustZone. Since this does not have representation and the Components' position must be relative, they will not have representation. The Dataflows between elements must unequivocally identify their origin and target, so no representation information is transferred to the OTM. How Visio representation data is processed? The Visio position information and the OTM representation data do not exactly fit, so some transformations are required: Diagram limits calculation . Visio diagrams are unbounded, so it is necessary to find their boundaries in some way. In that case, they are calculated using the position of the elements at their ends. Origin translation . Visio diagrams origin is located in the bottom left. Since the OTM representations origin is on the top left, it is necessary to recalculate the y position from the diagram's top limit. Precision and scale . OTM representation values must be integers. However, Visio data is in float precision, so it is rescaled and rounded. The scale factor is expected to be parametrizable in the future , but for now, it is fixed to the IriusRisk scale (based on DrawIO). This means that each Visio representation parameter is processed as follows: IRIUSRISK_SMALLEST_COMPONENT_SIZE = 82 VISIO_STENCILS_DEFAULT_SIZE = 0.5 SCALE_FACTOR : int = round ( IRIUSRISK_SMALLEST_COMPONENT_SIZE / VISIO_STENCILS_DEFAULT_SIZE ) An example Let's take this Visio example: OTM parsing result If we parse it into OTM, the result would be something like this: { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"VISIO\" , \"id\" : \"VISIO\" }, \"representations\" : [ { // (1)! \"name\" : \"VISIO Diagram Representation\" , \"id\" : \"VISIO-diagram\" , \"type\" : \"diagram\" , \"size\" : { // (2)! \"width\" : 1826 , \"height\" : 1207 } } ], \"trustZones\" : [ { \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"name\" : \"Public Cloud\" , \"risk\" : { \"trustRating\" : 10 }, \"representations\" : [ { // (3)! \"name\" : \"Public Cloud Representation\" , \"id\" : \"67-representation\" , // (4)! \"representation\" : \"VISIO-diagram\" , \"size\" : { \"width\" : 661 , \"height\" : 551 }, \"position\" : { \"x\" : 328 , \"y\" : 328 } } ] }, { // (5)! \"id\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" , \"name\" : \"Private Secured\" , \"risk\" : { \"trustRating\" : 10 } } ], \"components\" : [ { \"id\" : \"49\" , \"name\" : \"Custom VPC\" , \"type\" : \"empty-component\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"representations\" : [ { \"name\" : \"Custom VPC Representation\" , \"id\" : \"49-representation\" , \"representation\" : \"VISIO-diagram\" , \"size\" : { // (6)! \"width\" : 246 , \"height\" : 256 }, \"position\" : { // (7)! \"x\" : 361 , \"y\" : 31 } } ] }, { \"id\" : \"1\" , \"name\" : \"Amazon EC2\" , \"type\" : \"ec2\" , \"parent\" : { \"component\" : \"49\" }, \"representations\" : [ { // (8)! \"name\" : \"Amazon EC2 Representation\" , \"id\" : \"1-representation\" , \"representation\" : \"VISIO-diagram\" , \"size\" : { \"width\" : 82 , \"height\" : 82 }, \"position\" : { \"x\" : 82 , \"y\" : 25 } } ] }, { // (9)! \"id\" : \"30\" , \"name\" : \"Private Database\" , \"type\" : \"rds\" , \"parent\" : { \"trustZone\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" } }, { \"id\" : \"41\" , \"name\" : \"Custom log system\" , \"type\" : \"cloudwatch\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"representations\" : [ { // (10)! \"name\" : \"Custom log system Representation\" , \"id\" : \"41-representation\" , \"representation\" : \"VISIO-diagram\" , \"size\" : { \"width\" : 82 , \"height\" : 82 }, \"position\" : { \"x\" : 443 , \"y\" : 370 } } ] }, { \"id\" : \"69\" , \"name\" : \"Custom enterprise GW\" , \"type\" : \"api-gateway\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"representations\" : [ { // (11)! \"name\" : \"Custom enterprise GW Representation\" , \"id\" : \"69-representation\" , \"representation\" : \"VISIO-diagram\" , \"size\" : { \"width\" : 171 , \"height\" : 171 }, \"position\" : { \"x\" : 28 , \"y\" : 128 } } ] } ], \"dataflows\" : [ // (12)! { \"id\" : \"17\" , \"name\" : \"fe940e8c-f9ec-4a58-a555-5ef4119e97b6\" , \"source\" : \"1\" , \"destination\" : \"41\" }, { \"id\" : \"34\" , \"name\" : \"0b3f1707-1a91-44b8-bb06-5bfd7617e315\" , \"source\" : \"1\" , \"destination\" : \"30\" }, { \"id\" : \"70\" , \"name\" : \"16f21508-d45f-4beb-aa59-7189264e5385\" , \"source\" : \"69\" , \"destination\" : \"1\" } ] } A diagram representation for the Visio source. The size of the diagram is based on its components. Absolute position based on the main diagram canvas. Reference to the diagram representation id. No representation for boundary TrustZone. The dimensions are based in the width and height of the rectangle. Relative position to the parent TrustZone. Relative representation to the parent VPC. No representation because it belongs to a boundary TrustZone. Relative representation to the parent TrustZone. Relative representation to the parent TrustZone calculated from its rectangle envelope. No representations for Dataflows.","title":"Visio Representations"},{"location":"startleft-processors/diagram/Visio-Representations/#where-is-the-representation-data-located","text":"We use two OTM structures to store the representation data: The Representation object is placed at the root level and contains information about the general representation of the Threat Model, for instance, its type or the size of the canvas. The RepresentationElement object is placed at Component or TrustZone level and contains representation info of that element as its position and size.","title":"Where is the representation data located?"},{"location":"startleft-processors/diagram/Visio-Representations/#what-representation-data-is-included","text":"Position and size data extracted from the Visio file source are included. It is relevant to notice that no different types of shapes are supported and all Components and TrustZones will be represented in the OTM as rectangles .","title":"What representation data is included?"},{"location":"startleft-processors/diagram/Visio-Representations/#position-calculation","text":"In the case of TrustZones, the parent element is the limit of the Visio diagram itself. The position attribute of the OTM RepresentationElement object contains: x . Distance from the LEFT side of the parent element to the left side of the child element. y . Distance from the TOP of the parent element to the top of the child element.","title":"Position calculation"},{"location":"startleft-processors/diagram/Visio-Representations/#size-calculation","text":"The size attribute of the OTM RepresentationElement object contains: width . It is the difference between the right x value minus the left one. height . It is the difference between the bottom y value minus the top one.","title":"Size calculation"},{"location":"startleft-processors/diagram/Visio-Representations/#excluded-representations","text":"It is very important to consider that all the information included in the OTM is directly extracted from the Visio file and not calculated by the slp_visio . This means that some elements will never have representations in the OTM: The boundary TrustZones represents an ambiguous zone that is not explicitly defined in the source diagram, so they will not have a representation object. The default TrustZone may contain elements from different places of the diagram and neither has any representation info in the source Visio, so no representation object can be calculated. The Components without parent in the source Visio will be nested into the default TrustZone. Since this does not have representation and the Components' position must be relative, they will not have representation. The Dataflows between elements must unequivocally identify their origin and target, so no representation information is transferred to the OTM.","title":"Excluded representations"},{"location":"startleft-processors/diagram/Visio-Representations/#how-visio-representation-data-is-processed","text":"The Visio position information and the OTM representation data do not exactly fit, so some transformations are required: Diagram limits calculation . Visio diagrams are unbounded, so it is necessary to find their boundaries in some way. In that case, they are calculated using the position of the elements at their ends. Origin translation . Visio diagrams origin is located in the bottom left. Since the OTM representations origin is on the top left, it is necessary to recalculate the y position from the diagram's top limit. Precision and scale . OTM representation values must be integers. However, Visio data is in float precision, so it is rescaled and rounded. The scale factor is expected to be parametrizable in the future , but for now, it is fixed to the IriusRisk scale (based on DrawIO). This means that each Visio representation parameter is processed as follows: IRIUSRISK_SMALLEST_COMPONENT_SIZE = 82 VISIO_STENCILS_DEFAULT_SIZE = 0.5 SCALE_FACTOR : int = round ( IRIUSRISK_SMALLEST_COMPONENT_SIZE / VISIO_STENCILS_DEFAULT_SIZE )","title":"How Visio representation data is processed?"},{"location":"startleft-processors/diagram/Visio-Representations/#an-example","text":"Let's take this Visio example: OTM parsing result If we parse it into OTM, the result would be something like this: { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"VISIO\" , \"id\" : \"VISIO\" }, \"representations\" : [ { // (1)! \"name\" : \"VISIO Diagram Representation\" , \"id\" : \"VISIO-diagram\" , \"type\" : \"diagram\" , \"size\" : { // (2)! \"width\" : 1826 , \"height\" : 1207 } } ], \"trustZones\" : [ { \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"name\" : \"Public Cloud\" , \"risk\" : { \"trustRating\" : 10 }, \"representations\" : [ { // (3)! \"name\" : \"Public Cloud Representation\" , \"id\" : \"67-representation\" , // (4)! \"representation\" : \"VISIO-diagram\" , \"size\" : { \"width\" : 661 , \"height\" : 551 }, \"position\" : { \"x\" : 328 , \"y\" : 328 } } ] }, { // (5)! \"id\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" , \"name\" : \"Private Secured\" , \"risk\" : { \"trustRating\" : 10 } } ], \"components\" : [ { \"id\" : \"49\" , \"name\" : \"Custom VPC\" , \"type\" : \"empty-component\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"representations\" : [ { \"name\" : \"Custom VPC Representation\" , \"id\" : \"49-representation\" , \"representation\" : \"VISIO-diagram\" , \"size\" : { // (6)! \"width\" : 246 , \"height\" : 256 }, \"position\" : { // (7)! \"x\" : 361 , \"y\" : 31 } } ] }, { \"id\" : \"1\" , \"name\" : \"Amazon EC2\" , \"type\" : \"ec2\" , \"parent\" : { \"component\" : \"49\" }, \"representations\" : [ { // (8)! \"name\" : \"Amazon EC2 Representation\" , \"id\" : \"1-representation\" , \"representation\" : \"VISIO-diagram\" , \"size\" : { \"width\" : 82 , \"height\" : 82 }, \"position\" : { \"x\" : 82 , \"y\" : 25 } } ] }, { // (9)! \"id\" : \"30\" , \"name\" : \"Private Database\" , \"type\" : \"rds\" , \"parent\" : { \"trustZone\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" } }, { \"id\" : \"41\" , \"name\" : \"Custom log system\" , \"type\" : \"cloudwatch\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"representations\" : [ { // (10)! \"name\" : \"Custom log system Representation\" , \"id\" : \"41-representation\" , \"representation\" : \"VISIO-diagram\" , \"size\" : { \"width\" : 82 , \"height\" : 82 }, \"position\" : { \"x\" : 443 , \"y\" : 370 } } ] }, { \"id\" : \"69\" , \"name\" : \"Custom enterprise GW\" , \"type\" : \"api-gateway\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"representations\" : [ { // (11)! \"name\" : \"Custom enterprise GW Representation\" , \"id\" : \"69-representation\" , \"representation\" : \"VISIO-diagram\" , \"size\" : { \"width\" : 171 , \"height\" : 171 }, \"position\" : { \"x\" : 28 , \"y\" : 128 } } ] } ], \"dataflows\" : [ // (12)! { \"id\" : \"17\" , \"name\" : \"fe940e8c-f9ec-4a58-a555-5ef4119e97b6\" , \"source\" : \"1\" , \"destination\" : \"41\" }, { \"id\" : \"34\" , \"name\" : \"0b3f1707-1a91-44b8-bb06-5bfd7617e315\" , \"source\" : \"1\" , \"destination\" : \"30\" }, { \"id\" : \"70\" , \"name\" : \"16f21508-d45f-4beb-aa59-7189264e5385\" , \"source\" : \"69\" , \"destination\" : \"1\" } ] } A diagram representation for the Visio source. The size of the diagram is based on its components. Absolute position based on the main diagram canvas. Reference to the diagram representation id. No representation for boundary TrustZone. The dimensions are based in the width and height of the rectangle. Relative position to the parent TrustZone. Relative representation to the parent VPC. No representation because it belongs to a boundary TrustZone. Relative representation to the parent TrustZone. Relative representation to the parent TrustZone calculated from its rectangle envelope. No representations for Dataflows.","title":"An example"},{"location":"startleft-processors/diagram/Visio-TrustZones-Mapping/","text":"Visio shapes context Trustzones in a Visio diagram can be represented in different ways and, in each of them, it does not exist a perfect method to unambiguously identify the TrustZone to which a component belongs. This page pretends to clarify the different mechanisms used by StartLeft to identify TrustZones and assign components to them during the Visio diagram parsing to an Open Threat Model (OTM). Use of shapely Polygons Visio diagrams only have two ways to relate shapes: Connectors between shapes , that are used to create OTM dataflows. Grouped shapes . This may be useful in some circumstances, but grouping shapes is a decision of the person that is creating the diagram, so we cannot trust on that to perform generic processing. These two features are not enought for the processings we need to do. Along this document, we will see that we need to identify relationships between the shapes (inheritance, zones definition, etc.). For that reason, at the moment of loading the Visio diagram, we use the Visio library shapely to create a simplified representation of each shape, so we can then perform more or less complex operation with that representation model. This would be an example of a Visio diagram and the simplified model we generate: The shapely object we use for the Visio shapes representation is the Polygon and an extensive manual of how to manipulate those objects can be found here . TrustZone identification We have two ways to identify TrustZones in a Visio diagram that are described below. However, it is important to notice that, regardless of the type of TrustZone calculation, no TrustZone will be included in the OTM if it does not appear in the mapping file . If some TrustZone candidate is identified in the Visio diagram, but it is not in the mapping file, the TrustZone will be ignored or processed as a normal component depending on the case. Parent Shape TrustZone One shape that has no parent in the Visio diagram and that appears in the mapping file is considered a TrustZone . It is the case of this example: The TrustZone identification is based on the parent calculation. Notice that a component may belong directly to a TrustZone, but also be nested into another component. Anyway, each shape must have a parent, so, for each of them, we perform the following steps: We check if the shape is contained into another. If so, that shape is its parent. If a shape is not contained in any other, there are two options: If it is mapped as a TrustZone in the mapping file, it is a TrustZone. If not, it is a component whose parent is the default TrustZone. As stated before, Visio does not provide information about if a shape is over or \u201cbelongs to\u201c another one. To solve this, we use the shapely\u2019s Polygon representations of each shape. For each shape, we check if it is contained in another one by using the shapely\u2019s Polygon 's function contains(Polygon) -> bool . This function lets us know if some shape contains another. Nested components Nested components are a special case where more than one shapes will return True when calling the contains function. In the example above, the Public Cloud and Custom VPC contain the Some ec2 shape. In this case we use the Polygon 's function area. The parent shape is the one with the smallest area, that is, the Custom VPC . Then, the Custom VPC is only contained in the Public Cloud , so it is selected as its parent. Finally, the Public Cloud is not contained by any shape, and it is mapped as TrustZone in the mapping file, so it is converted into one. Boundary TrustZone Note : The tangent would be more precise than the secant, but given that its center point is more difficult to extract from the Visio data, we use the secant, whose calculations should be also valid for other types or arcs, like elliptical ones. Boundaries are the most common way to delimite TrustZones in a threat model. However, their graphic representation is more lax than the nested shapes, because they simply use arcs to define zones in the diagram. For example: In this case, we need to use the arcs that define the boundaries to generate different zones in the diagram and then check the shapes that belong to those zones. Anyway, do not forget that, if a TrustZone is not in the mapping file, it will not be generated. In case of boundary TrustZones, they will simply be ignored . Supported types of arcs Note : This is a relevant limitation . There are several types of shapes that could be used to determine boundaries in the diagram, and we will need to evolve StartLeft to support them. Currently, we only support the Curved shape Visio type to process TrustZones . It may be evolved in the future in order to include more types of connectors. Zones calculation To build the diagram zones from the arc shapes, we generate internal components based on the intersection of the secant of the boundary arcs with the diagram limits: Once we have these special zone components calculated, they are inserted in the usual parent calculation process described above . However, there are two particularities with them: A zone component can only be mapped to a TrustZone. If there is no TrustZone to match it in the mapping file, it is simply ignored and not transformed in a normal component. If two zone components are overlapped and a shape belongs to both, we cannot use here the area criteria to decide because it is not relevant. Instead of it, we use the shapely Polygon 's function centroid, that returns a Point representing the center of the generated component. Then we also get the center of the child shape and, using the Point 's distance function, we choose the zone whose center is closer to the shape\u2019s one. Zone component building details TL;DR : This is a very low level section, feel free to skip it if you want, since the more relevant info about TrustZone mappings can be understood without this level of detail. To build the zone components, we use three properties of the Visio arc shape (aka. Curved panel ): Shape/Cell['PinX'] : X coordinate of the center of the arc shape. Shape/Cell['PinY'] : Y coordinate of the center of the arc shape. Shape/Cell['Angle'] : Angle of rotation of the shape. Represented in Visio, these properties would be: Apart from this data, during the main parsing process of the shapes, we keep track of its position in order to calculate the borders of the diagrams, that are essential for the calculations described below. Angle normalization The first step of the process is translating the Visio angle from the [-pi, pi] range to (0, 2pi] to simplify further calculations using the following expression: angle = angle + 2*pi if angle < 0 Note : Notice that Visio angles are given in radians and so that is how they are processed in StartLeft. Once we have the angle normalized, there are two possible cases. The first one is when we have a perfectly vertical or horizontal secant. In this case, we will build a quadrant component (the Private Secured Cloud on the first example of this section). The second case is when the secant is sloped with a certain angle, and we need to calculate the intersection using the formula of the line (the other two cases in the example). Quadrant building This is the simplest case. We only have to know the orientation of the arc and then build the quadrant based on the X or Y value depending on the case. The correspondences between the four possible orientations and the normalized Visio angle are the following: UPPER : pi / 4 radians LOWER : (5 / 4) * pi radians LEFT : (3 / 4) * pi radians RIGHT : (7 / 4) * pi radians For each of these orientations, we have a function to determine the points of the Polygon we have to build: UPPER : [(x_floor, y), (x_floor, y_top), (x_top, y_top), (x_top, y)] LOWER : [(x_floor, y_floor), (x_floor, y), (x_top, y), (x_top, y_floor)]) LEFT : [(x_floor, y_floor), (x_floor, y_top), (x, y_top), (x, y_floor)]) RIGHT : [(x, y_floor), (x, y_top), (x_top, y_top), (x_top, y_floor)]) Irregular zone building In this case we have to calculate the formula of the secant line in order to calculate the point of intersection with the borders of the diagram. For that, the first step is getting the line angle. Notice that it is different from the Visio shape angle. For example, in the previous arc figure, the shape angle is pi/4 radians and the secant angle is 0 radians. To get the real angle, we need to perform the following calculation: def calc_slope_angle ( angle ): slope_angle = angle - pi / 4 if slope_angle < 0 : slope_angle = slope_angle + 2 * pi if slope_angle > pi : slope_angle = slope_angle - pi return slope_angle Then, we calculate the slope with the tangent: slope = tan(slope_angle) Once we have the slope and some point (the PinX , PinY coordinates), we can already calculate the formulas for getting the Y value from the X and viceversa. def calc_y_formula ( slope : float , any_line_point : tuple ): return lambda x : x * slope - any_line_point [ 0 ] * slope + any_line_point [ 1 ] def calc_x_formula ( slope : float , any_line_point : tuple ): return lambda y : y / slope + any_line_point [ 0 ] - ( any_line_point [ 1 ] / slope ) From this point on, the process is similar to the quadrant. In the first place, we need to determine the orientation of the arc: UPPER_LEFT : pi / 4 <= angle <= (3 / 4) * pi UPPER_RIGHT : 0 <= angle <= pi / 4 or (7 / 4) * pi <= angle <= 2 * pi LOWER_LEFT : (3 / 4) * pi <= angle <= (5 / 4) * pi LOWER_RIGHT : (5 / 4) * pi <= angle <= (7 / 4) * pi With the orientation and the x and y formulas, we already have all the necessary to build the Polygon from the intersection of the line with the diagram borders. In this case, the functions are a little more complex because, depending on how big the diagram is and what is the angle of the arc, the zone can be a triangle or a quadrilateral. To keep this document simpler, the functions are omitted, but they can be checked out in the slp_visio \u2019s irregular_zones.py file. Limitations Currently, there are a couple of significant limitations to take into account regarding the trustzone identification: In boundary TrustZones, if a shape is located between the secant and the arc itself, it is not considered part of the TrustZone. We only support Visio\u2019s Curved Panel to process boundary TrustZones.","title":"Visio TrustZones Mapping"},{"location":"startleft-processors/diagram/Visio-TrustZones-Mapping/#visio-shapes-context","text":"Trustzones in a Visio diagram can be represented in different ways and, in each of them, it does not exist a perfect method to unambiguously identify the TrustZone to which a component belongs. This page pretends to clarify the different mechanisms used by StartLeft to identify TrustZones and assign components to them during the Visio diagram parsing to an Open Threat Model (OTM).","title":"Visio shapes context"},{"location":"startleft-processors/diagram/Visio-TrustZones-Mapping/#use-of-shapely-polygons","text":"Visio diagrams only have two ways to relate shapes: Connectors between shapes , that are used to create OTM dataflows. Grouped shapes . This may be useful in some circumstances, but grouping shapes is a decision of the person that is creating the diagram, so we cannot trust on that to perform generic processing. These two features are not enought for the processings we need to do. Along this document, we will see that we need to identify relationships between the shapes (inheritance, zones definition, etc.). For that reason, at the moment of loading the Visio diagram, we use the Visio library shapely to create a simplified representation of each shape, so we can then perform more or less complex operation with that representation model. This would be an example of a Visio diagram and the simplified model we generate: The shapely object we use for the Visio shapes representation is the Polygon and an extensive manual of how to manipulate those objects can be found here .","title":"Use of shapely Polygons"},{"location":"startleft-processors/diagram/Visio-TrustZones-Mapping/#trustzone-identification","text":"We have two ways to identify TrustZones in a Visio diagram that are described below. However, it is important to notice that, regardless of the type of TrustZone calculation, no TrustZone will be included in the OTM if it does not appear in the mapping file . If some TrustZone candidate is identified in the Visio diagram, but it is not in the mapping file, the TrustZone will be ignored or processed as a normal component depending on the case.","title":"TrustZone identification"},{"location":"startleft-processors/diagram/Visio-TrustZones-Mapping/#parent-shape-trustzone","text":"One shape that has no parent in the Visio diagram and that appears in the mapping file is considered a TrustZone . It is the case of this example: The TrustZone identification is based on the parent calculation. Notice that a component may belong directly to a TrustZone, but also be nested into another component. Anyway, each shape must have a parent, so, for each of them, we perform the following steps: We check if the shape is contained into another. If so, that shape is its parent. If a shape is not contained in any other, there are two options: If it is mapped as a TrustZone in the mapping file, it is a TrustZone. If not, it is a component whose parent is the default TrustZone. As stated before, Visio does not provide information about if a shape is over or \u201cbelongs to\u201c another one. To solve this, we use the shapely\u2019s Polygon representations of each shape. For each shape, we check if it is contained in another one by using the shapely\u2019s Polygon 's function contains(Polygon) -> bool . This function lets us know if some shape contains another.","title":"Parent Shape TrustZone"},{"location":"startleft-processors/diagram/Visio-TrustZones-Mapping/#nested-components","text":"Nested components are a special case where more than one shapes will return True when calling the contains function. In the example above, the Public Cloud and Custom VPC contain the Some ec2 shape. In this case we use the Polygon 's function area. The parent shape is the one with the smallest area, that is, the Custom VPC . Then, the Custom VPC is only contained in the Public Cloud , so it is selected as its parent. Finally, the Public Cloud is not contained by any shape, and it is mapped as TrustZone in the mapping file, so it is converted into one.","title":"Nested components"},{"location":"startleft-processors/diagram/Visio-TrustZones-Mapping/#boundary-trustzone","text":"Note : The tangent would be more precise than the secant, but given that its center point is more difficult to extract from the Visio data, we use the secant, whose calculations should be also valid for other types or arcs, like elliptical ones. Boundaries are the most common way to delimite TrustZones in a threat model. However, their graphic representation is more lax than the nested shapes, because they simply use arcs to define zones in the diagram. For example: In this case, we need to use the arcs that define the boundaries to generate different zones in the diagram and then check the shapes that belong to those zones. Anyway, do not forget that, if a TrustZone is not in the mapping file, it will not be generated. In case of boundary TrustZones, they will simply be ignored .","title":"Boundary TrustZone"},{"location":"startleft-processors/diagram/Visio-TrustZones-Mapping/#supported-types-of-arcs","text":"Note : This is a relevant limitation . There are several types of shapes that could be used to determine boundaries in the diagram, and we will need to evolve StartLeft to support them. Currently, we only support the Curved shape Visio type to process TrustZones . It may be evolved in the future in order to include more types of connectors.","title":"Supported types of arcs"},{"location":"startleft-processors/diagram/Visio-TrustZones-Mapping/#zones-calculation","text":"To build the diagram zones from the arc shapes, we generate internal components based on the intersection of the secant of the boundary arcs with the diagram limits: Once we have these special zone components calculated, they are inserted in the usual parent calculation process described above . However, there are two particularities with them: A zone component can only be mapped to a TrustZone. If there is no TrustZone to match it in the mapping file, it is simply ignored and not transformed in a normal component. If two zone components are overlapped and a shape belongs to both, we cannot use here the area criteria to decide because it is not relevant. Instead of it, we use the shapely Polygon 's function centroid, that returns a Point representing the center of the generated component. Then we also get the center of the child shape and, using the Point 's distance function, we choose the zone whose center is closer to the shape\u2019s one.","title":"Zones calculation"},{"location":"startleft-processors/diagram/Visio-TrustZones-Mapping/#zone-component-building-details","text":"TL;DR : This is a very low level section, feel free to skip it if you want, since the more relevant info about TrustZone mappings can be understood without this level of detail. To build the zone components, we use three properties of the Visio arc shape (aka. Curved panel ): Shape/Cell['PinX'] : X coordinate of the center of the arc shape. Shape/Cell['PinY'] : Y coordinate of the center of the arc shape. Shape/Cell['Angle'] : Angle of rotation of the shape. Represented in Visio, these properties would be: Apart from this data, during the main parsing process of the shapes, we keep track of its position in order to calculate the borders of the diagrams, that are essential for the calculations described below. Angle normalization The first step of the process is translating the Visio angle from the [-pi, pi] range to (0, 2pi] to simplify further calculations using the following expression: angle = angle + 2*pi if angle < 0 Note : Notice that Visio angles are given in radians and so that is how they are processed in StartLeft. Once we have the angle normalized, there are two possible cases. The first one is when we have a perfectly vertical or horizontal secant. In this case, we will build a quadrant component (the Private Secured Cloud on the first example of this section). The second case is when the secant is sloped with a certain angle, and we need to calculate the intersection using the formula of the line (the other two cases in the example). Quadrant building This is the simplest case. We only have to know the orientation of the arc and then build the quadrant based on the X or Y value depending on the case. The correspondences between the four possible orientations and the normalized Visio angle are the following: UPPER : pi / 4 radians LOWER : (5 / 4) * pi radians LEFT : (3 / 4) * pi radians RIGHT : (7 / 4) * pi radians For each of these orientations, we have a function to determine the points of the Polygon we have to build: UPPER : [(x_floor, y), (x_floor, y_top), (x_top, y_top), (x_top, y)] LOWER : [(x_floor, y_floor), (x_floor, y), (x_top, y), (x_top, y_floor)]) LEFT : [(x_floor, y_floor), (x_floor, y_top), (x, y_top), (x, y_floor)]) RIGHT : [(x, y_floor), (x, y_top), (x_top, y_top), (x_top, y_floor)]) Irregular zone building In this case we have to calculate the formula of the secant line in order to calculate the point of intersection with the borders of the diagram. For that, the first step is getting the line angle. Notice that it is different from the Visio shape angle. For example, in the previous arc figure, the shape angle is pi/4 radians and the secant angle is 0 radians. To get the real angle, we need to perform the following calculation: def calc_slope_angle ( angle ): slope_angle = angle - pi / 4 if slope_angle < 0 : slope_angle = slope_angle + 2 * pi if slope_angle > pi : slope_angle = slope_angle - pi return slope_angle Then, we calculate the slope with the tangent: slope = tan(slope_angle) Once we have the slope and some point (the PinX , PinY coordinates), we can already calculate the formulas for getting the Y value from the X and viceversa. def calc_y_formula ( slope : float , any_line_point : tuple ): return lambda x : x * slope - any_line_point [ 0 ] * slope + any_line_point [ 1 ] def calc_x_formula ( slope : float , any_line_point : tuple ): return lambda y : y / slope + any_line_point [ 0 ] - ( any_line_point [ 1 ] / slope ) From this point on, the process is similar to the quadrant. In the first place, we need to determine the orientation of the arc: UPPER_LEFT : pi / 4 <= angle <= (3 / 4) * pi UPPER_RIGHT : 0 <= angle <= pi / 4 or (7 / 4) * pi <= angle <= 2 * pi LOWER_LEFT : (3 / 4) * pi <= angle <= (5 / 4) * pi LOWER_RIGHT : (5 / 4) * pi <= angle <= (7 / 4) * pi With the orientation and the x and y formulas, we already have all the necessary to build the Polygon from the intersection of the line with the diagram borders. In this case, the functions are a little more complex because, depending on how big the diagram is and what is the angle of the arc, the zone can be a triangle or a quadrilateral. To keep this document simpler, the functions are omitted, but they can be checked out in the slp_visio \u2019s irregular_zones.py file.","title":"Zone component building details"},{"location":"startleft-processors/diagram/Visio-TrustZones-Mapping/#limitations","text":"Currently, there are a couple of significant limitations to take into account regarding the trustzone identification: In boundary TrustZones, if a shape is located between the secant and the arc itself, it is not considered part of the TrustZone. We only support Visio\u2019s Curved Panel to process boundary TrustZones.","title":"Limitations"},{"location":"startleft-processors/diagram/legacy/Legacy-Mapping-File-Format/","text":"Mapping file legacy format Due to a backward compatibility StartLeft accepts the legacy mapping file format. For the current mapping file format, please read Visio-Mapping Unlike the new mapping file format, the legacy one had the id field, with the identifier of the trust zone type. Legacy format example: trustzones : - label : Public Cloud type : Public Cloud id : b61d6911-338d-46a8-9f39-8dcd24abfe91 When a shape is found in the Visio file whose name matches the mapping's label , then a Trustzone is created in the OTM with these fields: - id is the original id in the Visio file - name is the original name in the Visio file - type is the mapping's id , if present. If not, will be the mapping's type In the above example the resultant OTM would contain a TrustZone like this: { \"trustZones\" : [ { \"id\" : \"47\" , \"name\" : \"My Public Cloud\" , \"type\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"risk\" : { \"trustRating\" : 10 } } ] }","title":"Legacy Mapping File Format"},{"location":"startleft-processors/diagram/legacy/Legacy-Mapping-File-Format/#mapping-file-legacy-format","text":"Due to a backward compatibility StartLeft accepts the legacy mapping file format. For the current mapping file format, please read Visio-Mapping Unlike the new mapping file format, the legacy one had the id field, with the identifier of the trust zone type. Legacy format example: trustzones : - label : Public Cloud type : Public Cloud id : b61d6911-338d-46a8-9f39-8dcd24abfe91 When a shape is found in the Visio file whose name matches the mapping's label , then a Trustzone is created in the OTM with these fields: - id is the original id in the Visio file - name is the original name in the Visio file - type is the mapping's id , if present. If not, will be the mapping's type In the above example the resultant OTM would contain a TrustZone like this: { \"trustZones\" : [ { \"id\" : \"47\" , \"name\" : \"My Public Cloud\" , \"type\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"risk\" : { \"trustRating\" : 10 } } ] }","title":"Mapping file legacy format"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Mapping/","text":"MTMT mapping A source mapping file (or 'mapping file' for short) describe how to identify components, dataflows, TrustZones, threats and mitigations in source file and how to map them to the OTM equivalent. Let's see how to identify the different elements: Trustzones For the TrustZones we need to write two fields: label and id The label will identify the MTMT TrustZone by its type. Let's see an example with a TrustZone in the MTMT_example.tm7: Our TrustZone named Internet is of Generic Trust Border Boundary type. So we need to put this type in the label value. The type in the mapping file will be the type in the OTM trust zone output. In this example, the Generic Trust Border Boundary source trust zones will be mapped to a OTM trust zone which type will be the value of the type in our mapping file. - label : Generic Trust Border Boundary type : 6376d53e-6461-412b-8e04-7b3fe2b397de In the OTM each trust zone will have a unique id and the type will be the type that we put in the mapping file The TrustZone OTM output will be: { \"trustZones\" : [ { \"id\" : \"7537441a-1c03-48c0-b9c8-f82d5906c139\" , \"name\" : \"Internet\" , \"type\" : \"6376d53e-6461-412b-8e04-7b3fe2b397de\" , \"risk\" : { \"trustRating\" : 10 }, \"properties\" : { \"Name\" : \"Internet\" } }]} In case we have two trust zones with the same type, the OTM will have two trust zones with the same type but different id. In the mapping file is enough having mapped once: - label : Generic Trust Border Boundary type : 6376d53e-6461-412b-8e04-7b3fe2b397de With two trust zones of the same type the OTM output will be: { \"trustZones\" : [ { \"id\" : \"7537441a-1c03-48c0-b9c8-f82d5906c139\" , \"name\" : \"Internet\" , \"type\" : \"6376d53e-6461-412b-8e04-7b3fe2b397de\" , \"risk\" : { \"trustRating\" : 10 }, \"properties\" : { \"Name\" : \"Internet\" } }, { \"id\" : \"bd837730-6a59-11ed-a798-772dcc832e1d\" , \"name\" : \"Public zone\" , \"type\" : \"6376d53e-6461-412b-8e04-7b3fe2b397de\" , \"risk\" : { \"trustRating\" : 10 }, \"properties\" : { \"Name\" : \"Public zone\" } } ]} The id of the trust zone in the OTM will be the MTMT original component id in the source file Due to a backward compatibility StartLeft accepts as well the legacy mapping file format. Please read Legacy-Mapping-File-Format Components For the components we need to write two fields: label and type . The label will identify the MTMT component by its MTMT type. Let's see again the MTMT_example.tm7: Our Public API v2 component is of Web API type. So we need to put this type in the label value. The type in the mapping file will be the type in the OTM component output. - label : Web API type : web-service The component OTM output will be: { \"components\" : [ { \"id\" : \"5d15323e-3729-4694-87b1-181c90af5045\" , \"name\" : \"Public API v2\" , \"type\" : \"web-service\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"properties\" : { \"Name\" : \"Public API v2\" } }]} As you can see, the OTM component name is coming from the custom name in the MTMT, in our case Public API v2 . Mobile Client Component The Mobile Client component is a special case that needs a little customization in the mapping file. Because from the threat modeling point of view is not the same an Android than a iOS, we need to know which type of component is based in its Mobile Client Tecnologies property configured in the mapping file. Let's see how to do it: - label : Mobile Client key : Mobile Client Technologies values : - value : Android type : android-device-client - value : iOS type : ios-device-client - The label is the component type - The key is the property of the component where we are going to extract the value - The values is a map to convert from the MTMT value of the property to the OTM type Dataflows No need to be in the mapping file. StartLeft will detect them and will fill the OTM dataflow automatically detecting the custom name, the source, and the destination. Threats and Mitigations No need to be in the mapping file. StartLeft will extract OTM threats and threat instances, as well as OTM mitigations and mitigation instances from the same MTMT threat. Moreover, the OTM component to which the OTM threat instance will be added is the destination component of the MTMT threat. Currently, Startleft maps threats and mitigations from two kinds of templates: SDL TM Knowledge Base (Core) template A MTMT threat will be mapped to an OTM threat: { \"name\" : \"Web Application Process Memory Tampered\" , \"id\" : \"30\" , \"categories\" : [ \"Tampering\" ], \"risk\" : { \"likelihood\" : 100 , \"impact\" : 100 }, \"description\" : \"If Web Application is given access to memory, such as shared memory or pointers, or is given the ability to control what Web Service executes (for example, passing back a function pointer.), then Web Application can tamper with Web Service\" } to an OTM mitigation: { \"name\" : \"Consider if the function could work with less access to memory, such as passing data rather than pointers\" , \"id\" : \"30\" , \"riskReduction\" : 100 , \"description\" : \"Consider if the function could work with less access to memory, such as passing data rather than pointers. Copy in data provided, and then validate it\" } and also to an OTM threat instance along with its OTM mitigation instance, which will be mapped to the corresponding OTM component: { \"threat\" : \"30\" , \"state\" : \"AutoGenerated\" , \"mitigations\" : [ { \"mitigation\" : \"30\" , \"state\" : \"RECOMMENDED\" } ] } There is a special case when the MTMT threat has no \". Consider\" pattern in the \"Description\" field. In such case, no OTM mitigation nor OTM mitigation instance will be mapped, only the OTM threat and threat instance can be mapped. Azure Threat Model Template (AzureArchitecture) template A MTMT threat without a \"Steps\" field will be mapped to an OTM threat: { \"name\" : \"An adversary may read and/or tamper with the data transmitted to Azure Postgres DB due to weak configuration\" , \"id\" : \"1\" , \"categories\" : [ \"Tampering\" ], \"risk\" : { \"likelihood\" : 100 , \"impact\" : 100 }, \"description\" : \"An adversary may read and/or tamper with the data transmitted to Accounting PostgreSQL due to weak configuration\" } to an OTM Mitigation: { \"name\" : \"Enforce communication between clients and Azure Postgres DB to be over SSL/TLS by enabling the Enforce SSL connection feature on the server\" , \"id\" : \"1\" , \"riskReduction\" : 100 , \"description\" : \"Enforce communication between clients and Azure Postgres DB to be over SSL/TLS by enabling the Enforce SSL connection feature on the server. Check that the connection strings used to connect to MySQL databases have the right configuration (e.g. ssl = true or sslmode=require or sslmode=true are set). Refer: <a href=\\\"https://aka.ms/tmt-th154a\\\">https://aka.ms/tmt-th154a</a> Configure MySQL server to use a verifiable SSL certificate (needed for SSL/TLS communication). Refer: <a href=\\\"https://aka.ms/tmt-th154b\\\">https://aka.ms/tmt-th154b</a>\" } A MTMT threat with a \"Steps\" field will be mapped to an OTM threat: { \"name\" : \"An adversary can access Azure storage blobs and containers anonymously\" , \"id\" : \"27\" , \"categories\" : [ \"Spoofing\" ], \"risk\" : { \"likelihood\" : 100 , \"impact\" : 100 }, \"description\" : \"An adversary can gain access to Azure storage containers and blobs if anonymous access is provided to potentially sensitive data accidentally\" } to an OTM mitigation: { \"name\" : \"Ensure that only the required containers and blobs are given anonymous read access\" , \"id\" : \"27\" , \"riskReduction\" : 100 , \"description\" : \"By default, a container and any blobs within it may be accessed only by the owner of the storage account. To give anonymous users read permissions to a container and its blobs, one can set the container permissions to allow public access. Anonymous users can read blobs within a publicly accessible container without authenticating the request. Containers provide the following options for managing container access: Full public read access: Container and blob data can be read via anonymous request. Clients can enumerate blobs within the container via anonymous request, but cannot enumerate containers within the storage account. Public read access for blobs only: Blob data within this container can be read via anonymous request, but container data is not available. Clients cannot enumerate blobs within the container via anonymous request No public read access: Container and blob data can be read by the account owner only Anonymous access is best for scenarios where certain blobs should always be available for anonymous read access. For finer-grained control, one can create a shared access signature, which enables to delegate restricted access using different permissions and over a specified time interval. Ensure that containers and blobs, which may potentially contain sensitive data, are not given anonymous access accidentally\" } and, in both cases, also to an OTM threat instance along with its OTM mitigation instance, which will be mapped to the corresponding OTM component: { \"threat\" : \"27\" , \"state\" : \"AutoGenerated\" , \"mitigations\" : [ { \"mitigation\" : \"27\" , \"state\" : \"RECOMMENDED\" } ] }","title":"MTMT Mapping"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Mapping/#mtmt-mapping","text":"A source mapping file (or 'mapping file' for short) describe how to identify components, dataflows, TrustZones, threats and mitigations in source file and how to map them to the OTM equivalent. Let's see how to identify the different elements:","title":"MTMT mapping"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Mapping/#trustzones","text":"For the TrustZones we need to write two fields: label and id The label will identify the MTMT TrustZone by its type. Let's see an example with a TrustZone in the MTMT_example.tm7: Our TrustZone named Internet is of Generic Trust Border Boundary type. So we need to put this type in the label value. The type in the mapping file will be the type in the OTM trust zone output. In this example, the Generic Trust Border Boundary source trust zones will be mapped to a OTM trust zone which type will be the value of the type in our mapping file. - label : Generic Trust Border Boundary type : 6376d53e-6461-412b-8e04-7b3fe2b397de In the OTM each trust zone will have a unique id and the type will be the type that we put in the mapping file The TrustZone OTM output will be: { \"trustZones\" : [ { \"id\" : \"7537441a-1c03-48c0-b9c8-f82d5906c139\" , \"name\" : \"Internet\" , \"type\" : \"6376d53e-6461-412b-8e04-7b3fe2b397de\" , \"risk\" : { \"trustRating\" : 10 }, \"properties\" : { \"Name\" : \"Internet\" } }]} In case we have two trust zones with the same type, the OTM will have two trust zones with the same type but different id. In the mapping file is enough having mapped once: - label : Generic Trust Border Boundary type : 6376d53e-6461-412b-8e04-7b3fe2b397de With two trust zones of the same type the OTM output will be: { \"trustZones\" : [ { \"id\" : \"7537441a-1c03-48c0-b9c8-f82d5906c139\" , \"name\" : \"Internet\" , \"type\" : \"6376d53e-6461-412b-8e04-7b3fe2b397de\" , \"risk\" : { \"trustRating\" : 10 }, \"properties\" : { \"Name\" : \"Internet\" } }, { \"id\" : \"bd837730-6a59-11ed-a798-772dcc832e1d\" , \"name\" : \"Public zone\" , \"type\" : \"6376d53e-6461-412b-8e04-7b3fe2b397de\" , \"risk\" : { \"trustRating\" : 10 }, \"properties\" : { \"Name\" : \"Public zone\" } } ]} The id of the trust zone in the OTM will be the MTMT original component id in the source file Due to a backward compatibility StartLeft accepts as well the legacy mapping file format. Please read Legacy-Mapping-File-Format","title":"Trustzones"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Mapping/#components","text":"For the components we need to write two fields: label and type . The label will identify the MTMT component by its MTMT type. Let's see again the MTMT_example.tm7: Our Public API v2 component is of Web API type. So we need to put this type in the label value. The type in the mapping file will be the type in the OTM component output. - label : Web API type : web-service The component OTM output will be: { \"components\" : [ { \"id\" : \"5d15323e-3729-4694-87b1-181c90af5045\" , \"name\" : \"Public API v2\" , \"type\" : \"web-service\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"properties\" : { \"Name\" : \"Public API v2\" } }]} As you can see, the OTM component name is coming from the custom name in the MTMT, in our case Public API v2 .","title":"Components"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Mapping/#mobile-client-component","text":"The Mobile Client component is a special case that needs a little customization in the mapping file. Because from the threat modeling point of view is not the same an Android than a iOS, we need to know which type of component is based in its Mobile Client Tecnologies property configured in the mapping file. Let's see how to do it: - label : Mobile Client key : Mobile Client Technologies values : - value : Android type : android-device-client - value : iOS type : ios-device-client - The label is the component type - The key is the property of the component where we are going to extract the value - The values is a map to convert from the MTMT value of the property to the OTM type","title":"Mobile Client Component"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Mapping/#dataflows","text":"No need to be in the mapping file. StartLeft will detect them and will fill the OTM dataflow automatically detecting the custom name, the source, and the destination.","title":"Dataflows"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Mapping/#threats-and-mitigations","text":"No need to be in the mapping file. StartLeft will extract OTM threats and threat instances, as well as OTM mitigations and mitigation instances from the same MTMT threat. Moreover, the OTM component to which the OTM threat instance will be added is the destination component of the MTMT threat. Currently, Startleft maps threats and mitigations from two kinds of templates:","title":"Threats and Mitigations"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Mapping/#sdl-tm-knowledge-base-core-template","text":"","title":"SDL TM Knowledge Base (Core) template"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Mapping/#a-mtmt-threat","text":"will be mapped to an OTM threat: { \"name\" : \"Web Application Process Memory Tampered\" , \"id\" : \"30\" , \"categories\" : [ \"Tampering\" ], \"risk\" : { \"likelihood\" : 100 , \"impact\" : 100 }, \"description\" : \"If Web Application is given access to memory, such as shared memory or pointers, or is given the ability to control what Web Service executes (for example, passing back a function pointer.), then Web Application can tamper with Web Service\" } to an OTM mitigation: { \"name\" : \"Consider if the function could work with less access to memory, such as passing data rather than pointers\" , \"id\" : \"30\" , \"riskReduction\" : 100 , \"description\" : \"Consider if the function could work with less access to memory, such as passing data rather than pointers. Copy in data provided, and then validate it\" } and also to an OTM threat instance along with its OTM mitigation instance, which will be mapped to the corresponding OTM component: { \"threat\" : \"30\" , \"state\" : \"AutoGenerated\" , \"mitigations\" : [ { \"mitigation\" : \"30\" , \"state\" : \"RECOMMENDED\" } ] } There is a special case when the MTMT threat has no \". Consider\" pattern in the \"Description\" field. In such case, no OTM mitigation nor OTM mitigation instance will be mapped, only the OTM threat and threat instance can be mapped.","title":"A MTMT threat"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Mapping/#azure-threat-model-template-azurearchitecture-template","text":"","title":"Azure Threat Model Template (AzureArchitecture) template"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Mapping/#a-mtmt-threat-without-a-steps-field","text":"will be mapped to an OTM threat: { \"name\" : \"An adversary may read and/or tamper with the data transmitted to Azure Postgres DB due to weak configuration\" , \"id\" : \"1\" , \"categories\" : [ \"Tampering\" ], \"risk\" : { \"likelihood\" : 100 , \"impact\" : 100 }, \"description\" : \"An adversary may read and/or tamper with the data transmitted to Accounting PostgreSQL due to weak configuration\" } to an OTM Mitigation: { \"name\" : \"Enforce communication between clients and Azure Postgres DB to be over SSL/TLS by enabling the Enforce SSL connection feature on the server\" , \"id\" : \"1\" , \"riskReduction\" : 100 , \"description\" : \"Enforce communication between clients and Azure Postgres DB to be over SSL/TLS by enabling the Enforce SSL connection feature on the server. Check that the connection strings used to connect to MySQL databases have the right configuration (e.g. ssl = true or sslmode=require or sslmode=true are set). Refer: <a href=\\\"https://aka.ms/tmt-th154a\\\">https://aka.ms/tmt-th154a</a> Configure MySQL server to use a verifiable SSL certificate (needed for SSL/TLS communication). Refer: <a href=\\\"https://aka.ms/tmt-th154b\\\">https://aka.ms/tmt-th154b</a>\" }","title":"A MTMT threat without a \"Steps\" field"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Mapping/#a-mtmt-threat-with-a-steps-field","text":"will be mapped to an OTM threat: { \"name\" : \"An adversary can access Azure storage blobs and containers anonymously\" , \"id\" : \"27\" , \"categories\" : [ \"Spoofing\" ], \"risk\" : { \"likelihood\" : 100 , \"impact\" : 100 }, \"description\" : \"An adversary can gain access to Azure storage containers and blobs if anonymous access is provided to potentially sensitive data accidentally\" } to an OTM mitigation: { \"name\" : \"Ensure that only the required containers and blobs are given anonymous read access\" , \"id\" : \"27\" , \"riskReduction\" : 100 , \"description\" : \"By default, a container and any blobs within it may be accessed only by the owner of the storage account. To give anonymous users read permissions to a container and its blobs, one can set the container permissions to allow public access. Anonymous users can read blobs within a publicly accessible container without authenticating the request. Containers provide the following options for managing container access: Full public read access: Container and blob data can be read via anonymous request. Clients can enumerate blobs within the container via anonymous request, but cannot enumerate containers within the storage account. Public read access for blobs only: Blob data within this container can be read via anonymous request, but container data is not available. Clients cannot enumerate blobs within the container via anonymous request No public read access: Container and blob data can be read by the account owner only Anonymous access is best for scenarios where certain blobs should always be available for anonymous read access. For finer-grained control, one can create a shared access signature, which enables to delegate restricted access using different permissions and over a specified time interval. Ensure that containers and blobs, which may potentially contain sensitive data, are not given anonymous access accidentally\" } and, in both cases, also to an OTM threat instance along with its OTM mitigation instance, which will be mapped to the corresponding OTM component: { \"threat\" : \"27\" , \"state\" : \"AutoGenerated\" , \"mitigations\" : [ { \"mitigation\" : \"27\" , \"state\" : \"RECOMMENDED\" } ] }","title":"A MTMT threat with a \"Steps\" field"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Quickstart/","text":"MTMT Quickstart What is MTMT? From the official Microsoft Threat Model Tool page : The Threat Modeling Tool is a core element of the Microsoft Security Development Lifecycle (SDL). It allows software architects to identify and mitigate potential security issues. From the point of view of StartLeft, a MTMT file is an external threat model (external because is not OTM) input source which has information about: The diagram: With stencils, TrustZones and dataflows, their relationships and their visual representation. The threats. The mitigations. In Starleft we have available the slp_mtmt processor to import a MTM file. The slp_mtmt processor The slp_mtmt module is the StartLeft Processor responsible for processing MTMT files into OTM. Its operation is based on a mapping file that enables the users to define the translations between: The source stencils types and the OTM components output. The source TrustZones and the OTM TrustZones output. Once you got familiarized with the basics explained in this page, you will need to know more about how to use the processor in order to create the mapping file for a successful conversion from MTMT to OTM. For that, you should take a look to this page: Detailed information about how to build your own mapping files in the MTMT mapping page . A basic example This is a very basic threat model example from MTMT that you can use as source_file to test the endpoint You can find the source MTMT_example.tm7 file inside the examples directory MTMT support For MTMT we have available this endpoint POST /api/v1/startleft/external-threat-model Request Body: source_file: Required. File that contains the original threat model source_type: Required. Type of source file: MTMT id: Required. ID of the new project name: Required. Name of the new project default_mapping_file: Required. File that contains the default mapping file between the diagram resources and threat model resources MTMT file The source_file field must contain a valid tm7 file. StartLeft supports only the tm7 format for Microsoft Threat Modeling Tool. Default mapping file The aim of this mapping file is to map the MTMT elements from templates such as the Azure template. To know how to build your own mapping-file, please read MTMT-Mapping CLI Note : Before continue, make sure you have StartLeft properly installed in your machine. First of all, retrieve all the necessary files: Download the MTMT_example.tm7 and mtmt_default_mapping_example.yaml files from here . Now we are going to execute StartLeft for these files so that a basic-mtmt-example.otm file will be generated in our working directory. startleft parse \\ --etm-type MTMT \\ --default-mapping-file mtmt_default_mapping_example.yaml \\ --output-file basic-mtmt-example.otm \\ --project-id \"my-mtmt\" \\ --project-name \"My MTMT Basic Example\" \\ MTMT_example.tm7 cURL For work with the API, in first place we need to have StartLeft properly installed After that, set up the server with the command: startleft server If you want to run the server in a specific port, you can do: startleft server -p 8080 Then, execute the following command to retrieve the OTM file with your MTMT file: curl --location --request POST localhost:5000/api/v1/startleft/external-threat-model \\ --header \"Content-Type: multipart/form-data\" \\ --header \"Accept: application/json\" \\ --form source_type = \"MTMT\" \\ --form source_file = @ \"./MTMT_example.tm7\" \\ --form default_mapping_file = @ \"./mtmt_default_mapping_example.yaml\" \\ --form id = \"my-mtmt-project\" \\ --form name = \"My MTMT project\" Position of the elements For details about how we map the position of the elements, please read MTMT-elements-position.md .","title":"MTMT Quickstart"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Quickstart/#mtmt-quickstart","text":"","title":"MTMT Quickstart"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Quickstart/#what-is-mtmt","text":"From the official Microsoft Threat Model Tool page : The Threat Modeling Tool is a core element of the Microsoft Security Development Lifecycle (SDL). It allows software architects to identify and mitigate potential security issues. From the point of view of StartLeft, a MTMT file is an external threat model (external because is not OTM) input source which has information about: The diagram: With stencils, TrustZones and dataflows, their relationships and their visual representation. The threats. The mitigations. In Starleft we have available the slp_mtmt processor to import a MTM file.","title":"What is MTMT?"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Quickstart/#the-slp_mtmt-processor","text":"The slp_mtmt module is the StartLeft Processor responsible for processing MTMT files into OTM. Its operation is based on a mapping file that enables the users to define the translations between: The source stencils types and the OTM components output. The source TrustZones and the OTM TrustZones output. Once you got familiarized with the basics explained in this page, you will need to know more about how to use the processor in order to create the mapping file for a successful conversion from MTMT to OTM. For that, you should take a look to this page: Detailed information about how to build your own mapping files in the MTMT mapping page .","title":"The slp_mtmt processor"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Quickstart/#a-basic-example","text":"This is a very basic threat model example from MTMT that you can use as source_file to test the endpoint You can find the source MTMT_example.tm7 file inside the examples directory","title":"A basic example"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Quickstart/#mtmt-support","text":"For MTMT we have available this endpoint POST /api/v1/startleft/external-threat-model Request Body: source_file: Required. File that contains the original threat model source_type: Required. Type of source file: MTMT id: Required. ID of the new project name: Required. Name of the new project default_mapping_file: Required. File that contains the default mapping file between the diagram resources and threat model resources","title":"MTMT support"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Quickstart/#mtmt-file","text":"The source_file field must contain a valid tm7 file. StartLeft supports only the tm7 format for Microsoft Threat Modeling Tool.","title":"MTMT file"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Quickstart/#default-mapping-file","text":"The aim of this mapping file is to map the MTMT elements from templates such as the Azure template. To know how to build your own mapping-file, please read MTMT-Mapping","title":"Default mapping file"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Quickstart/#cli","text":"Note : Before continue, make sure you have StartLeft properly installed in your machine. First of all, retrieve all the necessary files: Download the MTMT_example.tm7 and mtmt_default_mapping_example.yaml files from here . Now we are going to execute StartLeft for these files so that a basic-mtmt-example.otm file will be generated in our working directory. startleft parse \\ --etm-type MTMT \\ --default-mapping-file mtmt_default_mapping_example.yaml \\ --output-file basic-mtmt-example.otm \\ --project-id \"my-mtmt\" \\ --project-name \"My MTMT Basic Example\" \\ MTMT_example.tm7","title":"CLI"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Quickstart/#curl","text":"For work with the API, in first place we need to have StartLeft properly installed After that, set up the server with the command: startleft server If you want to run the server in a specific port, you can do: startleft server -p 8080 Then, execute the following command to retrieve the OTM file with your MTMT file: curl --location --request POST localhost:5000/api/v1/startleft/external-threat-model \\ --header \"Content-Type: multipart/form-data\" \\ --header \"Accept: application/json\" \\ --form source_type = \"MTMT\" \\ --form source_file = @ \"./MTMT_example.tm7\" \\ --form default_mapping_file = @ \"./mtmt_default_mapping_example.yaml\" \\ --form id = \"my-mtmt-project\" \\ --form name = \"My MTMT project\"","title":"cURL"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-Quickstart/#position-of-the-elements","text":"For details about how we map the position of the elements, please read MTMT-elements-position.md .","title":"Position of the elements"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-elements-position/","text":"MTMT elements position StartLeft takes the position information from the border boundaries in order to represent the elements in the OTM at the same canvas position than the original. For this purpose we have: - The Representation for the OTM. - The RepresentationElement for the components and TrustZones. OTM In the representations of the OTM we are going to have a diagram representation, because MTMT has diagram relevant information, such the canvas size. { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"Example Project\" , \"id\" : \"example-project\" }, \"representations\" : [ { \"name\" : \"Microsoft Threat Modeling Tool\" , \"id\" : \"Microsoft Threat Modeling Tool\" , \"type\" : \"threat-model\" }, { \"name\" : \"example-project Diagram Representation\" , \"id\" : \"example-project-diagram\" , \"type\" : \"diagram\" , \"size\" : { \"width\" : 2000 , \"height\" : 2000 } } ]} Representation fields name : The name of this representation. id : The unique id of this representation. This field will be the reference for the TrustZones and components representations. type : The representation supported type. See representation-supported-types . size : The canvas width and height. TrustZones The representations element has two properties for the position info: size position { \"representations\" : [ { \"name\" : \"Cloud Representation\" , \"id\" : \"acafa4b0-f94d-4077-8a42-74b959bd0796-representation\" , \"representation\" : \"example-project-diagram\" , \"size\" : { \"width\" : 535 , \"height\" : 488 }, \"position\" : { \"x\" : 734 , \"y\" : 88 } } ] } TrustZone representation fields name : The name of this representation. id : The unique id of this representation. representation : The id of the OTM representation explained before. size : The width and height of the TrustZone. position : The position relative to the canvas. This applies for the border boundaries TrustZones. The TrustZones delimited by a MTMT line boundary won't have representations because its source size is undefined. Components Into the OTM components we have the representations property too, with the same fields as the TrustZone. The difference between the component representation and the TrustZone representation is the position. While at the TrustZones the position is relative to the canvas, in the components the position is relative to the parent TrustZone. Here an example: { \"components\" : [ { \"id\" : \"53245f54-0656-4ede-a393-357aeaa2e20f\" , \"name\" : \"Accounting PostgreSQL\" , \"type\" : \"CD-MICROSOFT-AZURE-DB-POSTGRESQL\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"properties\" : { \"Name\" : \"Accounting PostgreSQL\" , \"Out Of Scope\" : \"false\" , \"Azure Postgres DB Firewall Settings\" : \"Select\" , \"Azure Postgres DB TLS Enforced\" : \"Select\" }, \"representations\" : [ { \"name\" : \"Accounting PostgreSQL Representation\" , \"id\" : \"53245f54-0656-4ede-a393-357aeaa2e20f-representation\" , \"representation\" : \"example-project-diagram\" , \"size\" : { \"width\" : 100 , \"height\" : 100 }, \"position\" : { \"x\" : 334 , \"y\" : 45 } } ]} ]}","title":"MTMT elements position"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-elements-position/#mtmt-elements-position","text":"StartLeft takes the position information from the border boundaries in order to represent the elements in the OTM at the same canvas position than the original. For this purpose we have: - The Representation for the OTM. - The RepresentationElement for the components and TrustZones.","title":"MTMT elements position"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-elements-position/#otm","text":"In the representations of the OTM we are going to have a diagram representation, because MTMT has diagram relevant information, such the canvas size. { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"Example Project\" , \"id\" : \"example-project\" }, \"representations\" : [ { \"name\" : \"Microsoft Threat Modeling Tool\" , \"id\" : \"Microsoft Threat Modeling Tool\" , \"type\" : \"threat-model\" }, { \"name\" : \"example-project Diagram Representation\" , \"id\" : \"example-project-diagram\" , \"type\" : \"diagram\" , \"size\" : { \"width\" : 2000 , \"height\" : 2000 } } ]}","title":"OTM"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-elements-position/#representation-fields","text":"name : The name of this representation. id : The unique id of this representation. This field will be the reference for the TrustZones and components representations. type : The representation supported type. See representation-supported-types . size : The canvas width and height.","title":"Representation fields"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-elements-position/#trustzones","text":"The representations element has two properties for the position info: size position { \"representations\" : [ { \"name\" : \"Cloud Representation\" , \"id\" : \"acafa4b0-f94d-4077-8a42-74b959bd0796-representation\" , \"representation\" : \"example-project-diagram\" , \"size\" : { \"width\" : 535 , \"height\" : 488 }, \"position\" : { \"x\" : 734 , \"y\" : 88 } } ] }","title":"TrustZones"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-elements-position/#trustzone-representation-fields","text":"name : The name of this representation. id : The unique id of this representation. representation : The id of the OTM representation explained before. size : The width and height of the TrustZone. position : The position relative to the canvas. This applies for the border boundaries TrustZones. The TrustZones delimited by a MTMT line boundary won't have representations because its source size is undefined.","title":"TrustZone representation fields"},{"location":"startleft-processors/external-threat-model/mtmt/MTMT-elements-position/#components","text":"Into the OTM components we have the representations property too, with the same fields as the TrustZone. The difference between the component representation and the TrustZone representation is the position. While at the TrustZones the position is relative to the canvas, in the components the position is relative to the parent TrustZone. Here an example: { \"components\" : [ { \"id\" : \"53245f54-0656-4ede-a393-357aeaa2e20f\" , \"name\" : \"Accounting PostgreSQL\" , \"type\" : \"CD-MICROSOFT-AZURE-DB-POSTGRESQL\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"properties\" : { \"Name\" : \"Accounting PostgreSQL\" , \"Out Of Scope\" : \"false\" , \"Azure Postgres DB Firewall Settings\" : \"Select\" , \"Azure Postgres DB TLS Enforced\" : \"Select\" }, \"representations\" : [ { \"name\" : \"Accounting PostgreSQL Representation\" , \"id\" : \"53245f54-0656-4ede-a393-357aeaa2e20f-representation\" , \"representation\" : \"example-project-diagram\" , \"size\" : { \"width\" : 100 , \"height\" : 100 }, \"position\" : { \"x\" : 334 , \"y\" : 45 } } ]} ]}","title":"Components"},{"location":"startleft-processors/external-threat-model/mtmt/legacy/Legacy-Mapping-File-Format/","text":"Mapping file legacy format Due to a backward compatibility StartLeft accepts the legacy mapping file format. For the current mapping file format, please read MTMT-Mapping Unlike the new mapping file format, the legacy one had the id field, with the identifier of the trust zone type. Legacy format example: trustzones : - label : Generic Trust Border Boundary type : Public Cloud id : 6376d53e-6461-412b-8e04-7b3fe2b397de When we found a Generic Trust Border Boundary in the MTMT file, then a Trustzone is created in the OTM with these fields: - id is the original id in the MTMT file - name is the original name in the MTMT file - type is the mapping's id , if present. If not, will be the mapping's type In the above example the resultant OTM would contain a TrustZone like this: { \"trustZones\" : [ { \"id\" : \"7537441a-1c03-48c0-b9c8-f82d5906c139\" , \"name\" : \"Internet\" , \"type\" : \"6376d53e-6461-412b-8e04-7b3fe2b397de\" , \"risk\" : { \"trustRating\" : 10 }, \"properties\" : { \"Name\" : \"Internet\" } }]}","title":"Legacy Mapping File Format"},{"location":"startleft-processors/external-threat-model/mtmt/legacy/Legacy-Mapping-File-Format/#mapping-file-legacy-format","text":"Due to a backward compatibility StartLeft accepts the legacy mapping file format. For the current mapping file format, please read MTMT-Mapping Unlike the new mapping file format, the legacy one had the id field, with the identifier of the trust zone type. Legacy format example: trustzones : - label : Generic Trust Border Boundary type : Public Cloud id : 6376d53e-6461-412b-8e04-7b3fe2b397de When we found a Generic Trust Border Boundary in the MTMT file, then a Trustzone is created in the OTM with these fields: - id is the original id in the MTMT file - name is the original name in the MTMT file - type is the mapping's id , if present. If not, will be the mapping's type In the above example the resultant OTM would contain a TrustZone like this: { \"trustZones\" : [ { \"id\" : \"7537441a-1c03-48c0-b9c8-f82d5906c139\" , \"name\" : \"Internet\" , \"type\" : \"6376d53e-6461-412b-8e04-7b3fe2b397de\" , \"risk\" : { \"trustRating\" : 10 }, \"properties\" : { \"Name\" : \"Internet\" } }]}","title":"Mapping file legacy format"},{"location":"startleft-processors/iac/cft/CloudFormation-Examples/","text":"CloudFormation Template examples Sources You can find some sample source files inside the examples directory: examples/cloudformation contains CloudFormation Template example files to convert into OTM format. examples/cloudformation/split contains a complete CloudFormation Template example file split into two different files. To process these examples, it is mandatory to use the mapping files according to the file data type. You can find some sample mapping files inside the examples/cloudformation directory. Examples CloudFormation is the AWS tool which lets you model, provision, and manage AWS and third-party resources by treating infrastructure as code. StartLeft's repository contains an example CloudFormation mapping file that enables you to generate threat models based on the OTM standard from both a single or multiple CloudFormation template files using a single command. The following examples, which are located in the examples/cloudformation and examples/cloudformation/split directories, show you how to carry out the different stages of the process separately or in a single step. Security Groups on multinetwork with Load Balancer This is a rich example when you can see in action some the capabilities of StartLeft. It represents the threat model for an architecture with two TrustZones and several Virtual Private Networks which contain elements such as: Elastic Load Balancer . Elastic Container Service . CloudWatch Canary . VPC Endpoint Security Groups mapped as dataflows. The following command will parse the CloudFormation source file multinetwork_security_groups_with_lb.json creating an OTM file multinetwork_security_groups_with_lb.otm in the process. startleft parse \\ --iac-type CLOUDFORMATION \\ --mapping-file iriusrisk-cft-mapping.yaml \\ --output-file multinetwork_security_groups_with_lb.otm \\ --project-name \"CFT MN Security Groups with LB\" \\ --project-id \"cft-mn-sg-lb\" \\ multinetwork_security_groups_with_lb.json Other examples There are inside the StartLeft repositories some other CloudFormation files with different architectures that allow you to experiment with different mappings and options. For them, the same commands described before can be applied. elb-no-waf . This is the simplest example, including only a public cloud as a TrustZone with an AWS Elastic Load Balancer as a single component. elb-with-waf . Slight evolution of elb-no-waf by including another component, a Web Application Firewall, within the same TrustZone public cloud. Split examples In the examples/cloudformation/split directory we have split the multinetwork_security_groups_with_lb.json into two files which are networks_cft_file.json and resources_cft_file.json . The following command will parse both CloudFormation source files creating an OTM file multinetwork_security_groups_with_lb_from_multiple_files.otm in the process. startleft parse \\ --iac-type CLOUDFORMATION \\ --mapping-file iriusrisk-cft-mapping.yaml \\ --output-file multinetwork_security_groups_with_lb_from_multiple_files.otm \\ --project-name \"CFT MN Security Groups with LB from multiple files\" \\ --project-id \"cft-mn-sg-lb-ml-fl\" \\ networks_cft_file.json \\ resources_cft_file.json","title":"CloudFormation Examples"},{"location":"startleft-processors/iac/cft/CloudFormation-Examples/#cloudformation-template-examples","text":"","title":"CloudFormation Template examples"},{"location":"startleft-processors/iac/cft/CloudFormation-Examples/#sources","text":"You can find some sample source files inside the examples directory: examples/cloudformation contains CloudFormation Template example files to convert into OTM format. examples/cloudformation/split contains a complete CloudFormation Template example file split into two different files. To process these examples, it is mandatory to use the mapping files according to the file data type. You can find some sample mapping files inside the examples/cloudformation directory.","title":"Sources"},{"location":"startleft-processors/iac/cft/CloudFormation-Examples/#examples","text":"CloudFormation is the AWS tool which lets you model, provision, and manage AWS and third-party resources by treating infrastructure as code. StartLeft's repository contains an example CloudFormation mapping file that enables you to generate threat models based on the OTM standard from both a single or multiple CloudFormation template files using a single command. The following examples, which are located in the examples/cloudformation and examples/cloudformation/split directories, show you how to carry out the different stages of the process separately or in a single step.","title":"Examples"},{"location":"startleft-processors/iac/cft/CloudFormation-Examples/#security-groups-on-multinetwork-with-load-balancer","text":"This is a rich example when you can see in action some the capabilities of StartLeft. It represents the threat model for an architecture with two TrustZones and several Virtual Private Networks which contain elements such as: Elastic Load Balancer . Elastic Container Service . CloudWatch Canary . VPC Endpoint Security Groups mapped as dataflows. The following command will parse the CloudFormation source file multinetwork_security_groups_with_lb.json creating an OTM file multinetwork_security_groups_with_lb.otm in the process. startleft parse \\ --iac-type CLOUDFORMATION \\ --mapping-file iriusrisk-cft-mapping.yaml \\ --output-file multinetwork_security_groups_with_lb.otm \\ --project-name \"CFT MN Security Groups with LB\" \\ --project-id \"cft-mn-sg-lb\" \\ multinetwork_security_groups_with_lb.json","title":"Security Groups on multinetwork with Load Balancer"},{"location":"startleft-processors/iac/cft/CloudFormation-Examples/#other-examples","text":"There are inside the StartLeft repositories some other CloudFormation files with different architectures that allow you to experiment with different mappings and options. For them, the same commands described before can be applied. elb-no-waf . This is the simplest example, including only a public cloud as a TrustZone with an AWS Elastic Load Balancer as a single component. elb-with-waf . Slight evolution of elb-no-waf by including another component, a Web Application Firewall, within the same TrustZone public cloud.","title":"Other examples"},{"location":"startleft-processors/iac/cft/CloudFormation-Examples/#split-examples","text":"In the examples/cloudformation/split directory we have split the multinetwork_security_groups_with_lb.json into two files which are networks_cft_file.json and resources_cft_file.json . The following command will parse both CloudFormation source files creating an OTM file multinetwork_security_groups_with_lb_from_multiple_files.otm in the process. startleft parse \\ --iac-type CLOUDFORMATION \\ --mapping-file iriusrisk-cft-mapping.yaml \\ --output-file multinetwork_security_groups_with_lb_from_multiple_files.otm \\ --project-name \"CFT MN Security Groups with LB from multiple files\" \\ --project-id \"cft-mn-sg-lb-ml-fl\" \\ networks_cft_file.json \\ resources_cft_file.json","title":"Split examples"},{"location":"startleft-processors/iac/cft/CloudFormation-Mapping/","text":"CloudFormation mapping A source mapping file (or \"mapping files\" for short) describes how to find components, dataflows, and trustzones in source file data structures. To accomplish this, a mapping file contains additional logic around a collection of JMESPath queries which are used. Also, some exclusive StartLeft actions based on JMESPath may be used in mapping files to solve the most complex mappings. Source mapping files are made up of three main sections corresponding to the main sections in an OTM file, plus an optional lookup section described below: trustzones components dataflows Each contains a list of 0 or more objects that describe how to find the respective object in the source file, and each object has a number of required and optional fields. Take a look at the JSONSchema file for more details. JMESPath Queries Special $action fields begin with a dollar sign ($) and do not directly contribute to the OTM output. Instead, they specify an action and behaviour used to process the source files or generate the OTM output. This table describes each special $actions: $action Description Example $source Specifies the source of the object type $source: $root JMESPath search through the entire source file data structure $root: \"Resources|squash(@)[?Type=='AWS::EC2::VPC']\" $path JMESPath search through the object identified in the $source. A default value is optional by using the $searchParams structure $path: \"Type\" $path: \"Properties.VpcId.Ref\" $path: {$searchParams:{ searchPath: \"Properties.SubnetId.Ref\", defaultValue: \"b61d6911-338d-46a8-9f39-8dcd24abfe91\"}} $findFirst JMESPath search through the list of objects identified in the $source and returning the first successful match. A default value is optional by using the $searchParams structure $findFirst: [\"Properties.FunctionName.Ref\", \"Properties.FunctionName\"] $findFirst: {$searchParams:{ searchPath: [\"Properties.SubnetId.Ref\",\"Properties.SubnetId\"], defaultValue: \"b61d6911-338d-46a8-9f39-8dcd24abfe91\"}} $format A named format string based on the output of other $special fields. Note, only to be used for id fields. $format: \"{name}\" $catchall A sub-field of $source, specifying a default search for all other objects not explicitly defined $catchall: $skip A sub-field of $source, specifying specific objects to skip if not explicitly defined $skip: $singleton A sub-field of $source, specifying specific objects to be unified under a single component or trustzone $singleton: $numberOfSources When using singleton, allows you to set different values for output name or tags when the number of sources for the same mapping are single or multiple $numberOfSources: {oneSource:{$path: \"_key\"}, multipleSource:{ $format: \"CD-ACM (grouped)\" }} $altsource Specifies an alternative mapping when $source returns no object. $altsource: - $mappingType: {$root: \"Resources|squash(@)[?Type=='AWS::EC2::VPCEndpoint']\"} $mappingPath: {$path: \"Properties.ServiceName\"} $mappingLookups: - regex: ^(.*)s3$ name: S3 from VPCEndpoint type: s3 $lookup Allows you to look up the output of a $special field against a key-value lookup table $lookup: $hub Only for dataflow's \"source\" and \"destination\" fields. Especially created for building dataflows from Security Group structures without generating components from them. Allows to define abstract contact points for larger end-to-end final dataflows destination: {$hub: {$path: \"Properties.GroupId\"}} $ip When defining a component's \"name\" field as $ip, will generate a singleton component for representing an external IP but without limitations of singleton for this case, so the \"type\" for the defined mapping definition with $ip (i.e. generic-terminal) will not be catalogued as singleton. name: { $ip: { $path: \"Properties.SecurityGroupEgress[0].CidrIp\" } } For more information on how to create a JMESPath search query, check out the website . Hardcoded values In addition to using $source and other special $actions, you can also just hardcode values which will be taken and mapped as is. For example, you may want to specify a default trustzone which wouldn't be found anywhere in the source files. You can do this easily just by adding it to a mapping file: trustzones: - id: tz1 name: Default type: default-zone The id field uniquely identifies a trustzone, and differentiates it from other trustzones of the same type. For mapping trustzones to IriusRisk trustzones, type field must take internal IriusRisk values depending on the type of trustzone. These values are defined in the internal CloudFormation mapping file. For the purpose of preserving backwards compatibility, StartLeft also accepts the legacy mapping file format. In this format, there is no type field and the id will be used as both, ID and type. It is not possible to have multiple trustzones of the same type when using this format. Lookup table Just in case there are some inconsistencies in naming conventions used, and you need to be able to translate one name into another, a simple lookup key-value table section can be added to the mapping file. For example, if we have a situation where a subnet name is written using a short naming convention, but is actually referred to via a longer name elsewhere, we can use the $lookup action. parent: $lookup: {$path: \"Properties.Subnets[]|map(&values(@), @)[]|map(&re_sub('[:]', '-', @), @)\"} If the above query returns a subnet called shortnameA , then it will be looked up in the below table: lookup: shortnameA: amuchlongernameA shortnameB: amuchlongernameB To give a final value of amuchlongernameA . Additional JMESPath functions Parsing of IaC files may be sometimes complex, so that the built-in JMESPath described above are not enough. For those cases, a set of custom functions has been created to simplify and make more powerful the creation of mapping files. re_sub The re_sub function replaces the occurrences of pattern with replace in the given string . def _func_re_sub ( self , pattern , replace , origin_string ) For example, we may want to replace colon characters with hyphens such as in re_sub('[:]', '-', 'stack:subnet') . squash The squash function takes a nested object of objects, and squashes them into a list of objects, injecting the parent \"key\" to the child object as \"_key\". def _func_squash ( self , obj ) This function is specially useful for Cloudformation mapping files. These have a root Resources object whose top level keys are the resource names which have the resource objects as values. This structure is hard to iterate over without losing the important name key. So you can use squash and refer to the name through the _key field. name : { $path : \"_key\" } $source : { $root : \"Resources|squash(@)[?Type=='AWS::EC2::Subnet']\" } tail The tail function returns the characters of a given string from the count index onwards. It is equivalent to python's string[count:] . def _func_tail ( self , string , count ) get_starts_with This function is equivalent to get , but instead of using the component_type argument to perform an exact filter, the target component type must start with it. def _func_get_starts_with ( self , obj_arr , component_type ) split The split function is the equivalent to the python's one. It breaks a given string based on a given separator and returns the resulting array of strings. It is equivalent to python's split function.","title":"CloudFormation Mapping"},{"location":"startleft-processors/iac/cft/CloudFormation-Mapping/#cloudformation-mapping","text":"A source mapping file (or \"mapping files\" for short) describes how to find components, dataflows, and trustzones in source file data structures. To accomplish this, a mapping file contains additional logic around a collection of JMESPath queries which are used. Also, some exclusive StartLeft actions based on JMESPath may be used in mapping files to solve the most complex mappings. Source mapping files are made up of three main sections corresponding to the main sections in an OTM file, plus an optional lookup section described below: trustzones components dataflows Each contains a list of 0 or more objects that describe how to find the respective object in the source file, and each object has a number of required and optional fields. Take a look at the JSONSchema file for more details.","title":"CloudFormation mapping"},{"location":"startleft-processors/iac/cft/CloudFormation-Mapping/#jmespath-queries","text":"Special $action fields begin with a dollar sign ($) and do not directly contribute to the OTM output. Instead, they specify an action and behaviour used to process the source files or generate the OTM output. This table describes each special $actions: $action Description Example $source Specifies the source of the object type $source: $root JMESPath search through the entire source file data structure $root: \"Resources|squash(@)[?Type=='AWS::EC2::VPC']\" $path JMESPath search through the object identified in the $source. A default value is optional by using the $searchParams structure $path: \"Type\" $path: \"Properties.VpcId.Ref\" $path: {$searchParams:{ searchPath: \"Properties.SubnetId.Ref\", defaultValue: \"b61d6911-338d-46a8-9f39-8dcd24abfe91\"}} $findFirst JMESPath search through the list of objects identified in the $source and returning the first successful match. A default value is optional by using the $searchParams structure $findFirst: [\"Properties.FunctionName.Ref\", \"Properties.FunctionName\"] $findFirst: {$searchParams:{ searchPath: [\"Properties.SubnetId.Ref\",\"Properties.SubnetId\"], defaultValue: \"b61d6911-338d-46a8-9f39-8dcd24abfe91\"}} $format A named format string based on the output of other $special fields. Note, only to be used for id fields. $format: \"{name}\" $catchall A sub-field of $source, specifying a default search for all other objects not explicitly defined $catchall: $skip A sub-field of $source, specifying specific objects to skip if not explicitly defined $skip: $singleton A sub-field of $source, specifying specific objects to be unified under a single component or trustzone $singleton: $numberOfSources When using singleton, allows you to set different values for output name or tags when the number of sources for the same mapping are single or multiple $numberOfSources: {oneSource:{$path: \"_key\"}, multipleSource:{ $format: \"CD-ACM (grouped)\" }} $altsource Specifies an alternative mapping when $source returns no object. $altsource: - $mappingType: {$root: \"Resources|squash(@)[?Type=='AWS::EC2::VPCEndpoint']\"} $mappingPath: {$path: \"Properties.ServiceName\"} $mappingLookups: - regex: ^(.*)s3$ name: S3 from VPCEndpoint type: s3 $lookup Allows you to look up the output of a $special field against a key-value lookup table $lookup: $hub Only for dataflow's \"source\" and \"destination\" fields. Especially created for building dataflows from Security Group structures without generating components from them. Allows to define abstract contact points for larger end-to-end final dataflows destination: {$hub: {$path: \"Properties.GroupId\"}} $ip When defining a component's \"name\" field as $ip, will generate a singleton component for representing an external IP but without limitations of singleton for this case, so the \"type\" for the defined mapping definition with $ip (i.e. generic-terminal) will not be catalogued as singleton. name: { $ip: { $path: \"Properties.SecurityGroupEgress[0].CidrIp\" } } For more information on how to create a JMESPath search query, check out the website .","title":"JMESPath Queries"},{"location":"startleft-processors/iac/cft/CloudFormation-Mapping/#hardcoded-values","text":"In addition to using $source and other special $actions, you can also just hardcode values which will be taken and mapped as is. For example, you may want to specify a default trustzone which wouldn't be found anywhere in the source files. You can do this easily just by adding it to a mapping file: trustzones: - id: tz1 name: Default type: default-zone The id field uniquely identifies a trustzone, and differentiates it from other trustzones of the same type. For mapping trustzones to IriusRisk trustzones, type field must take internal IriusRisk values depending on the type of trustzone. These values are defined in the internal CloudFormation mapping file. For the purpose of preserving backwards compatibility, StartLeft also accepts the legacy mapping file format. In this format, there is no type field and the id will be used as both, ID and type. It is not possible to have multiple trustzones of the same type when using this format.","title":"Hardcoded values"},{"location":"startleft-processors/iac/cft/CloudFormation-Mapping/#lookup-table","text":"Just in case there are some inconsistencies in naming conventions used, and you need to be able to translate one name into another, a simple lookup key-value table section can be added to the mapping file. For example, if we have a situation where a subnet name is written using a short naming convention, but is actually referred to via a longer name elsewhere, we can use the $lookup action. parent: $lookup: {$path: \"Properties.Subnets[]|map(&values(@), @)[]|map(&re_sub('[:]', '-', @), @)\"} If the above query returns a subnet called shortnameA , then it will be looked up in the below table: lookup: shortnameA: amuchlongernameA shortnameB: amuchlongernameB To give a final value of amuchlongernameA .","title":"Lookup table"},{"location":"startleft-processors/iac/cft/CloudFormation-Mapping/#additional-jmespath-functions","text":"Parsing of IaC files may be sometimes complex, so that the built-in JMESPath described above are not enough. For those cases, a set of custom functions has been created to simplify and make more powerful the creation of mapping files.","title":"Additional JMESPath functions"},{"location":"startleft-processors/iac/cft/CloudFormation-Mapping/#re_sub","text":"The re_sub function replaces the occurrences of pattern with replace in the given string . def _func_re_sub ( self , pattern , replace , origin_string ) For example, we may want to replace colon characters with hyphens such as in re_sub('[:]', '-', 'stack:subnet') .","title":"re_sub"},{"location":"startleft-processors/iac/cft/CloudFormation-Mapping/#squash","text":"The squash function takes a nested object of objects, and squashes them into a list of objects, injecting the parent \"key\" to the child object as \"_key\". def _func_squash ( self , obj ) This function is specially useful for Cloudformation mapping files. These have a root Resources object whose top level keys are the resource names which have the resource objects as values. This structure is hard to iterate over without losing the important name key. So you can use squash and refer to the name through the _key field. name : { $path : \"_key\" } $source : { $root : \"Resources|squash(@)[?Type=='AWS::EC2::Subnet']\" }","title":"squash"},{"location":"startleft-processors/iac/cft/CloudFormation-Mapping/#tail","text":"The tail function returns the characters of a given string from the count index onwards. It is equivalent to python's string[count:] . def _func_tail ( self , string , count )","title":"tail"},{"location":"startleft-processors/iac/cft/CloudFormation-Mapping/#get_starts_with","text":"This function is equivalent to get , but instead of using the component_type argument to perform an exact filter, the target component type must start with it. def _func_get_starts_with ( self , obj_arr , component_type )","title":"get_starts_with"},{"location":"startleft-processors/iac/cft/CloudFormation-Mapping/#split","text":"The split function is the equivalent to the python's one. It breaks a given string based on a given separator and returns the resulting array of strings. It is equivalent to python's split function.","title":"split"},{"location":"startleft-processors/iac/cft/CloudFormation-Quickstart/","text":"CloudFormation Quickstart What is CloudFormation? From the official AWS CloudFormation page : AWS CloudFormation is a service that gives developers and businesses an easy way to create a collection of related AWS and third-party resources, and provision and manage them in an orderly and predictable fashion. From the StartLeft's perspective, a CloudFormation Template (CFT) is a file that defines a set of components with relationships among them which can be interpreted to create a threat model. The slp_cft module The slp_cft module is the StartLeft Processor responsible for converting CFT files into OTM. Its operation is based on a mapping file that enables the users to define the translations between the source AWS types and the expected output in the OTM file. Once you got familiarized with the basics explained on this page, you will need to know more about how to use and customize the behavior of the processor in order to configure your own conversions. For that, you should take a look at the CloudFormation mapping page , where you will find all the information you need, from basic to advanced, to build your own CFT mapping files. Apart from this, you may also find interesting the generic usage manuals for the CLI and REST API . A basic example Let's suppose you have a CFT file with a single AWS::EC2:Instance like this: Whose source code is: { \"AWSTemplateFormatVersion\" : \"2010-09-09\" , \"Metadata\" : { \"AWS::CloudFormation::Designer\" : { \"a7e8649b-4100-4217-8aff-3342e0afa392\" : { \"size\" : { \"width\" : 60 , \"height\" : 60 }, \"position\" : { \"x\" : 120 , \"y\" : 450 }, \"z\" : 0 , \"embeds\" : [] } } }, \"Resources\" : { \"MyEC2Instance\" : { \"Type\" : \"AWS::EC2::Instance\" , \"Properties\" : {}, \"Metadata\" : { \"AWS::CloudFormation::Designer\" : { \"id\" : \"a7e8649b-4100-4217-8aff-3342e0afa392\" } } } } } And you want to translate it to OTM in order to import it into IriusRisk , whose equivalent type for an EC2 instance is an ec2 component and the expected resultant project should be like this: In that case, you will need a mapping file which contains, at least, a TrustZone and the mapping for the EC2 component. Notice that the standard requires that all the components must have a parent, in this case, the Public Cloud TrustZone. This mapping file could be as simple as this: trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 components : - id : { $format : \"{name}\" } type : ec2 name : { $path : \"_key\" } $source : { $root : \"Resources|squash(@)[?Type=='AWS::EC2::Instance']\" } parent : public-cloud-01 tags : - { $path : \"Type\" } dataflows : [] The combination of this CFT and mapping file will result in the OTM file below, that contains the mapped TrustZone and component along with all the necessary metadata defined by the standard and that is ready to be imported into a threat modeling tool like IriusRisk. { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"My EC2 project\" , \"id\" : \"my-ec2-project\" }, \"representations\" : [ { \"name\" : \"CloudFormation\" , \"id\" : \"CloudFormation\" , \"type\" : \"code\" } ], \"trustZones\" : [ { \"id\" : \"public-cloud-01\" , \"name\" : \"Public Cloud\" , \"type\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"risk\" : { \"trustRating\" : 10 } } ], \"components\" : [ { \"id\" : \"public-cloud-01.myec2instance\" , \"name\" : \"MyEC2Instance\" , \"type\" : \"ec2\" , \"parent\" : { \"trustZone\" : \"public-cloud-01\" }, \"tags\" : [ \"AWS::EC2::Instance\" ] } ], \"dataflows\" : [] } CLI Note : Before continuing, make sure you have StartLeft properly installed on your machine. Save the files above in your file system with these names: ec2-cft.json for the CloudFormation Template file. ec2-mapping.yaml for the mapping file. Now we are going to execute StartLeft for these files so that an ec2.otm file will be generated in our working directory with identical contents to the one above. startleft parse \\ --iac-type CLOUDFORMATION \\ --mapping-file ec2-mapping.yaml \\ --output-file ec2.otm \\ --project-id \"my-ec2-project\" \\ --project-name \"My EC2 project\" \\ ec2-cft.json cURL You can get the same result through the StartLeft's REST API. For that, in the first place we need to set up the server with the command: startleft server If you want to run the server in a specific port, you can do: startleft server -p 8080 Then, execute the following command to retrieve the OTM file with your EC2 component: curl --location --request POST localhost:5000/api/v1/startleft/iac \\ --header \"Content-Type: multipart/form-data\" \\ --header \"Accept: application/json\" \\ --form iac_type = \"CLOUDFORMATION\" \\ --form iac_file = @ \"./ec2-cft.json\" \\ --form mapping_file = @ \"./ec2-mapping.yaml\" \\ --form id = \"my-ec2-project\" \\ --form name = \"My EC2 project\" More examples The infrastructure built with CloudFormation Templates may be as complex as you want. This is the reason because StartLeft, through the mapping files, is intended to be configurable, so you can extend or modify its behavior and/or create your own mappings on demand. To help you to walk through more complex situations with larger CFT and mapping files, we have created a page with explained CFT examples which may be useful for you as a base for building your own mapping files.","title":"CloudFormation Quickstart"},{"location":"startleft-processors/iac/cft/CloudFormation-Quickstart/#cloudformation-quickstart","text":"","title":"CloudFormation Quickstart"},{"location":"startleft-processors/iac/cft/CloudFormation-Quickstart/#what-is-cloudformation","text":"From the official AWS CloudFormation page : AWS CloudFormation is a service that gives developers and businesses an easy way to create a collection of related AWS and third-party resources, and provision and manage them in an orderly and predictable fashion. From the StartLeft's perspective, a CloudFormation Template (CFT) is a file that defines a set of components with relationships among them which can be interpreted to create a threat model.","title":"What is CloudFormation?"},{"location":"startleft-processors/iac/cft/CloudFormation-Quickstart/#the-slp_cft-module","text":"The slp_cft module is the StartLeft Processor responsible for converting CFT files into OTM. Its operation is based on a mapping file that enables the users to define the translations between the source AWS types and the expected output in the OTM file. Once you got familiarized with the basics explained on this page, you will need to know more about how to use and customize the behavior of the processor in order to configure your own conversions. For that, you should take a look at the CloudFormation mapping page , where you will find all the information you need, from basic to advanced, to build your own CFT mapping files. Apart from this, you may also find interesting the generic usage manuals for the CLI and REST API .","title":"The slp_cft module"},{"location":"startleft-processors/iac/cft/CloudFormation-Quickstart/#a-basic-example","text":"Let's suppose you have a CFT file with a single AWS::EC2:Instance like this: Whose source code is: { \"AWSTemplateFormatVersion\" : \"2010-09-09\" , \"Metadata\" : { \"AWS::CloudFormation::Designer\" : { \"a7e8649b-4100-4217-8aff-3342e0afa392\" : { \"size\" : { \"width\" : 60 , \"height\" : 60 }, \"position\" : { \"x\" : 120 , \"y\" : 450 }, \"z\" : 0 , \"embeds\" : [] } } }, \"Resources\" : { \"MyEC2Instance\" : { \"Type\" : \"AWS::EC2::Instance\" , \"Properties\" : {}, \"Metadata\" : { \"AWS::CloudFormation::Designer\" : { \"id\" : \"a7e8649b-4100-4217-8aff-3342e0afa392\" } } } } } And you want to translate it to OTM in order to import it into IriusRisk , whose equivalent type for an EC2 instance is an ec2 component and the expected resultant project should be like this: In that case, you will need a mapping file which contains, at least, a TrustZone and the mapping for the EC2 component. Notice that the standard requires that all the components must have a parent, in this case, the Public Cloud TrustZone. This mapping file could be as simple as this: trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 components : - id : { $format : \"{name}\" } type : ec2 name : { $path : \"_key\" } $source : { $root : \"Resources|squash(@)[?Type=='AWS::EC2::Instance']\" } parent : public-cloud-01 tags : - { $path : \"Type\" } dataflows : [] The combination of this CFT and mapping file will result in the OTM file below, that contains the mapped TrustZone and component along with all the necessary metadata defined by the standard and that is ready to be imported into a threat modeling tool like IriusRisk. { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"My EC2 project\" , \"id\" : \"my-ec2-project\" }, \"representations\" : [ { \"name\" : \"CloudFormation\" , \"id\" : \"CloudFormation\" , \"type\" : \"code\" } ], \"trustZones\" : [ { \"id\" : \"public-cloud-01\" , \"name\" : \"Public Cloud\" , \"type\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"risk\" : { \"trustRating\" : 10 } } ], \"components\" : [ { \"id\" : \"public-cloud-01.myec2instance\" , \"name\" : \"MyEC2Instance\" , \"type\" : \"ec2\" , \"parent\" : { \"trustZone\" : \"public-cloud-01\" }, \"tags\" : [ \"AWS::EC2::Instance\" ] } ], \"dataflows\" : [] }","title":"A basic example"},{"location":"startleft-processors/iac/cft/CloudFormation-Quickstart/#cli","text":"Note : Before continuing, make sure you have StartLeft properly installed on your machine. Save the files above in your file system with these names: ec2-cft.json for the CloudFormation Template file. ec2-mapping.yaml for the mapping file. Now we are going to execute StartLeft for these files so that an ec2.otm file will be generated in our working directory with identical contents to the one above. startleft parse \\ --iac-type CLOUDFORMATION \\ --mapping-file ec2-mapping.yaml \\ --output-file ec2.otm \\ --project-id \"my-ec2-project\" \\ --project-name \"My EC2 project\" \\ ec2-cft.json","title":"CLI"},{"location":"startleft-processors/iac/cft/CloudFormation-Quickstart/#curl","text":"You can get the same result through the StartLeft's REST API. For that, in the first place we need to set up the server with the command: startleft server If you want to run the server in a specific port, you can do: startleft server -p 8080 Then, execute the following command to retrieve the OTM file with your EC2 component: curl --location --request POST localhost:5000/api/v1/startleft/iac \\ --header \"Content-Type: multipart/form-data\" \\ --header \"Accept: application/json\" \\ --form iac_type = \"CLOUDFORMATION\" \\ --form iac_file = @ \"./ec2-cft.json\" \\ --form mapping_file = @ \"./ec2-mapping.yaml\" \\ --form id = \"my-ec2-project\" \\ --form name = \"My EC2 project\"","title":"cURL"},{"location":"startleft-processors/iac/cft/CloudFormation-Quickstart/#more-examples","text":"The infrastructure built with CloudFormation Templates may be as complex as you want. This is the reason because StartLeft, through the mapping files, is intended to be configurable, so you can extend or modify its behavior and/or create your own mappings on demand. To help you to walk through more complex situations with larger CFT and mapping files, we have created a page with explained CFT examples which may be useful for you as a base for building your own mapping files.","title":"More examples"},{"location":"startleft-processors/iac/tf/Terraform-Examples/","text":"Terraform examples Sources You can find some sample source files inside the examples directory: examples/terraform contains Terraform example files to convert into OTM format. examples/terraform/split contains a complete Terraform example file split into two different files. To process this examples, it is mandatory to use the mapping files according to the file data type. You can find some sample mapping files inside the examples/terraform directory. Examples StartLeft supports parsing Terraform source files. Some examples are provided in the examples/terraform and examples/terraform/split directories. startleft parse \\ --iac-type TERRAFORM \\ --mapping-file iriusrisk-tf-aws-mapping \\ --output-file elb.otm \\ --project-name \"Terraform ELB\" \\ --project-id \"terraform-elb\" \\ elb.tf","title":"Terraform Examples"},{"location":"startleft-processors/iac/tf/Terraform-Examples/#terraform-examples","text":"","title":"Terraform examples"},{"location":"startleft-processors/iac/tf/Terraform-Examples/#sources","text":"You can find some sample source files inside the examples directory: examples/terraform contains Terraform example files to convert into OTM format. examples/terraform/split contains a complete Terraform example file split into two different files. To process this examples, it is mandatory to use the mapping files according to the file data type. You can find some sample mapping files inside the examples/terraform directory.","title":"Sources"},{"location":"startleft-processors/iac/tf/Terraform-Examples/#examples","text":"StartLeft supports parsing Terraform source files. Some examples are provided in the examples/terraform and examples/terraform/split directories. startleft parse \\ --iac-type TERRAFORM \\ --mapping-file iriusrisk-tf-aws-mapping \\ --output-file elb.otm \\ --project-name \"Terraform ELB\" \\ --project-id \"terraform-elb\" \\ elb.tf","title":"Examples"},{"location":"startleft-processors/iac/tf/Terraform-Quickstart/","text":"Terraform Quickstart What is Terraform? From the official Terraform page : Terraform is an open-source infrastructure as code software tool that enables you to safely and predictably create, change, and improve infrastructure. From the StartLeft's perspective, a Terraform (TF) defines a format to write files that define sets of components with relationships among them which can be interpreted to create a threat model. The slp_tf module The slp_tf module is the StartLeft Processor responsible for converting TF files into OTM. Its operation is based on a mapping file that enables the users to define the translations between the source TF types and the expected output in the OTM file. Once you got familiarized with the basics explained in this page, you will need to know more about how to use and customize the behavior of the processor in order to configure your own conversions. For that, you should take a look to the Terraform mapping page , where you will find all the information you need, from basic to advanced, to build your own CFT mapping files. Apart from this, you may also find interesting the generic usage manuals for the CLI and REST API . A basic example Let's suppose you have a TF file with a single EC2 instance like this: data \"aws_ami\" \"ubuntu\" { most_recent = true filter { name = \"name\" values = [ \"ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*\" ] } filter { name = \"virtualization-type\" values = [ \"hvm\" ] } owners = [ \"099720109477\" ] # Canonical } resource \"aws_instance\" \"web\" { ami = data.aws_ami.ubuntu.id instance_type = \"t3.micro\" tags = { Name = \"HelloWorld\" } } And you want to translate it to OTM in order to import it into IriusRisk , whose equivalent type for an EC2 instance is an ec2 component and the expected resultant project should be like this: In that case, you will need a mapping file that contains, at least, a TrustZone and the mapping for the EC2 component. Notice that the standard requires that all the components must have a parent, in this case, the Public Cloud TrustZone is mapped as the default component's TrustZone. This mapping file could be as simple as this: trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : ec2 $source : { $type : \"aws_instance\" } dataflows : [] The combination of this TF and mapping file will result in the OTM file below, that contains the mapped TrustZone and component along with all the necessary metadata defined by the standard and that is ready to be imported in a threat modeling tool like IriusRisk. { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"My EC2 project\" , \"id\" : \"my-ec2-project\" }, \"representations\" : [ { \"name\" : \"Terraform\" , \"id\" : \"Terraform\" , \"type\" : \"code\" } ], \"trustZones\" : [ { \"id\" : \"public-cloud-01\" , \"name\" : \"Public Cloud\" , \"type\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"risk\" : { \"trustRating\" : 10 } } ], \"components\" : [ { \"id\" : \"public-cloud-01.aws_instance-web\" , \"name\" : \"web\" , \"type\" : \"ec2\" , \"parent\" : { \"trustZone\" : \"public-cloud-01\" }, \"tags\" : [ \"aws_instance\" ] } ], \"dataflows\" : [] } CLI Note : Before continue, make sure you have StartLeft properly installed in your machine. Save the files above in your file system with these names: ec2-tf.json for the Terraform file. ec2-mapping.yaml for the mapping file. Now we are going to execute StartLeft for these files so that an ec2.otm file will be generated in our working directory with identical contents to the one above. startleft parse \\ --iac-type TERRAFORM \\ --mapping-file ec2-mapping.yaml \\ --output-file ec2.otm \\ --project-id \"my-ec2-project\" \\ --project-name \"My EC2 project\" \\ ec2-tf.json cURL You can get the same result if through the StartLeft's REST API. For that, in first place we need to set up the server with the command: startleft server Then, execute the following command to retrieve the OTM file with your EC2 component: curl --location --request POST localhost:5000/api/v1/startleft/iac \\ --header \"Content-Type: multipart/form-data\" \\ --header \"Accept: application/json\" \\ --form iac_type = \"TERRAFORM\" \\ --form iac_file = @ \"./ec2-tf.json\" \\ --form mapping_file = @ \"./ec2-mapping.yaml\" \\ --form id = \"my-ec2-project\" \\ --form name = \"My EC2 project\" More examples The infrastructure built with Terraform may be as complex as you want. This is the reason because StartLeft, through the mapping files, is intended to be configurable, so you can extend or modify its behavior and/or create your own mappings on demand. To help you to walk through more complex situations with larger Terraform and mapping files, we have created a page with explained TF examples which may be useful for you as a base for build your own mapping files.","title":"Terraform Quickstart"},{"location":"startleft-processors/iac/tf/Terraform-Quickstart/#terraform-quickstart","text":"","title":"Terraform Quickstart"},{"location":"startleft-processors/iac/tf/Terraform-Quickstart/#what-is-terraform","text":"From the official Terraform page : Terraform is an open-source infrastructure as code software tool that enables you to safely and predictably create, change, and improve infrastructure. From the StartLeft's perspective, a Terraform (TF) defines a format to write files that define sets of components with relationships among them which can be interpreted to create a threat model.","title":"What is Terraform?"},{"location":"startleft-processors/iac/tf/Terraform-Quickstart/#the-slp_tf-module","text":"The slp_tf module is the StartLeft Processor responsible for converting TF files into OTM. Its operation is based on a mapping file that enables the users to define the translations between the source TF types and the expected output in the OTM file. Once you got familiarized with the basics explained in this page, you will need to know more about how to use and customize the behavior of the processor in order to configure your own conversions. For that, you should take a look to the Terraform mapping page , where you will find all the information you need, from basic to advanced, to build your own CFT mapping files. Apart from this, you may also find interesting the generic usage manuals for the CLI and REST API .","title":"The slp_tf module"},{"location":"startleft-processors/iac/tf/Terraform-Quickstart/#a-basic-example","text":"Let's suppose you have a TF file with a single EC2 instance like this: data \"aws_ami\" \"ubuntu\" { most_recent = true filter { name = \"name\" values = [ \"ubuntu/images/hvm-ssd/ubuntu-focal-20.04-amd64-server-*\" ] } filter { name = \"virtualization-type\" values = [ \"hvm\" ] } owners = [ \"099720109477\" ] # Canonical } resource \"aws_instance\" \"web\" { ami = data.aws_ami.ubuntu.id instance_type = \"t3.micro\" tags = { Name = \"HelloWorld\" } } And you want to translate it to OTM in order to import it into IriusRisk , whose equivalent type for an EC2 instance is an ec2 component and the expected resultant project should be like this: In that case, you will need a mapping file that contains, at least, a TrustZone and the mapping for the EC2 component. Notice that the standard requires that all the components must have a parent, in this case, the Public Cloud TrustZone is mapped as the default component's TrustZone. This mapping file could be as simple as this: trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : ec2 $source : { $type : \"aws_instance\" } dataflows : [] The combination of this TF and mapping file will result in the OTM file below, that contains the mapped TrustZone and component along with all the necessary metadata defined by the standard and that is ready to be imported in a threat modeling tool like IriusRisk. { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"My EC2 project\" , \"id\" : \"my-ec2-project\" }, \"representations\" : [ { \"name\" : \"Terraform\" , \"id\" : \"Terraform\" , \"type\" : \"code\" } ], \"trustZones\" : [ { \"id\" : \"public-cloud-01\" , \"name\" : \"Public Cloud\" , \"type\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"risk\" : { \"trustRating\" : 10 } } ], \"components\" : [ { \"id\" : \"public-cloud-01.aws_instance-web\" , \"name\" : \"web\" , \"type\" : \"ec2\" , \"parent\" : { \"trustZone\" : \"public-cloud-01\" }, \"tags\" : [ \"aws_instance\" ] } ], \"dataflows\" : [] }","title":"A basic example"},{"location":"startleft-processors/iac/tf/Terraform-Quickstart/#cli","text":"Note : Before continue, make sure you have StartLeft properly installed in your machine. Save the files above in your file system with these names: ec2-tf.json for the Terraform file. ec2-mapping.yaml for the mapping file. Now we are going to execute StartLeft for these files so that an ec2.otm file will be generated in our working directory with identical contents to the one above. startleft parse \\ --iac-type TERRAFORM \\ --mapping-file ec2-mapping.yaml \\ --output-file ec2.otm \\ --project-id \"my-ec2-project\" \\ --project-name \"My EC2 project\" \\ ec2-tf.json","title":"CLI"},{"location":"startleft-processors/iac/tf/Terraform-Quickstart/#curl","text":"You can get the same result if through the StartLeft's REST API. For that, in first place we need to set up the server with the command: startleft server Then, execute the following command to retrieve the OTM file with your EC2 component: curl --location --request POST localhost:5000/api/v1/startleft/iac \\ --header \"Content-Type: multipart/form-data\" \\ --header \"Accept: application/json\" \\ --form iac_type = \"TERRAFORM\" \\ --form iac_file = @ \"./ec2-tf.json\" \\ --form mapping_file = @ \"./ec2-mapping.yaml\" \\ --form id = \"my-ec2-project\" \\ --form name = \"My EC2 project\"","title":"cURL"},{"location":"startleft-processors/iac/tf/Terraform-Quickstart/#more-examples","text":"The infrastructure built with Terraform may be as complex as you want. This is the reason because StartLeft, through the mapping files, is intended to be configurable, so you can extend or modify its behavior and/or create your own mappings on demand. To help you to walk through more complex situations with larger Terraform and mapping files, we have created a page with explained TF examples which may be useful for you as a base for build your own mapping files.","title":"More examples"},{"location":"startleft-processors/iac/tf/Terraform-additional-jmespath-functions/","text":"Parsing of IaC files may be sometimes complex, so that the built-in JMESPath functions are not enough. For that cases, a set of custom functions has been created to simplify and make more powerful the creation of mapping files. JMESPath functions re_sub The re_sub function replaces the occurrences of pattern with replace in the given string . def _func_re_sub ( self , pattern , replace , origin_string ) For example, we may want to replace colon characters with hyphens such as in re_sub('[:]', '-', 'stack:subnet') . squash_terraform The squash_terraform function takes a nested object of objects, and squashes them into a list of objects, injecting the parent \"key\" to the child object as \"_key\". def _func_squash_terraform ( self , obj ) These have a root Resources object whose top level keys are the resource names which have the resource objects as values. This structure is hard to iterate over without losing the important name key. So you can use squash it and refer to the name through the _key field. name : { $path : \"_key\" } $source : { $root : \"Resources|squash_terraform(@)[?Type=='aws_instance']\" } tail The tail function returns the characters of a given string from the count index onwards. It is equivalent to python's string[count:] . def _func_tail ( self , string , count ) get The get function takes a dictionary array of components whose root key is the type of the component. The other argument is a component type to filter the array. It returns a component dictionary whose root key is the name of the component that also includes a Type and a _key keys with the component type and the component name respectively. def _func_get ( self , obj_arr , component_type ) The get function is mainly used for Terraform mappings in order to retrieve components by their type. An example of its use is: resource|get(@, 'aws_subnet') . get_starts_with This function is equivalent to get , but instead of using the component_type argument to perform an exact filter, the target component type must starts with it. def _func_get_starts_with ( self , obj_arr , component_type ) split The split function is the equivalent to the python's one. It breaks a given string based on a given separator and returns the resulting array of strings. It is equivalent to python's split function. def _func_split ( self , string , separator ) For instance, this function is used in Terraform mappings to retrieve the name of a referenced component, whose naming structure is component-type.component-name.some-field . In this case, the name is retrieved as: split(component, '.')[1] . get_module_terraform The get_module_terraform function takes a dict array of Terraform modules (not resources) and a component type, which is the key to filter the array comparing against 'source' module property. Returns an OTM component dict whose root key is the name of the component that also includes a Type and a _key keys with the module type (AWS type) and the module name (custom name) respectively. def _func_get_module_terraform ( self , modules , module_type )","title":"Additional JMESPath functions"},{"location":"startleft-processors/iac/tf/Terraform-additional-jmespath-functions/#jmespath-functions","text":"","title":"JMESPath functions"},{"location":"startleft-processors/iac/tf/Terraform-additional-jmespath-functions/#re_sub","text":"The re_sub function replaces the occurrences of pattern with replace in the given string . def _func_re_sub ( self , pattern , replace , origin_string ) For example, we may want to replace colon characters with hyphens such as in re_sub('[:]', '-', 'stack:subnet') .","title":"re_sub"},{"location":"startleft-processors/iac/tf/Terraform-additional-jmespath-functions/#squash_terraform","text":"The squash_terraform function takes a nested object of objects, and squashes them into a list of objects, injecting the parent \"key\" to the child object as \"_key\". def _func_squash_terraform ( self , obj ) These have a root Resources object whose top level keys are the resource names which have the resource objects as values. This structure is hard to iterate over without losing the important name key. So you can use squash it and refer to the name through the _key field. name : { $path : \"_key\" } $source : { $root : \"Resources|squash_terraform(@)[?Type=='aws_instance']\" }","title":"squash_terraform"},{"location":"startleft-processors/iac/tf/Terraform-additional-jmespath-functions/#tail","text":"The tail function returns the characters of a given string from the count index onwards. It is equivalent to python's string[count:] . def _func_tail ( self , string , count )","title":"tail"},{"location":"startleft-processors/iac/tf/Terraform-additional-jmespath-functions/#get","text":"The get function takes a dictionary array of components whose root key is the type of the component. The other argument is a component type to filter the array. It returns a component dictionary whose root key is the name of the component that also includes a Type and a _key keys with the component type and the component name respectively. def _func_get ( self , obj_arr , component_type ) The get function is mainly used for Terraform mappings in order to retrieve components by their type. An example of its use is: resource|get(@, 'aws_subnet') .","title":"get"},{"location":"startleft-processors/iac/tf/Terraform-additional-jmespath-functions/#get_starts_with","text":"This function is equivalent to get , but instead of using the component_type argument to perform an exact filter, the target component type must starts with it. def _func_get_starts_with ( self , obj_arr , component_type )","title":"get_starts_with"},{"location":"startleft-processors/iac/tf/Terraform-additional-jmespath-functions/#split","text":"The split function is the equivalent to the python's one. It breaks a given string based on a given separator and returns the resulting array of strings. It is equivalent to python's split function. def _func_split ( self , string , separator ) For instance, this function is used in Terraform mappings to retrieve the name of a referenced component, whose naming structure is component-type.component-name.some-field . In this case, the name is retrieved as: split(component, '.')[1] .","title":"split"},{"location":"startleft-processors/iac/tf/Terraform-additional-jmespath-functions/#get_module_terraform","text":"The get_module_terraform function takes a dict array of Terraform modules (not resources) and a component type, which is the key to filter the array comparing against 'source' module property. Returns an OTM component dict whose root key is the name of the component that also includes a Type and a _key keys with the module type (AWS type) and the module name (custom name) respectively. def _func_get_module_terraform ( self , modules , module_type )","title":"get_module_terraform"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/","text":"There is an available Terraform Domain-Specific Language for easy mapping behavior configuration. This Terraform-DSL can be split into two sections: Special Mapping Fields and Mapping functions. SPECIAL MAPPING FIELDS These functions begin with a dollar sign ($) and do not directly contribute to the OTM output. Instead, they specify an action or behavior used to process the source files or generate the OTM output. $functions Description Applies to $ default Specifies the TrustZone as default TrustZones $ source Specifies the source of the object type Components, TrustZones & Dataflows $ altsource Specifies an alternative mapping when $source returns no object. Components $ children Specifies whose components are their children Components $ default This special mapping field default specifies a TrustZone as the default trustzone for the components in case those components don't define their parent. Applies to: TrustZones The components[].parent value is assigned by the attribute $default on the trustZones section. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : empty-component $source : { $type : \"aws_internet_gateway\" } dataflows : [] resource \"aws_internet_gateway\" \"InterneteGateway\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_internet_gateway-internetegateway name : InterneteGateway type : empty-component parent : trustZone : public-cloud-01 tags : - aws_internet_gateway dataflows : [] $ source This special mapping field source specifies the origin of the object type to be mapped. Its behavior is configured by the Terraform-DSL mapping functions to go through all the Terraform Resource files for returning the matching elements. Applies to: Components, TrustZones & Dataflows This mapping specifies the source for the empty-component with the resources of type aws_internet_gateway . Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : empty-component $source : { $type : \"aws_internet_gateway\" } dataflows : [] resource \"aws_internet_gateway\" \"InterneteGateway\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_internet_gateway-internetegateway name : InterneteGateway type : empty-component parent : trustZone : public-cloud-01 tags : - aws_internet_gateway dataflows : [] $ altsource This special mapping field altsource specifies an alternative mapping when $source returns nothing. Applies to: Components Reference to Mapping an AltSource for deeper explanation $ children This special mapping field children specifies whose components are their children on the OTM, it will set the parent attribute of those components on the OTM. Applies to: Components Reference to Mapping a Children for deeper explanation MAPPING FUNCTIONS These functions are used as parameters of the mapping attributes for configuring its behavior. $functions Type Description $ type filter Finds a resource by its type $ name filter Finds a resource by its name $ props filter Finds a resource by its properties $ regex filter Specifies a custom regex to be matched by the given argument $ root filter JMESPath search through the entire source file data structure $ path accessor JMESPath search through the object identified in the $source. A default value is optional by using the $searchParams structure $ findFirst selector JMESPath search through the list of objects identified in the $source and returns the first successful match. A default value is optional by using the $searchParams structure $ searchParams selector Specifies a default value for $path or $findFirst mapping functions $ singleton grouper Specific objects to be unified under a single component or TrustZone $ numberOfSources selector When using a $singleton , it allows you to set different values for output name or tags when the number of sources for the same mapping is single or multiple $ format formatter A named format string based on the output of other $special fields. $ module filter Search through the module section matching by source's attribute $ skip filter A sub-field of $source , specifying specific objects to skip if not explicitly defined $ catchall filter A sub-field of $source , including any matching resource unless it is already found (as a more specific one) or if it has been skipped $ lookup selector Allows you to look up the output of a $special field against a key-value lookup table $ hub connector Only for dataflow's \"source\" and \"destination\" fields. Specially created for building dataflows from Security Group structures without generating components from them. Allows defining abstract contact points for larger end-to-end final dataflows $ ip grouper When defining a component's \"name\" field as $ip , will generate a singleton component for representing an external IP but without limitations of singleton for this case, so the \"type\" for the defined mapping definition with $ip (i.e. generic-terminal) will not be catalogued as singleton $ type This mapping function type returns resources by their resource_type attribute on the Terraform Source Dictionary . This function can be used combined with $name and $props to create a more complete query. Type Consumes Produces Configuration params filter A list of resources A resources list filtered by type Can be configured with a string, a list of strings or using the $ regex mapping function This mapping specifies the component rds by the resources of type in ( aws_db_instance , aws_rds_cluster ) Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : rds $source : { $type : [ \"aws_db_instance\" , \"aws_rds_cluster\" ]} dataflows : [] resource \"aws_db_instance\" \"mysql\" {} resource \"aws_rds_cluster\" \"aurora-cluster-demo\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_db_instance-mysql name : mysql type : rds parent : trustZone : public-cloud-01 tags : - aws_db_instance - id : public-cloud-01.aws_rds_cluster-aurora_cluster_demo name : aurora-cluster-demo type : rds parent : trustZone : public-cloud-01 tags : - aws_rds_cluster dataflows : [] $ name This mapping function name returns resources by their resource_name attribute on the Terraform Source Dictionary . This function can be used combined with $type and $props to create a more complete query. Type Consumes Produces Configuration params filter A list of resources A resources list filtered by name Can be configured with a string, a list of strings or using the $ regex mapping function This mapping specifies the component rds by the resources with name mysql Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : rds $source : { $name : \"mysql\" } dataflows : [] resource \"aws_db_instance\" \"mysql\" {} resource \"aws_rds_cluster\" \"aurora-cluster-demo\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_db_instance-mysql name : mysql type : rds parent : trustZone : public-cloud-01 tags : - aws_db_instance dataflows : [] $ props This mapping function props returns resources by their resource_properties attribute on the Terraform Source Dictionary . This function can be used combined with $type and $name to create a more complete query. Type Consumes Produces Configuration params filter A list of resources A resources list filtered by its properties Can be configured with a string, a list of strings or using the $ regex mapping function This mapping specifies the component generic-client by the resources with type aws_security_group having the property egress[0].cidr_blocks present in their resource_properties Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : generic-client $source : { $type : \"aws_security_group\" , $props : \"egress[0].cidr_blocks\" } dataflows : [] resource \"aws_security_group\" \"webserver\" { egress { cidr_blocks = [ \"0.0.0.0/0\" ] } } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_security_group-webserver name : webserver type : generic-client parent : trustZone : public-cloud-01 tags : - aws_security_group dataflows : [] $ regex This mapping function regex allows configuring a custom regex to be matched against the resource attribute. This function can be used as a parameter for $type , $name and $props . Type Consumes Produces Configuration params filter A list of resources A resources list which attribute matches the regex A valid regex This mapping specifies the component api-gateway by the resources with type matching the regex ^aws_api_gateway_\\w*$ Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : api-gateway $source : { $type : { $regex : ^aws_api_gateway_\\w*$ }} dataflows : [] resource \"aws_api_gateway_rest_api\" \"rest_api\" {} resource \"aws_api_gateway_authorizer\" \"api_authorizer\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_api_gateway_rest_api-rest_api name : rest_api type : api-gateway parent : trustZone : public-cloud-01 tags : - aws_api_gateway_rest_api - id : public-cloud-01.aws_api_gateway_authorizer-api_authorizer name : api_authorizer type : api-gateway parent : trustZone : public-cloud-01 tags : - aws_api_gateway_authorizer dataflows : [] $ root This mapping function root allows to search through the entire source file data structure by using JMESPath . Type Consumes Produces Configuration params filter The entire source file A resources list filtered by the JMESpath query A JMESpath query When using $root , it may be useful to use Additional JMESPath functions . This map specifies the component vpc by using the get JMESPath functions Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : vpc $source : { $root : \"resource|get(@, 'aws_vpc')\" } dataflows : [] resource \"aws_vpc\" \"CustomVPC\" { cidr_block = var.vpcCidrblock } --- otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_vpc-customvpc name : CustomVPC type : vpc parent : trustZone : public-cloud-01 tags : - aws_vpc dataflows : [] $ path This mapping function path allows getting the values from the object identified in the $source by using JMESPath . A default value is optional by using the $searchParams structure. Type Consumes Produces Configuration params accessor The $source object An attribute list filtered by the query A JMESpath query or $searchParams structure This mapping specifies the component empty-component which name is retrieved by the $source attribute resouce_properties.cidr_block Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : empty-component name : { $path : \"resource_properties.cidr_block\" } $source : { $type : \"aws_subnet\" } dataflows : [] resource \"aws_subnet\" \"PrivateSubnet1\" { vpc_id = aws_vpc.CustomVPC.id cidr_block = \"10.0.2.0/24\" } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_subnet-privatesubnet1 name : 10.0.2.0/24 type : empty-component parent : trustZone : public-cloud-01 tags : - aws_subnet dataflows : [] $ findFirst This mapping function findFirst searchs through the list of objects identified in the $source and returns the first successful match. A default value is optional by using the $searchParams structure. Type Consumes Produces Configuration params filter The $source object A string attribute A list of objects identified in the $source or $searchParams structure This mapping specifies a component rds whose name is configured by a list of attributes Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : empty-component name : { $findFirst : [ \"resource_properties.cidr_block\" , \"resource_name\" ]} $source : { $type : \"aws_subnet\" } dataflows : [] resource \"aws_subnet\" \"PrivateSubnet1\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_subnet-privatesubnet1 name : PrivateSubnet1 type : empty-component parent : trustZone : public-cloud-01 tags : - aws_subnet dataflows : [] $ searchParams This mapping function searchParams specifies a default value for $path or $findFirst mapping functions. Type Consumes Produces Configuration params selector The $path or $findFirst functions A string attribute A searchPath and/or a defaultValue This mapping specifies a component rds whose tag is retrieved from resource_properties. engine with rds as default value. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : rds $source : { $type : [ \"aws_db_instance\" , \"aws_rds_cluster\" ]} tags : - { $path : { $searchParams : { searchPath : \"resource_properties.engine\" , defaultValue : \"rds\" }}} dataflows : [] resource \"aws_db_instance\" \"mysql\" { engine = \"mysql\" } resource \"aws_rds_cluster\" \"aurora-cluster-demo\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_db_instance-mysql name : mysql type : rds parent : trustZone : public-cloud-01 tags : - mysql - id : public-cloud-01.aws_rds_cluster-aurora_cluster_demo name : aurora-cluster-demo type : rds parent : trustZone : public-cloud-01 tags : - rds dataflows : [] $ singleton This mapping function singleton unifies TF resources under a single component or TrustZone. This function is frequently combined with $numberOfSources for generating text fields like the name or the tags. So is done, for example, in the default configuration described in the Component Template Pattern . Type Consumes Produces Configuration params group A list of resources A list of resources grouped by the given params Mapping Function configuration This mapping specifies a unique component CD-SYSTEMS-MANAGER for any number of resources whose name starts with aws_ssm_ . Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : CD-SYSTEMS-MANAGER $source : { $singleton : { $type : { $regex : ^aws_ssm_\\w*$ }}} dataflows : [] resource \"aws_ssm_parameter\" \"ssm_parameter\" {} resource \"aws_ssm_document\" \"ssm_document\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_ssm_parameter-ssm_parameter name : CD-SYSTEMS-MANAGER (grouped) type : CD-SYSTEMS-MANAGER parent : trustZone : public-cloud-01 tags : - ssm_parameter (aws_ssm_parameter) - ssm_document (aws_ssm_document) dataflows : [] $ numberOfSources This mapping function numberOfSources allows you to set different values for output name or tags when the number of sources for the same mapping is single or multiple. Type Consumes Produces Configuration params group The $source object A string attribute oneSource and multipleSource configuration attributes The result of this function may be expressed as: multipleSource if $ singleton && ( numberOfSources > 1 ) else oneSource This mapping specifies a unique component CD-SYSTEMS-MANAGER and set its name by CD-SYSTEMS-MANAGER (grouped) when found more than one resource. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : CD-SYSTEMS-MANAGER name : { $numberOfSources : { oneSource : { $path : \"resource_name\" }, multipleSource : { $format : \"{type} (grouped)\" }}} $source : { $singleton : { $type : { $regex : ^aws_ssm_\\w*$ }}} dataflows : [] resource \"aws_ssm_parameter\" \"ssm_parameter\" {} resource \"aws_ssm_document\" \"ssm_document\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_ssm_parameter-ssm_parameter name : CD-SYSTEMS-MANAGER (grouped) type : CD-SYSTEMS-MANAGER parent : trustZone : public-cloud-01 tags : - ssm_parameter (aws_ssm_parameter) - ssm_document (aws_ssm_document) dataflows : [] $ format This mapping function format returns a formatted version of the string, using values from $source and the name or type mapper attributes. These substitutions are identified by braces ('{' and '}') Type Consumes Produces Configuration params formatter The $source object and name and type mapper attributes A string attribute The string formatter configuration This mapping specifies a component rds whose name is configured by a complex string Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : rds name : { $format : \"{type} created by resource {resource_name} of type {resource_type}\" } $source : { $type : \"aws_db_instance\" } dataflows : [] resource \"aws_db_instance\" \"mysql\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_db_instance-mysql name : rds created by resource mysql of type aws_db_instance type : rds parent : trustZone : public-cloud-01 tags : - aws_db_instance dataflows : [] $ module This mapping function module searches for modules in the TF configuration matching by the source 's attribute. Type Consumes Produces Configuration params filter A list of resources A modules list filtered by source's attribute The source's attribute value This mapping specifies a component rds for the module terraform-aws-modules/rds/aws Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : rds $source : { $module : \"terraform-aws-modules/rds/aws\" } dataflows : [] module \"db\" { source = \"terraform-aws-modules/rds/aws\" } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.db name : db type : rds parent : trustZone : public-cloud-01 tags : - terraform-aws-modules/rds/aws dataflows : [] $ skip This mapping function skip specifying specific objects to skip if not explicitly defined. Type Consumes Produces Configuration params filter A list of resources A resources list of resources to skip Mapping Function configuration This mapping specifies the component rds for the resources of type in ( aws_db_instance , aws_rds_cluster ) but skipping the resource with name mysql-secret Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : rds $source : { $type : [ \"aws_db_instance\" , \"aws_rds_cluster\" ]} - type : skip_mysql-secret $source : { $skip : { $name : \"mysql-secret\" }} dataflows : [] resource \"aws_db_instance\" \"mysql\" {} resource \"aws_db_instance\" \"mysql-secret\" {} resource \"aws_rds_cluster\" \"aurora-cluster-demo\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_db_instance-mysql name : mysql type : rds parent : trustZone : public-cloud-01 tags : - aws_db_instance - id : public-cloud-01.aws_rds_cluster-aurora_cluster_demo name : aurora-cluster-demo type : rds parent : trustZone : public-cloud-01 tags : - aws_rds_cluster dataflows : [] $ catchall This mapping function catchall is used to create a component for each resource that matches a certain query. It will include any matching resource unless it is already found as a more specific resource or if it has been skipped. Type Consumes Produces Configuration params filter A list of resources A list of resources matching the provided query Mapping Function configuration Example #1: only catchall This mapping matches all previously not matched components, regardless theirs specific types or names. It is used along with $root mapping function seen before, and with $squash_terraform explained in the next section Mapping file Resource File OTM trustzones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud $default : true components : - type : empty-component $source : { $catchall : { $root : \"resource|squash_terraform(@)\" }} dataflows : [] resource \"aws_db_instance\" \"mysql\" {} resource \"aws_db_instance\" \"mysql-secret\" {} resource \"aws_rds_cluster\" \"aurora-cluster-demo\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud risk : trustRating : 10 components : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_db_instance-mysql name : mysql type : empty-component parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_db_instance - id : b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_db_instance-mysql_secret name : mysql-secret type : empty-component parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_db_instance - id : b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_db_instance-aurora_cluster_demo name : aurora-cluster-demo type : empty-component parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_rds_cluster dataflows : [] Example #2: explicit mapping and catchall This mapping matches all resources, except for those ones already mapped by a more specific case Mapping file Resource File OTM trustzones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud $default : true components : - type : rds $source : { $type : [ \"aws_db_instance\" , \"aws_rds_cluster\" ]} - type : empty-component $source : { $catchall : { $root : \"resource|squash_terraform(@)\" }} dataflows : [] resource \"aws_db_instance\" \"mysql\" {} resource \"aws_db_instance\" \"mysql-secret\" {} resource \"aws_rds_cluster\" \"aurora-cluster-demo\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud risk : trustRating : 10 components : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_db_instance-mysql name : mysql type : rds parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_db_instance - id : b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_db_instance-mysql_secret name : mysql-secret type : rds parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_db_instance - id : b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_db_instance-aurora_cluster_demo name : aurora-cluster-demo type : empty-component parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_rds_cluster dataflows : [] Example #3: skip and catchall This mapping matches all resources, except for those explicitly skipped Mapping file Resource File OTM trustzones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud $default : true components : - type : skip_mysql-secret $source : { $skip : { $name : \"mysql-secret\" }} - type : empty-component $source : { $catchall : { $root : \"resource|squash_terraform(@)\" }} dataflows : [] resource \"aws_db_instance\" \"mysql\" {} resource \"aws_db_instance\" \"mysql-secret\" {} resource \"aws_rds_cluster\" \"aurora-cluster-demo\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud risk : trustRating : 10 components : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_db_instance-mysql name : mysql type : empty-component parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_db_instance - id : b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_db_instance-aurora_cluster_demo name : aurora-cluster-demo type : empty-component parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_rds_cluster dataflows : [] $ lookup This mapping function lookup allows you to look up the output of a special field against a key-value lookup table. Example for lookup Just in case there are some inconsistencies in naming conventions used, and you need to be able to translate one name into another, a simple lookup key-value table section can be added to the mapping file. For example, if we have a situation where a subnet name is written using a short naming convention, but is actually referred to via a longer name elsewhere, we can use the $lookup action. parent : $lookup : { $path : \"Properties.Subnets[]|map(&values(@), @)[]|map(&re_sub('[:]', '-', @), @)\" } If the above query returns a subnet called shortnameA , then it will be looked up in the below table: lookup : shortnameA : amuchlongernameA shortnameB : amuchlongernameB To give a final value of amuchlongernameA . $ hub This special mapping field hub allows defining abstract contact points for larger end-to-end final dataflows. Only for dataflow's \"source\" and \"destination\" fields. Specially created for building dataflows from Security Group structures without generating components from them. Reference to Security Groups as dataflows for usage examples. $ ip When defining a component's \"name\" field as $ip , will generate a singleton component for representing an external IP but without limitations of singleton for this case, so the \"type\" for the defined mapping definition with $ip (i.e. generic-terminal ) will not be catalogued as singleton. Reference to Security Groups as dataflows for usage examples.","title":"Domain-Specific Language"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#special-mapping-fields","text":"These functions begin with a dollar sign ($) and do not directly contribute to the OTM output. Instead, they specify an action or behavior used to process the source files or generate the OTM output. $functions Description Applies to $ default Specifies the TrustZone as default TrustZones $ source Specifies the source of the object type Components, TrustZones & Dataflows $ altsource Specifies an alternative mapping when $source returns no object. Components $ children Specifies whose components are their children Components","title":"SPECIAL MAPPING FIELDS"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#default","text":"This special mapping field default specifies a TrustZone as the default trustzone for the components in case those components don't define their parent. Applies to: TrustZones The components[].parent value is assigned by the attribute $default on the trustZones section. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : empty-component $source : { $type : \"aws_internet_gateway\" } dataflows : [] resource \"aws_internet_gateway\" \"InterneteGateway\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_internet_gateway-internetegateway name : InterneteGateway type : empty-component parent : trustZone : public-cloud-01 tags : - aws_internet_gateway dataflows : []","title":"$default"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#source","text":"This special mapping field source specifies the origin of the object type to be mapped. Its behavior is configured by the Terraform-DSL mapping functions to go through all the Terraform Resource files for returning the matching elements. Applies to: Components, TrustZones & Dataflows This mapping specifies the source for the empty-component with the resources of type aws_internet_gateway . Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : empty-component $source : { $type : \"aws_internet_gateway\" } dataflows : [] resource \"aws_internet_gateway\" \"InterneteGateway\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_internet_gateway-internetegateway name : InterneteGateway type : empty-component parent : trustZone : public-cloud-01 tags : - aws_internet_gateway dataflows : []","title":"$source"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#altsource","text":"This special mapping field altsource specifies an alternative mapping when $source returns nothing. Applies to: Components Reference to Mapping an AltSource for deeper explanation","title":"$altsource"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#children","text":"This special mapping field children specifies whose components are their children on the OTM, it will set the parent attribute of those components on the OTM. Applies to: Components Reference to Mapping a Children for deeper explanation","title":"$children"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#mapping-functions","text":"These functions are used as parameters of the mapping attributes for configuring its behavior. $functions Type Description $ type filter Finds a resource by its type $ name filter Finds a resource by its name $ props filter Finds a resource by its properties $ regex filter Specifies a custom regex to be matched by the given argument $ root filter JMESPath search through the entire source file data structure $ path accessor JMESPath search through the object identified in the $source. A default value is optional by using the $searchParams structure $ findFirst selector JMESPath search through the list of objects identified in the $source and returns the first successful match. A default value is optional by using the $searchParams structure $ searchParams selector Specifies a default value for $path or $findFirst mapping functions $ singleton grouper Specific objects to be unified under a single component or TrustZone $ numberOfSources selector When using a $singleton , it allows you to set different values for output name or tags when the number of sources for the same mapping is single or multiple $ format formatter A named format string based on the output of other $special fields. $ module filter Search through the module section matching by source's attribute $ skip filter A sub-field of $source , specifying specific objects to skip if not explicitly defined $ catchall filter A sub-field of $source , including any matching resource unless it is already found (as a more specific one) or if it has been skipped $ lookup selector Allows you to look up the output of a $special field against a key-value lookup table $ hub connector Only for dataflow's \"source\" and \"destination\" fields. Specially created for building dataflows from Security Group structures without generating components from them. Allows defining abstract contact points for larger end-to-end final dataflows $ ip grouper When defining a component's \"name\" field as $ip , will generate a singleton component for representing an external IP but without limitations of singleton for this case, so the \"type\" for the defined mapping definition with $ip (i.e. generic-terminal) will not be catalogued as singleton","title":"MAPPING FUNCTIONS"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#type","text":"This mapping function type returns resources by their resource_type attribute on the Terraform Source Dictionary . This function can be used combined with $name and $props to create a more complete query. Type Consumes Produces Configuration params filter A list of resources A resources list filtered by type Can be configured with a string, a list of strings or using the $ regex mapping function This mapping specifies the component rds by the resources of type in ( aws_db_instance , aws_rds_cluster ) Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : rds $source : { $type : [ \"aws_db_instance\" , \"aws_rds_cluster\" ]} dataflows : [] resource \"aws_db_instance\" \"mysql\" {} resource \"aws_rds_cluster\" \"aurora-cluster-demo\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_db_instance-mysql name : mysql type : rds parent : trustZone : public-cloud-01 tags : - aws_db_instance - id : public-cloud-01.aws_rds_cluster-aurora_cluster_demo name : aurora-cluster-demo type : rds parent : trustZone : public-cloud-01 tags : - aws_rds_cluster dataflows : []","title":"$type"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#name","text":"This mapping function name returns resources by their resource_name attribute on the Terraform Source Dictionary . This function can be used combined with $type and $props to create a more complete query. Type Consumes Produces Configuration params filter A list of resources A resources list filtered by name Can be configured with a string, a list of strings or using the $ regex mapping function This mapping specifies the component rds by the resources with name mysql Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : rds $source : { $name : \"mysql\" } dataflows : [] resource \"aws_db_instance\" \"mysql\" {} resource \"aws_rds_cluster\" \"aurora-cluster-demo\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_db_instance-mysql name : mysql type : rds parent : trustZone : public-cloud-01 tags : - aws_db_instance dataflows : []","title":"$name"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#props","text":"This mapping function props returns resources by their resource_properties attribute on the Terraform Source Dictionary . This function can be used combined with $type and $name to create a more complete query. Type Consumes Produces Configuration params filter A list of resources A resources list filtered by its properties Can be configured with a string, a list of strings or using the $ regex mapping function This mapping specifies the component generic-client by the resources with type aws_security_group having the property egress[0].cidr_blocks present in their resource_properties Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : generic-client $source : { $type : \"aws_security_group\" , $props : \"egress[0].cidr_blocks\" } dataflows : [] resource \"aws_security_group\" \"webserver\" { egress { cidr_blocks = [ \"0.0.0.0/0\" ] } } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_security_group-webserver name : webserver type : generic-client parent : trustZone : public-cloud-01 tags : - aws_security_group dataflows : []","title":"$props"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#regex","text":"This mapping function regex allows configuring a custom regex to be matched against the resource attribute. This function can be used as a parameter for $type , $name and $props . Type Consumes Produces Configuration params filter A list of resources A resources list which attribute matches the regex A valid regex This mapping specifies the component api-gateway by the resources with type matching the regex ^aws_api_gateway_\\w*$ Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : api-gateway $source : { $type : { $regex : ^aws_api_gateway_\\w*$ }} dataflows : [] resource \"aws_api_gateway_rest_api\" \"rest_api\" {} resource \"aws_api_gateway_authorizer\" \"api_authorizer\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_api_gateway_rest_api-rest_api name : rest_api type : api-gateway parent : trustZone : public-cloud-01 tags : - aws_api_gateway_rest_api - id : public-cloud-01.aws_api_gateway_authorizer-api_authorizer name : api_authorizer type : api-gateway parent : trustZone : public-cloud-01 tags : - aws_api_gateway_authorizer dataflows : []","title":"$regex"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#root","text":"This mapping function root allows to search through the entire source file data structure by using JMESPath . Type Consumes Produces Configuration params filter The entire source file A resources list filtered by the JMESpath query A JMESpath query When using $root , it may be useful to use Additional JMESPath functions . This map specifies the component vpc by using the get JMESPath functions Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : vpc $source : { $root : \"resource|get(@, 'aws_vpc')\" } dataflows : [] resource \"aws_vpc\" \"CustomVPC\" { cidr_block = var.vpcCidrblock } --- otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_vpc-customvpc name : CustomVPC type : vpc parent : trustZone : public-cloud-01 tags : - aws_vpc dataflows : []","title":"$root"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#path","text":"This mapping function path allows getting the values from the object identified in the $source by using JMESPath . A default value is optional by using the $searchParams structure. Type Consumes Produces Configuration params accessor The $source object An attribute list filtered by the query A JMESpath query or $searchParams structure This mapping specifies the component empty-component which name is retrieved by the $source attribute resouce_properties.cidr_block Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : empty-component name : { $path : \"resource_properties.cidr_block\" } $source : { $type : \"aws_subnet\" } dataflows : [] resource \"aws_subnet\" \"PrivateSubnet1\" { vpc_id = aws_vpc.CustomVPC.id cidr_block = \"10.0.2.0/24\" } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_subnet-privatesubnet1 name : 10.0.2.0/24 type : empty-component parent : trustZone : public-cloud-01 tags : - aws_subnet dataflows : []","title":"$path"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#findfirst","text":"This mapping function findFirst searchs through the list of objects identified in the $source and returns the first successful match. A default value is optional by using the $searchParams structure. Type Consumes Produces Configuration params filter The $source object A string attribute A list of objects identified in the $source or $searchParams structure This mapping specifies a component rds whose name is configured by a list of attributes Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : empty-component name : { $findFirst : [ \"resource_properties.cidr_block\" , \"resource_name\" ]} $source : { $type : \"aws_subnet\" } dataflows : [] resource \"aws_subnet\" \"PrivateSubnet1\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_subnet-privatesubnet1 name : PrivateSubnet1 type : empty-component parent : trustZone : public-cloud-01 tags : - aws_subnet dataflows : []","title":"$findFirst"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#searchparams","text":"This mapping function searchParams specifies a default value for $path or $findFirst mapping functions. Type Consumes Produces Configuration params selector The $path or $findFirst functions A string attribute A searchPath and/or a defaultValue This mapping specifies a component rds whose tag is retrieved from resource_properties. engine with rds as default value. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : rds $source : { $type : [ \"aws_db_instance\" , \"aws_rds_cluster\" ]} tags : - { $path : { $searchParams : { searchPath : \"resource_properties.engine\" , defaultValue : \"rds\" }}} dataflows : [] resource \"aws_db_instance\" \"mysql\" { engine = \"mysql\" } resource \"aws_rds_cluster\" \"aurora-cluster-demo\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_db_instance-mysql name : mysql type : rds parent : trustZone : public-cloud-01 tags : - mysql - id : public-cloud-01.aws_rds_cluster-aurora_cluster_demo name : aurora-cluster-demo type : rds parent : trustZone : public-cloud-01 tags : - rds dataflows : []","title":"$searchParams"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#singleton","text":"This mapping function singleton unifies TF resources under a single component or TrustZone. This function is frequently combined with $numberOfSources for generating text fields like the name or the tags. So is done, for example, in the default configuration described in the Component Template Pattern . Type Consumes Produces Configuration params group A list of resources A list of resources grouped by the given params Mapping Function configuration This mapping specifies a unique component CD-SYSTEMS-MANAGER for any number of resources whose name starts with aws_ssm_ . Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : CD-SYSTEMS-MANAGER $source : { $singleton : { $type : { $regex : ^aws_ssm_\\w*$ }}} dataflows : [] resource \"aws_ssm_parameter\" \"ssm_parameter\" {} resource \"aws_ssm_document\" \"ssm_document\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_ssm_parameter-ssm_parameter name : CD-SYSTEMS-MANAGER (grouped) type : CD-SYSTEMS-MANAGER parent : trustZone : public-cloud-01 tags : - ssm_parameter (aws_ssm_parameter) - ssm_document (aws_ssm_document) dataflows : []","title":"$singleton"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#numberofsources","text":"This mapping function numberOfSources allows you to set different values for output name or tags when the number of sources for the same mapping is single or multiple. Type Consumes Produces Configuration params group The $source object A string attribute oneSource and multipleSource configuration attributes The result of this function may be expressed as: multipleSource if $ singleton && ( numberOfSources > 1 ) else oneSource This mapping specifies a unique component CD-SYSTEMS-MANAGER and set its name by CD-SYSTEMS-MANAGER (grouped) when found more than one resource. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : CD-SYSTEMS-MANAGER name : { $numberOfSources : { oneSource : { $path : \"resource_name\" }, multipleSource : { $format : \"{type} (grouped)\" }}} $source : { $singleton : { $type : { $regex : ^aws_ssm_\\w*$ }}} dataflows : [] resource \"aws_ssm_parameter\" \"ssm_parameter\" {} resource \"aws_ssm_document\" \"ssm_document\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_ssm_parameter-ssm_parameter name : CD-SYSTEMS-MANAGER (grouped) type : CD-SYSTEMS-MANAGER parent : trustZone : public-cloud-01 tags : - ssm_parameter (aws_ssm_parameter) - ssm_document (aws_ssm_document) dataflows : []","title":"$numberOfSources"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#format","text":"This mapping function format returns a formatted version of the string, using values from $source and the name or type mapper attributes. These substitutions are identified by braces ('{' and '}') Type Consumes Produces Configuration params formatter The $source object and name and type mapper attributes A string attribute The string formatter configuration This mapping specifies a component rds whose name is configured by a complex string Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : rds name : { $format : \"{type} created by resource {resource_name} of type {resource_type}\" } $source : { $type : \"aws_db_instance\" } dataflows : [] resource \"aws_db_instance\" \"mysql\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_db_instance-mysql name : rds created by resource mysql of type aws_db_instance type : rds parent : trustZone : public-cloud-01 tags : - aws_db_instance dataflows : []","title":"$format"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#module","text":"This mapping function module searches for modules in the TF configuration matching by the source 's attribute. Type Consumes Produces Configuration params filter A list of resources A modules list filtered by source's attribute The source's attribute value This mapping specifies a component rds for the module terraform-aws-modules/rds/aws Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : rds $source : { $module : \"terraform-aws-modules/rds/aws\" } dataflows : [] module \"db\" { source = \"terraform-aws-modules/rds/aws\" } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.db name : db type : rds parent : trustZone : public-cloud-01 tags : - terraform-aws-modules/rds/aws dataflows : []","title":"$module"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#skip","text":"This mapping function skip specifying specific objects to skip if not explicitly defined. Type Consumes Produces Configuration params filter A list of resources A resources list of resources to skip Mapping Function configuration This mapping specifies the component rds for the resources of type in ( aws_db_instance , aws_rds_cluster ) but skipping the resource with name mysql-secret Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : rds $source : { $type : [ \"aws_db_instance\" , \"aws_rds_cluster\" ]} - type : skip_mysql-secret $source : { $skip : { $name : \"mysql-secret\" }} dataflows : [] resource \"aws_db_instance\" \"mysql\" {} resource \"aws_db_instance\" \"mysql-secret\" {} resource \"aws_rds_cluster\" \"aurora-cluster-demo\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_db_instance-mysql name : mysql type : rds parent : trustZone : public-cloud-01 tags : - aws_db_instance - id : public-cloud-01.aws_rds_cluster-aurora_cluster_demo name : aurora-cluster-demo type : rds parent : trustZone : public-cloud-01 tags : - aws_rds_cluster dataflows : []","title":"$skip"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#catchall","text":"This mapping function catchall is used to create a component for each resource that matches a certain query. It will include any matching resource unless it is already found as a more specific resource or if it has been skipped. Type Consumes Produces Configuration params filter A list of resources A list of resources matching the provided query Mapping Function configuration Example #1: only catchall This mapping matches all previously not matched components, regardless theirs specific types or names. It is used along with $root mapping function seen before, and with $squash_terraform explained in the next section Mapping file Resource File OTM trustzones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud $default : true components : - type : empty-component $source : { $catchall : { $root : \"resource|squash_terraform(@)\" }} dataflows : [] resource \"aws_db_instance\" \"mysql\" {} resource \"aws_db_instance\" \"mysql-secret\" {} resource \"aws_rds_cluster\" \"aurora-cluster-demo\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud risk : trustRating : 10 components : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_db_instance-mysql name : mysql type : empty-component parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_db_instance - id : b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_db_instance-mysql_secret name : mysql-secret type : empty-component parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_db_instance - id : b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_db_instance-aurora_cluster_demo name : aurora-cluster-demo type : empty-component parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_rds_cluster dataflows : [] Example #2: explicit mapping and catchall This mapping matches all resources, except for those ones already mapped by a more specific case Mapping file Resource File OTM trustzones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud $default : true components : - type : rds $source : { $type : [ \"aws_db_instance\" , \"aws_rds_cluster\" ]} - type : empty-component $source : { $catchall : { $root : \"resource|squash_terraform(@)\" }} dataflows : [] resource \"aws_db_instance\" \"mysql\" {} resource \"aws_db_instance\" \"mysql-secret\" {} resource \"aws_rds_cluster\" \"aurora-cluster-demo\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud risk : trustRating : 10 components : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_db_instance-mysql name : mysql type : rds parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_db_instance - id : b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_db_instance-mysql_secret name : mysql-secret type : rds parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_db_instance - id : b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_db_instance-aurora_cluster_demo name : aurora-cluster-demo type : empty-component parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_rds_cluster dataflows : [] Example #3: skip and catchall This mapping matches all resources, except for those explicitly skipped Mapping file Resource File OTM trustzones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud $default : true components : - type : skip_mysql-secret $source : { $skip : { $name : \"mysql-secret\" }} - type : empty-component $source : { $catchall : { $root : \"resource|squash_terraform(@)\" }} dataflows : [] resource \"aws_db_instance\" \"mysql\" {} resource \"aws_db_instance\" \"mysql-secret\" {} resource \"aws_rds_cluster\" \"aurora-cluster-demo\" {} otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud risk : trustRating : 10 components : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_db_instance-mysql name : mysql type : empty-component parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_db_instance - id : b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_db_instance-aurora_cluster_demo name : aurora-cluster-demo type : empty-component parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_rds_cluster dataflows : []","title":"$catchall"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#lookup","text":"This mapping function lookup allows you to look up the output of a special field against a key-value lookup table. Example for lookup Just in case there are some inconsistencies in naming conventions used, and you need to be able to translate one name into another, a simple lookup key-value table section can be added to the mapping file. For example, if we have a situation where a subnet name is written using a short naming convention, but is actually referred to via a longer name elsewhere, we can use the $lookup action. parent : $lookup : { $path : \"Properties.Subnets[]|map(&values(@), @)[]|map(&re_sub('[:]', '-', @), @)\" } If the above query returns a subnet called shortnameA , then it will be looked up in the below table: lookup : shortnameA : amuchlongernameA shortnameB : amuchlongernameB To give a final value of amuchlongernameA .","title":"$lookup"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#hub","text":"This special mapping field hub allows defining abstract contact points for larger end-to-end final dataflows. Only for dataflow's \"source\" and \"destination\" fields. Specially created for building dataflows from Security Group structures without generating components from them. Reference to Security Groups as dataflows for usage examples.","title":"$hub"},{"boost":2,"location":"startleft-processors/iac/tf/Terraform-domain-specific-language/#ip","text":"When defining a component's \"name\" field as $ip , will generate a singleton component for representing an external IP but without limitations of singleton for this case, so the \"type\" for the defined mapping definition with $ip (i.e. generic-terminal ) will not be catalogued as singleton. Reference to Security Groups as dataflows for usage examples.","title":"$ip"},{"location":"startleft-processors/iac/tf/Terraform-how-dataflow-mapping-works/","text":"Refer to How To Map Dataflows section for a simpler introduction. Info In Terraform configuration files there not exist a direct relationship between resources and data flow. Mapping configuration is needed to be configured in the mapping file to represent its flows in the OTM. Types of dataflows in Terraform Simple dataflows When dataflows mapping attribute has enough information, they are mapped directly through the mapping file. It could be divided into three types: resource A, A \u2192 B The $source is the origin of the dataflow and has the information about the destination dataflow itself. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : api-gateway $source : { $type : \"aws_api_gateway_authorizer\" } - type : cognito $source : { $type : \"aws_cognito_user_pool\" } dataflows : - name : { $format : \"API gateway data flow from {resource_type}\" } $source : { $type : \"aws_api_gateway_authorizer\" } source : { $path : \"resource_id\" } destination : { $path : \"resource_properties.provider_arns[0]\" } tags : - API gateway dataflow resource \"aws_cognito_user_pool\" \"user_pool\" { } resource \"aws_api_gateway_authorizer\" \"api_authorizer\" { provider_arns = [ aws_cognito_user_pool.user_pool.arn ] } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud risk : trustRating : 10 components : - id : public-cloud-01.aws_api_gateway_authorizer-api_authorizer name : api_authorizer type : api-gateway parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_api_gateway_authorizer - id : public-cloud-01.aws_cognito_user_pool-user_pool name : user_pool type : cognito parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_cognito_user_pool dataflows : - id : 2ced6f2f-5eb9-4fa2-8417-beca148a6994 name : API gateway data flow from aws_api_gateway_authorizer source : public-cloud-01.aws_api_gateway_authorizer-api_authorizer destination : public-cloud-01.aws_cognito_user_pool-user_pool tags : - API gateway dataflow resource A, singleton(A) \u2192 B The $source is the origin of the dataflow and has the information about the destination dataflow itself, but the origin resource is mapped as a $singleton in the terraform file. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : api-gateway $source : { $singleton : { $type : { $regex : ^aws_api_gateway_\\w*$ }}} - type : cognito $source : { $type : \"aws_cognito_user_pool\" } dataflows : - name : { $format : \"API gateway data flow from {resource_type}\" } $source : { $type : \"aws_api_gateway_authorizer\" } source : { $numberOfSources : { oneSource : { $path : \"resource_id\" }, multipleSource : { $format : \"api-gateway (grouped)\" }}} destination : { $path : \"resource_properties.provider_arns[0]\" } tags : - API gateway dataflow resource \"aws_api_gateway_rest_api\" \"rest_api\" { } resource \"aws_cognito_user_pool\" \"user_pool\" { } resource \"aws_api_gateway_authorizer\" \"api_authorizer\" { provider_arns = [ aws_cognito_user_pool.user_pool.arn ] } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud risk : trustRating : 10 components : - id : public-cloud-01.aws_cognito_user_pool-user_pool name : user_pool type : cognito parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_cognito_user_pool - id : public-cloud-01.aws_api_gateway_rest_api-rest_api name : api-gateway (grouped) type : api-gateway parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - rest_api (aws_api_gateway_rest_api) - api_authorizer (aws_api_gateway_authorizer) dataflows : - id : 3708e8b2-c593-4d4e-a2a6-a9861985ad12 name : API gateway data flow from aws_api_gateway_authorizer source : public-cloud-01.aws_api_gateway_rest_api-rest_api destination : public-cloud-01.aws_cognito_user_pool-user_pool tags : - API gateway dataflow resource A, B \u2192 C . The $source has info to define a dataflow between two different resources. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : s3 $source : { $type : \"aws_s3_bucket\" } dataflows : - name : { $format : \"S3 dataflow from {resource_type}\" } $source : { $type : \"aws_s3_bucket_logging\" } source : { $path : \"resource_properties.bucket\" } destination : { $path : \"resource_properties.target_bucket\" } tags : - $format : \"Dataflow created by {resource_type}-{resource_name}\" resource \"aws_s3_bucket_logging\" \"logging\" { bucket = aws_s3_bucket.bucket.id target_bucket = aws_s3_bucket.log_bucket.id } resource \"aws_s3_bucket\" \"bucket\" { } resource \"aws_s3_bucket\" \"log_bucket\" { } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud risk : trustRating : 10 components : - id : public-cloud-01.aws_s3_bucket-bucket name : bucket type : s3 parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_s3_bucket - id : public-cloud-01.aws_s3_bucket-log_bucket name : log_bucket type : s3 parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_s3_bucket dataflows : - id : 591089c3-9dc1-42c0-a574-3674f2d9deaf name : S3 dataflow from aws_s3_bucket_logging source : public-cloud-01.aws_s3_bucket-bucket destination : public-cloud-01.aws_s3_bucket-log_bucket tags : - Dataflow created by aws_s3_bucket_logging-logging Security Groups as dataflows After some analysis of the best way on how to implement Security Groups(as trustzones, components or dataflows), the final decision was to begin implementing them as dataflows, leaving for later a possible implementation in other ways. Scope of a Security Group If a Threat Model is going to be generated from a Terraform file and the IaC file contains AWS resources and some of those AWS resources contains Security Groups information and this information is consistent and sufficient then there are AWS Security Groups that can be threat modeled as dataflows from the IaC file Security Group referencing external IPs If an AWS Security Group has got security group rules referencing an external IP then the resultant Threat Model will include an Internet trust zone and that trust zone will include a \"generic terminal\" component and this \"generic terminal\" component will be named as the external IP and this \"generic terminal\" component will be the origin or destination to all associated components to the SG. Security Group Egress Security Group Ingress A \u2192 SG_A \u2192 B These are the dataflows that have only one Security Group between the two connected resources. Security Group as dataflow type 1: A \u2192 SG_A \u2192 B If an IaC resource is an AWS Security Group and has Security Group rules inside SecurityGroupIngress and/or SecurityGroupEgress data structures and there is an AWS resource with SecurityGroupIds containing the name of the AWS Security Group then the AWS resource is associated to that Security Group and the AWS resource will take from Security Group the rules to allow inbound or outbound connections Mapping file Resource File OTM IriusRisk Threat Model Example trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true - id : f0ba7722-39b6-4c81-8290-a30a248bb8d9 name : Internet type : f0ba7722-39b6-4c81-8290-a30a248bb8d9 $source : { $singleton : { $type : \"aws_security_group\" , $props : [ \"egress[0].cidr_blocks\" , \"ingress[0].cidr_blocks\" ]}} components : - type : vpc $source : { $type : \"aws_vpc\" } - type : empty-component $source : { $type : \"aws_subnet\" } parent : { $path : \"resource_properties.vpc_id\" } - type : empty-component $source : { $type : \"aws_vpc_endpoint\" } parent : { $path : \"resource_properties.subnet_ids\" } - type : generic-client name : { $ip : { $path : \"resource_properties.egress[0].cidr_blocks\" }} $source : { $type : \"aws_security_group\" , $props : \"egress[0].cidr_blocks\" } parent : f0ba7722-39b6-4c81-8290-a30a248bb8d9 tags : - Outbound connection destination IP - type : generic-client name : { $ip : { $path : \"resource_properties.ingress[0].cidr_blocks\" }} $source : { $type : \"aws_security_group\" , $props : \"ingress[0].cidr_blocks\" } parent : f0ba7722-39b6-4c81-8290-a30a248bb8d9 tags : - Inbound connection source IP dataflows : - $source : { $props : \"security_group_ids\" } source : { $path : \"resource_id\" } destination : { $hub : { $path : \"resource_properties.security_group_ids\" }} - $source : { $type : \"aws_security_group\" } source : { $path : \"resource_properties.ingress[0].cidr_blocks\" } destination : { $hub : { $path : \"resource_id\" }} tags : - $path : \"resource_properties.ingress[0].description\" - $path : \"resource_properties.ingress[0].protocol\" - $path : \"resource_properties.ingress[0].from_port|to_string(@)\" - $path : \"resource_properties.ingress[0].to_port|to_string(@)\" - $source : { $type : \"aws_security_group\" } source : { $hub : { $path : \"resource_id\" }} destination : { $path : \"resource_properties.egress[0].cidr_blocks\" } tags : - $path : \"resource_properties.egress[0].description\" - $path : \"resource_properties.egress[0].protocol\" - $path : \"resource_properties.egress[0].cidr_blocks|join(',', @)\" variable \"vpcCidrblock\" { default = [ \"10.0.0.0/16\" ] } resource \"aws_vpc\" \"CustomVPC\" { cidr_block = var.vpcCidrblock } resource \"aws_subnet\" \"PrivateSubnet1\" { vpc_id = aws_vpc.CustomVPC.id } resource \"aws_security_group\" \"VPCssmSecurityGroup\" { vpc_id = aws_vpc.CustomVPC.id ingress { cidr_blocks = var.vpcCidrblock from_port = 443 to_port = 443 protocol = \"tcp\" description = \"from CustomVPC:443\" } egress { from_port = 0 to_port = 0 protocol = \"-1\" cidr_blocks = [ \"0.0.0.0/0\" ] description = \"Allow all outbound traffic by default\" } } resource \"aws_vpc_endpoint\" \"VPCssm\" { security_group_ids = [ aws_security_group.VPCssmSecurityGroup.id , ] subnet_ids = [ aws_subnet.PrivateSubnet1.id ] } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud risk : trustRating : 10 - id : f0ba7722-39b6-4c81-8290-a30a248bb8d9 name : Internet risk : trustRating : 10 components : - id : public-cloud-01.aws_vpc-customvpc name : CustomVPC type : vpc parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_vpc - id : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1 name : PrivateSubnet1 type : empty-component parent : component : public-cloud-01.aws_vpc-customvpc tags : - aws_subnet - id : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1.aws_vpc_endpoint-vpcssm name : VPCssm type : empty-component parent : component : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1 tags : - aws_vpc_endpoint - id : f0ba7722-39b6-4c81-8290-a30a248bb8d9.aws_security_group-vpcssmsecuritygroup.0_0_0_0_0 name : 0.0.0.0/0 type : generic-client parent : trustZone : f0ba7722-39b6-4c81-8290-a30a248bb8d9 tags : - Outbound connection destination IP dataflows : - id : 5173a0d7-a7dc-438a-a8a2-d310294f7698 name : VPCssmSecurityGroup -> VPCssm source : public-cloud-01.aws_vpc-customvpc destination : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1.aws_vpc_endpoint-vpcssm tags : - from CustomVPC:443 - tcp - \"443\" - \"443\" - id : 38306ec7-5db4-421c-9a74-13b2a30ca3f6 name : VPCssm -> VPCssmSecurityGroup source : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1.aws_vpc_endpoint-vpcssm destination : f0ba7722-39b6-4c81-8290-a30a248bb8d9.aws_security_group-vpcssmsecuritygroup.0_0_0_0_0 tags : - Allow all outbound traffic by default - \"-1\" - 0.0.0.0/0 A \u2192 SG_A \u2192 SG_B \u2192 B These are the dataflows that have two Security Groups between the two connected resources like this. Security Group as dataflow type 2: A \u2192 SG_A \u2192 SG_B \u2192 B If there is a Security Group that has ingress or egress data with other AWS Security Groups and both security groups have at least a resource associated to it and the resources are within different subnets then this Security Group will be threat modeled as dataflows between the resource of every subnet to the rest of resources of the other security group The resultant Threat Model is not a network but a TM of a network. If there are the same resources replicated in the Threat Model because there is more than a subnet, applying the rest of business rules for SGs as dataflows, those dataflows will be generated consistently. What is threat modeled are the inbound and outbound connections from some components to other components, not from the component to itself Mapping file Resource File OTM IriusRisk Threat Model Example trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : vpc $source : { $type : \"aws_vpc\" } - type : empty-component $source : { $type : \"aws_subnet\" } parent : { $path : \"resource_properties.vpc_id\" } - type : empty-component $source : { $type : \"aws_vpc_endpoint\" } parent : { $path : \"resource_properties.subnet_ids\" } - type : elastic-container-service $source : { $type : \"aws_ecs_service\" } parent : { $path : \"resource_properties.network_configuration[0].subnets\" } - type : load-balancer $source : { $type : \"aws_lb\" } parent : { $path : \"resource_properties.subnets\" } dataflows : - $source : { $props : \"security_groups\" } source : { $path : \"resource_id\" } destination : { $hub : { $path : \"resource_properties.security_groups\" }} - $source : { $props : \"network_configuration | [0].security_groups\" } source : { $path : \"resource_id\" } destination : { $hub : { $path : \"resource_properties.network_configuration[0].security_groups\" }} - $source : { $type : \"aws_security_group_rule\" , $props : \"type=='ingress'\" } source : { $hub : { $path : \"resource_properties.source_security_group_id\" }} destination : { $hub : { $path : \"resource_properties.security_group_id\" }} tags : - $path : \"resource_properties.description\" - $path : \"resource_properties.protocol\" - $path : \"resource_properties.from_port|to_string(@)\" - $path : \"resource_properties.to_port|to_string(@)\" - $source : { $type : \"aws_security_group_rule\" , $props : \"type=='egress'\" } source : { $hub : { $path : \"resource_properties.security_group_id\" }} destination : { $hub : { $path : \"resource_properties.source_security_group_id\" }} tags : - $path : \"resource_properties.description\" - $path : \"resource_properties.protocol\" - $path : \"resource_properties.from_port|to_string(@)\" - $path : \"resource_properties.to_port|to_string(@)\" resource \"aws_vpc\" \"CustomVPC\" { cidr_block = \"10.0.0.0/16\" } resource \"aws_subnet\" \"PrivateSubnet1\" { vpc_id = aws_vpc.CustomVPC.id } resource \"aws_subnet\" \"PrivateSubnet2\" { vpc_id = aws_vpc.CustomVPC.id } resource \"aws_security_group\" \"OutboundSecurityGroup\" { vpc_id = aws_vpc.CustomVPC.id } resource \"aws_security_group\" \"ServiceLBSecurityGroup\" { vpc_id = aws_vpc.CustomVPC.id } resource \"aws_security_group_rule\" \"OutboundSecurityGroupIngressfromServiceLBSecurityGroup\" { type = \"ingress\" from_port = 80 to_port = 80 protocol = \"tcp\" security_group_id = aws_security_group.OutboundSecurityGroup.id source_security_group_id = aws_security_group.ServiceLBSecurityGroup.id description = \"Load balancer to target\" } resource \"aws_security_group_rule\" \"ServiceLBSecurityGroupEgresstoOutboundSecurityGroup\" { type = \"egress\" from_port = 80 to_port = 80 protocol = \"tcp\" security_group_id = aws_security_group.ServiceLBSecurityGroup.id source_security_group_id = aws_security_group.OutboundSecurityGroup.id description = \"Load balancer to target\" } resource \"aws_ecs_service\" \"Service\" { network_configuration { subnets = [ aws_subnet.PrivateSubnet1.id , aws_subnet.PrivateSubnet2.id ] security_groups = [ aws_security_group.OutboundSecurityGroup.id ] } } resource \"aws_lb\" \"ServiceLB\" { security_groups = [ aws_security_group.ServiceLBSecurityGroup.id ] subnets = [ aws_subnet.PrivateSubnet1.id , aws_subnet.PrivateSubnet2.id ] } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud risk : trustRating : 10 components : - id : public-cloud-01.aws_vpc-customvpc name : CustomVPC type : vpc parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_vpc - id : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1 name : PrivateSubnet1 type : empty-component parent : component : public-cloud-01.aws_vpc-customvpc tags : - aws_subnet - id : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet2 name : PrivateSubnet2 type : empty-component parent : component : public-cloud-01.aws_vpc-customvpc tags : - aws_subnet - id : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1.aws_ecs_service-service name : Service type : elastic-container-service parent : component : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1 tags : - aws_ecs_service - id : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet2.aws_ecs_service-service name : Service type : elastic-container-service parent : component : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet2 tags : - aws_ecs_service - id : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1.aws_lb-servicelb name : ServiceLB type : load-balancer parent : component : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1 tags : - aws_lb - id : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet2.aws_lb-servicelb name : ServiceLB type : load-balancer parent : component : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet2 tags : - aws_lb dataflows : - id : 9e5be4ce-d37c-423e-9981-4dcb0b39c175 name : ServiceLB -> Service source : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1.aws_lb-servicelb destination : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1.aws_ecs_service-service tags : - Load balancer to target - tcp - \"80\" - \"80\" - Load balancer to target - tcp - \"80\" - \"80\" - id : 92d467a9-6ee8-4f41-8d01-7fb0a6a5e06d name : ServiceLB -> Service source : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1.aws_lb-servicelb destination : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet2.aws_ecs_service-service tags : - Load balancer to target - tcp - \"80\" - \"80\" - Load balancer to target - tcp - \"80\" - \"80\" - id : 2dfbd037-469a-4168-8388-e673f1190a3b name : ServiceLB -> Service source : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet2.aws_lb-servicelb destination : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1.aws_ecs_service-service tags : - Load balancer to target - tcp - \"80\" - \"80\" - Load balancer to target - tcp - \"80\" - \"80\" - id : f04c37bf-3a01-40dd-a0cc-b438c840fa84 name : ServiceLB -> Service source : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet2.aws_lb-servicelb destination : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet2.aws_ecs_service-service tags : - Load balancer to target - tcp - \"80\" - \"80\" - Load balancer to target - tcp - \"80\" - \"80\"","title":"How Dataflow Mapping File works"},{"location":"startleft-processors/iac/tf/Terraform-how-dataflow-mapping-works/#types-of-dataflows-in-terraform","text":"","title":"Types of dataflows in Terraform"},{"location":"startleft-processors/iac/tf/Terraform-how-dataflow-mapping-works/#simple-dataflows","text":"When dataflows mapping attribute has enough information, they are mapped directly through the mapping file. It could be divided into three types:","title":"Simple dataflows"},{"location":"startleft-processors/iac/tf/Terraform-how-dataflow-mapping-works/#resource-a-ab","text":"The $source is the origin of the dataflow and has the information about the destination dataflow itself. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : api-gateway $source : { $type : \"aws_api_gateway_authorizer\" } - type : cognito $source : { $type : \"aws_cognito_user_pool\" } dataflows : - name : { $format : \"API gateway data flow from {resource_type}\" } $source : { $type : \"aws_api_gateway_authorizer\" } source : { $path : \"resource_id\" } destination : { $path : \"resource_properties.provider_arns[0]\" } tags : - API gateway dataflow resource \"aws_cognito_user_pool\" \"user_pool\" { } resource \"aws_api_gateway_authorizer\" \"api_authorizer\" { provider_arns = [ aws_cognito_user_pool.user_pool.arn ] } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud risk : trustRating : 10 components : - id : public-cloud-01.aws_api_gateway_authorizer-api_authorizer name : api_authorizer type : api-gateway parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_api_gateway_authorizer - id : public-cloud-01.aws_cognito_user_pool-user_pool name : user_pool type : cognito parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_cognito_user_pool dataflows : - id : 2ced6f2f-5eb9-4fa2-8417-beca148a6994 name : API gateway data flow from aws_api_gateway_authorizer source : public-cloud-01.aws_api_gateway_authorizer-api_authorizer destination : public-cloud-01.aws_cognito_user_pool-user_pool tags : - API gateway dataflow","title":"resource A, A\u2192B"},{"location":"startleft-processors/iac/tf/Terraform-how-dataflow-mapping-works/#resource-a-singletonab","text":"The $source is the origin of the dataflow and has the information about the destination dataflow itself, but the origin resource is mapped as a $singleton in the terraform file. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : api-gateway $source : { $singleton : { $type : { $regex : ^aws_api_gateway_\\w*$ }}} - type : cognito $source : { $type : \"aws_cognito_user_pool\" } dataflows : - name : { $format : \"API gateway data flow from {resource_type}\" } $source : { $type : \"aws_api_gateway_authorizer\" } source : { $numberOfSources : { oneSource : { $path : \"resource_id\" }, multipleSource : { $format : \"api-gateway (grouped)\" }}} destination : { $path : \"resource_properties.provider_arns[0]\" } tags : - API gateway dataflow resource \"aws_api_gateway_rest_api\" \"rest_api\" { } resource \"aws_cognito_user_pool\" \"user_pool\" { } resource \"aws_api_gateway_authorizer\" \"api_authorizer\" { provider_arns = [ aws_cognito_user_pool.user_pool.arn ] } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud risk : trustRating : 10 components : - id : public-cloud-01.aws_cognito_user_pool-user_pool name : user_pool type : cognito parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_cognito_user_pool - id : public-cloud-01.aws_api_gateway_rest_api-rest_api name : api-gateway (grouped) type : api-gateway parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - rest_api (aws_api_gateway_rest_api) - api_authorizer (aws_api_gateway_authorizer) dataflows : - id : 3708e8b2-c593-4d4e-a2a6-a9861985ad12 name : API gateway data flow from aws_api_gateway_authorizer source : public-cloud-01.aws_api_gateway_rest_api-rest_api destination : public-cloud-01.aws_cognito_user_pool-user_pool tags : - API gateway dataflow","title":"resource A, singleton(A)\u2192B"},{"location":"startleft-processors/iac/tf/Terraform-how-dataflow-mapping-works/#resource-a-bc","text":"The $source has info to define a dataflow between two different resources. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : s3 $source : { $type : \"aws_s3_bucket\" } dataflows : - name : { $format : \"S3 dataflow from {resource_type}\" } $source : { $type : \"aws_s3_bucket_logging\" } source : { $path : \"resource_properties.bucket\" } destination : { $path : \"resource_properties.target_bucket\" } tags : - $format : \"Dataflow created by {resource_type}-{resource_name}\" resource \"aws_s3_bucket_logging\" \"logging\" { bucket = aws_s3_bucket.bucket.id target_bucket = aws_s3_bucket.log_bucket.id } resource \"aws_s3_bucket\" \"bucket\" { } resource \"aws_s3_bucket\" \"log_bucket\" { } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud risk : trustRating : 10 components : - id : public-cloud-01.aws_s3_bucket-bucket name : bucket type : s3 parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_s3_bucket - id : public-cloud-01.aws_s3_bucket-log_bucket name : log_bucket type : s3 parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_s3_bucket dataflows : - id : 591089c3-9dc1-42c0-a574-3674f2d9deaf name : S3 dataflow from aws_s3_bucket_logging source : public-cloud-01.aws_s3_bucket-bucket destination : public-cloud-01.aws_s3_bucket-log_bucket tags : - Dataflow created by aws_s3_bucket_logging-logging","title":"resource A, B\u2192C."},{"location":"startleft-processors/iac/tf/Terraform-how-dataflow-mapping-works/#security-groups-as-dataflows","text":"After some analysis of the best way on how to implement Security Groups(as trustzones, components or dataflows), the final decision was to begin implementing them as dataflows, leaving for later a possible implementation in other ways. Scope of a Security Group If a Threat Model is going to be generated from a Terraform file and the IaC file contains AWS resources and some of those AWS resources contains Security Groups information and this information is consistent and sufficient then there are AWS Security Groups that can be threat modeled as dataflows from the IaC file Security Group referencing external IPs If an AWS Security Group has got security group rules referencing an external IP then the resultant Threat Model will include an Internet trust zone and that trust zone will include a \"generic terminal\" component and this \"generic terminal\" component will be named as the external IP and this \"generic terminal\" component will be the origin or destination to all associated components to the SG. Security Group Egress Security Group Ingress","title":"Security Groups as dataflows"},{"location":"startleft-processors/iac/tf/Terraform-how-dataflow-mapping-works/#a-sg_a-b","text":"These are the dataflows that have only one Security Group between the two connected resources. Security Group as dataflow type 1: A \u2192 SG_A \u2192 B If an IaC resource is an AWS Security Group and has Security Group rules inside SecurityGroupIngress and/or SecurityGroupEgress data structures and there is an AWS resource with SecurityGroupIds containing the name of the AWS Security Group then the AWS resource is associated to that Security Group and the AWS resource will take from Security Group the rules to allow inbound or outbound connections Mapping file Resource File OTM IriusRisk Threat Model Example trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true - id : f0ba7722-39b6-4c81-8290-a30a248bb8d9 name : Internet type : f0ba7722-39b6-4c81-8290-a30a248bb8d9 $source : { $singleton : { $type : \"aws_security_group\" , $props : [ \"egress[0].cidr_blocks\" , \"ingress[0].cidr_blocks\" ]}} components : - type : vpc $source : { $type : \"aws_vpc\" } - type : empty-component $source : { $type : \"aws_subnet\" } parent : { $path : \"resource_properties.vpc_id\" } - type : empty-component $source : { $type : \"aws_vpc_endpoint\" } parent : { $path : \"resource_properties.subnet_ids\" } - type : generic-client name : { $ip : { $path : \"resource_properties.egress[0].cidr_blocks\" }} $source : { $type : \"aws_security_group\" , $props : \"egress[0].cidr_blocks\" } parent : f0ba7722-39b6-4c81-8290-a30a248bb8d9 tags : - Outbound connection destination IP - type : generic-client name : { $ip : { $path : \"resource_properties.ingress[0].cidr_blocks\" }} $source : { $type : \"aws_security_group\" , $props : \"ingress[0].cidr_blocks\" } parent : f0ba7722-39b6-4c81-8290-a30a248bb8d9 tags : - Inbound connection source IP dataflows : - $source : { $props : \"security_group_ids\" } source : { $path : \"resource_id\" } destination : { $hub : { $path : \"resource_properties.security_group_ids\" }} - $source : { $type : \"aws_security_group\" } source : { $path : \"resource_properties.ingress[0].cidr_blocks\" } destination : { $hub : { $path : \"resource_id\" }} tags : - $path : \"resource_properties.ingress[0].description\" - $path : \"resource_properties.ingress[0].protocol\" - $path : \"resource_properties.ingress[0].from_port|to_string(@)\" - $path : \"resource_properties.ingress[0].to_port|to_string(@)\" - $source : { $type : \"aws_security_group\" } source : { $hub : { $path : \"resource_id\" }} destination : { $path : \"resource_properties.egress[0].cidr_blocks\" } tags : - $path : \"resource_properties.egress[0].description\" - $path : \"resource_properties.egress[0].protocol\" - $path : \"resource_properties.egress[0].cidr_blocks|join(',', @)\" variable \"vpcCidrblock\" { default = [ \"10.0.0.0/16\" ] } resource \"aws_vpc\" \"CustomVPC\" { cidr_block = var.vpcCidrblock } resource \"aws_subnet\" \"PrivateSubnet1\" { vpc_id = aws_vpc.CustomVPC.id } resource \"aws_security_group\" \"VPCssmSecurityGroup\" { vpc_id = aws_vpc.CustomVPC.id ingress { cidr_blocks = var.vpcCidrblock from_port = 443 to_port = 443 protocol = \"tcp\" description = \"from CustomVPC:443\" } egress { from_port = 0 to_port = 0 protocol = \"-1\" cidr_blocks = [ \"0.0.0.0/0\" ] description = \"Allow all outbound traffic by default\" } } resource \"aws_vpc_endpoint\" \"VPCssm\" { security_group_ids = [ aws_security_group.VPCssmSecurityGroup.id , ] subnet_ids = [ aws_subnet.PrivateSubnet1.id ] } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud risk : trustRating : 10 - id : f0ba7722-39b6-4c81-8290-a30a248bb8d9 name : Internet risk : trustRating : 10 components : - id : public-cloud-01.aws_vpc-customvpc name : CustomVPC type : vpc parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_vpc - id : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1 name : PrivateSubnet1 type : empty-component parent : component : public-cloud-01.aws_vpc-customvpc tags : - aws_subnet - id : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1.aws_vpc_endpoint-vpcssm name : VPCssm type : empty-component parent : component : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1 tags : - aws_vpc_endpoint - id : f0ba7722-39b6-4c81-8290-a30a248bb8d9.aws_security_group-vpcssmsecuritygroup.0_0_0_0_0 name : 0.0.0.0/0 type : generic-client parent : trustZone : f0ba7722-39b6-4c81-8290-a30a248bb8d9 tags : - Outbound connection destination IP dataflows : - id : 5173a0d7-a7dc-438a-a8a2-d310294f7698 name : VPCssmSecurityGroup -> VPCssm source : public-cloud-01.aws_vpc-customvpc destination : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1.aws_vpc_endpoint-vpcssm tags : - from CustomVPC:443 - tcp - \"443\" - \"443\" - id : 38306ec7-5db4-421c-9a74-13b2a30ca3f6 name : VPCssm -> VPCssmSecurityGroup source : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1.aws_vpc_endpoint-vpcssm destination : f0ba7722-39b6-4c81-8290-a30a248bb8d9.aws_security_group-vpcssmsecuritygroup.0_0_0_0_0 tags : - Allow all outbound traffic by default - \"-1\" - 0.0.0.0/0","title":"A \u2192 SG_A \u2192 B"},{"location":"startleft-processors/iac/tf/Terraform-how-dataflow-mapping-works/#a-sg_a-sg_b-b","text":"These are the dataflows that have two Security Groups between the two connected resources like this. Security Group as dataflow type 2: A \u2192 SG_A \u2192 SG_B \u2192 B If there is a Security Group that has ingress or egress data with other AWS Security Groups and both security groups have at least a resource associated to it and the resources are within different subnets then this Security Group will be threat modeled as dataflows between the resource of every subnet to the rest of resources of the other security group The resultant Threat Model is not a network but a TM of a network. If there are the same resources replicated in the Threat Model because there is more than a subnet, applying the rest of business rules for SGs as dataflows, those dataflows will be generated consistently. What is threat modeled are the inbound and outbound connections from some components to other components, not from the component to itself Mapping file Resource File OTM IriusRisk Threat Model Example trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : vpc $source : { $type : \"aws_vpc\" } - type : empty-component $source : { $type : \"aws_subnet\" } parent : { $path : \"resource_properties.vpc_id\" } - type : empty-component $source : { $type : \"aws_vpc_endpoint\" } parent : { $path : \"resource_properties.subnet_ids\" } - type : elastic-container-service $source : { $type : \"aws_ecs_service\" } parent : { $path : \"resource_properties.network_configuration[0].subnets\" } - type : load-balancer $source : { $type : \"aws_lb\" } parent : { $path : \"resource_properties.subnets\" } dataflows : - $source : { $props : \"security_groups\" } source : { $path : \"resource_id\" } destination : { $hub : { $path : \"resource_properties.security_groups\" }} - $source : { $props : \"network_configuration | [0].security_groups\" } source : { $path : \"resource_id\" } destination : { $hub : { $path : \"resource_properties.network_configuration[0].security_groups\" }} - $source : { $type : \"aws_security_group_rule\" , $props : \"type=='ingress'\" } source : { $hub : { $path : \"resource_properties.source_security_group_id\" }} destination : { $hub : { $path : \"resource_properties.security_group_id\" }} tags : - $path : \"resource_properties.description\" - $path : \"resource_properties.protocol\" - $path : \"resource_properties.from_port|to_string(@)\" - $path : \"resource_properties.to_port|to_string(@)\" - $source : { $type : \"aws_security_group_rule\" , $props : \"type=='egress'\" } source : { $hub : { $path : \"resource_properties.security_group_id\" }} destination : { $hub : { $path : \"resource_properties.source_security_group_id\" }} tags : - $path : \"resource_properties.description\" - $path : \"resource_properties.protocol\" - $path : \"resource_properties.from_port|to_string(@)\" - $path : \"resource_properties.to_port|to_string(@)\" resource \"aws_vpc\" \"CustomVPC\" { cidr_block = \"10.0.0.0/16\" } resource \"aws_subnet\" \"PrivateSubnet1\" { vpc_id = aws_vpc.CustomVPC.id } resource \"aws_subnet\" \"PrivateSubnet2\" { vpc_id = aws_vpc.CustomVPC.id } resource \"aws_security_group\" \"OutboundSecurityGroup\" { vpc_id = aws_vpc.CustomVPC.id } resource \"aws_security_group\" \"ServiceLBSecurityGroup\" { vpc_id = aws_vpc.CustomVPC.id } resource \"aws_security_group_rule\" \"OutboundSecurityGroupIngressfromServiceLBSecurityGroup\" { type = \"ingress\" from_port = 80 to_port = 80 protocol = \"tcp\" security_group_id = aws_security_group.OutboundSecurityGroup.id source_security_group_id = aws_security_group.ServiceLBSecurityGroup.id description = \"Load balancer to target\" } resource \"aws_security_group_rule\" \"ServiceLBSecurityGroupEgresstoOutboundSecurityGroup\" { type = \"egress\" from_port = 80 to_port = 80 protocol = \"tcp\" security_group_id = aws_security_group.ServiceLBSecurityGroup.id source_security_group_id = aws_security_group.OutboundSecurityGroup.id description = \"Load balancer to target\" } resource \"aws_ecs_service\" \"Service\" { network_configuration { subnets = [ aws_subnet.PrivateSubnet1.id , aws_subnet.PrivateSubnet2.id ] security_groups = [ aws_security_group.OutboundSecurityGroup.id ] } } resource \"aws_lb\" \"ServiceLB\" { security_groups = [ aws_security_group.ServiceLBSecurityGroup.id ] subnets = [ aws_subnet.PrivateSubnet1.id , aws_subnet.PrivateSubnet2.id ] } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud risk : trustRating : 10 components : - id : public-cloud-01.aws_vpc-customvpc name : CustomVPC type : vpc parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_vpc - id : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1 name : PrivateSubnet1 type : empty-component parent : component : public-cloud-01.aws_vpc-customvpc tags : - aws_subnet - id : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet2 name : PrivateSubnet2 type : empty-component parent : component : public-cloud-01.aws_vpc-customvpc tags : - aws_subnet - id : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1.aws_ecs_service-service name : Service type : elastic-container-service parent : component : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1 tags : - aws_ecs_service - id : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet2.aws_ecs_service-service name : Service type : elastic-container-service parent : component : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet2 tags : - aws_ecs_service - id : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1.aws_lb-servicelb name : ServiceLB type : load-balancer parent : component : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1 tags : - aws_lb - id : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet2.aws_lb-servicelb name : ServiceLB type : load-balancer parent : component : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet2 tags : - aws_lb dataflows : - id : 9e5be4ce-d37c-423e-9981-4dcb0b39c175 name : ServiceLB -> Service source : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1.aws_lb-servicelb destination : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1.aws_ecs_service-service tags : - Load balancer to target - tcp - \"80\" - \"80\" - Load balancer to target - tcp - \"80\" - \"80\" - id : 92d467a9-6ee8-4f41-8d01-7fb0a6a5e06d name : ServiceLB -> Service source : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1.aws_lb-servicelb destination : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet2.aws_ecs_service-service tags : - Load balancer to target - tcp - \"80\" - \"80\" - Load balancer to target - tcp - \"80\" - \"80\" - id : 2dfbd037-469a-4168-8388-e673f1190a3b name : ServiceLB -> Service source : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet2.aws_lb-servicelb destination : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet1.aws_ecs_service-service tags : - Load balancer to target - tcp - \"80\" - \"80\" - Load balancer to target - tcp - \"80\" - \"80\" - id : f04c37bf-3a01-40dd-a0cc-b438c840fa84 name : ServiceLB -> Service source : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet2.aws_lb-servicelb destination : public-cloud-01.aws_vpc-customvpc.aws_subnet-privatesubnet2.aws_ecs_service-service tags : - Load balancer to target - tcp - \"80\" - \"80\" - Load balancer to target - tcp - \"80\" - \"80\"","title":"A \u2192 SG_A \u2192 SG_B \u2192 B"},{"location":"startleft-processors/iac/tf/Terraform-how-mapping-file-works/","text":"This page is an in-depth explanation of how slp_tf handles mapping and Terraform resource files to generate an OTM. This diagram shows how mapping and Terraform resource files are pre-processed to simplify and decouple the Terraform parser logic from the input files. Loading the Terraform Source File In this step, the Terraform Loader receives a file written in the Terraform configuration language and generates a Terraform source dictionary with the internal data structure used by the Terraform Parser for compose the OTM. What is a Terraform Configuration \"A Terraform configuration is a complete document in the Terraform language that tells Terraform how to manage a given collection of infrastructure. A configuration can consist of multiple files and directories.\" Terraform language Syntax The syntax of the Terraform language consists of only a few basic elements resource \"aws_vpc\" \"main\" { cidr_block = var.base_cidr_block } <BLOCK TYPE> \"<BLOCK LABEL>\" \"<BLOCK LABEL>\" { # Block body <IDENTIFIER> = <EXPRESSION> # Argument } Example for Network topology for Amazon Web Services The following example describes a simple network topology for Amazon Web Services, just to give you a sense of the overall structure and syntax of the Terraform language. Similar configurations can be created for other virtual network services, using resource types defined by other providers, and a practical network configuration will often contain additional elements not shown here. terraform { required_providers { aws = { source = \"hashicorp/aws\" version = \"~> 1.0.4\" } } } variable \"aws_region\" {} variable \"base_cidr_block\" { description = \"A /16 CIDR range definition, such as 10.1.0.0/16, that the VPC will use\" default = \"10.1.0.0/16\" } variable \"availability_zones\" { description = \"A list of availability zones in which to create subnets\" type = list ( string ) } provider \"aws\" { region = var.aws_region } resource \"aws_vpc\" \"main\" { # Referencing the base_cidr_block variable allows the network address # to be changed without modifying the configuration. cidr_block = var.base_cidr_block } resource \"aws_subnet\" \"az\" { # Create one subnet for each given availability zone. count = length ( var.availability_zones ) # For each subnet, use one of the specified availability zones. availability_zone = var.availability_zones[count.index ] # By referencing the aws_vpc.main object, Terraform knows that the subnet # must be created only after the VPC is created. vpc_id = aws_vpc.main.id # Built-in functions and operators can be used for simple transformations of # values, such as computing a subnet address. Here we create a /20 prefix for # each subnet, using consecutive addresses for each availability zone, # such as 10.1.16.0/20 . cidr_block = cidrsubnet ( aws_vpc.main.cidr_block , 4 , count.index + 1 ) } Terraform Source Dictionary The most important data for the TerraformParser is placed into the <BLOCK TYPE> : Resource Blocks and Module Blocks This TerraformLoader takes the Terraform Configuration files and generates the Terraform source dictionary used to build the OTM. It is important to notice that the mapping file works always against this data structure and not the against raw Terraform source. Terraform Source Dictionary Syntax This data structure is generated by post-processing the Terraform Configuration files for adding the values resource_type, resource_name and resource_properties which will be used to configure the mapping behavior. Some additional data may exist due to its existence in the original loaded file. The fields resource_* is used for matching and generating the OTM components. Terraform Configuration files Terraform source dictionary # [...] Reduced for simplicity resource \"aws_vpc\" \"main\" { cidr_block = var.base_cidr_block } resource \"aws_subnet\" \"az\" { count = length ( var.availability_zones ) availability_zone = var.availability_zones[count.index ] vpc_id = aws_vpc.main.id cidr_block = cidrsubnet ( aws_vpc.main.cidr_block , 4 , count.index + 1 ) } module \"vpc\" { source = \"terraform-aws-modules/vpc/aws\" } # [...] Reduced for simplicity # [...] Reduced for simplicity resource : - resource_type : aws_vpc resource_name : main resource_properties : cidr_block : '${var.base_cidr_block}' - resource_type : aws_subnet resource_name : az resource_properties : count : '${length(var.availability_zones)}' availability_zone : '${var.availability_zones[count.index]}' vpc_id : '${aws_vpc.main.id}' cidr_block : '${cidrsubnet(aws_vpc.main.cidr_block,4,count.index + 1)}' module : - vpc : source : terraform-aws-modules/vpc/aws # [...] Reduced for simplicity Creating a Terraform Mapping File This section will explain the three different sections into which a Mapping File is divided. How To Map TrustZones The TrustZone is a Threat Modelling concept that will never be present as is in the Terraform source file. Thus, the slp_tf relies on the configuration defined in the trustzones section of the Mapping File. trustzones : # (1)! - id : public-cloud-01 # (2)! name : Public Cloud # (3)! type : b61d6911-338d-46a8-9f39-8dcd24abfe91 # (5)! $default : true # (4)! trustzones section defines the TrustZone mapping behavior. At least one TrustZone is needed to be defined set trustzone[id] value, which also can be used as a reference when setting the parent of a component parent: public-cloud . The id field uniquely identifies a trustzone, and differentiates it from other trustzones of the same type. set trustzone[name] value Optional: default trustzone to be used if a component does not define its parent set trustzone[type] value. For mapping trustzones to IriusRisk trustzones, type field must take internal IriusRisk values depending on the type of trustzone. For the purpose of preserving backwards compatibility, StartLeft also accepts the legacy mapping file format. In this format, there is no type field and the id will be used as both, ID and type. It is not possible to have multiple trustzones of the same type when using this format. The creation of some TrustZone may depend on the existence of some resources in the original file. To configure this behavior, the $source attribute is used. trustzones : - id : internet-01 name : Internet type : f0ba7722-39b6-4c81-8290-a30a248bb8d9 $source : { # (1)! $singleton : # (2)! { $type : \"aws_security_group\" , # (3)! $props : \"egress[0].cidr_blocks\" } # (4)! } special mapping fields $source this attribute is used to configure the mapping behavior which will create a TrustZone All the matching resources will be unified under a single TrustZone which will be created in case the {$type: \"aws_security_group\", $props: \"egress[0].cidr_blocks\"} query returns any element mapping functions $type performs a search along the entire resource list to return the element with the matching type mapping functions $props performs a search along the entire resource list to return the element with the matching props Example for TrustZones Terraform Mapping In this example, two TrustZones are created: The Public Cloud is created as the default TrustZone. The Internet is created because a resource with resource_type == aws_security_group with resource_properties contains egress[0].cidr_blocks is present. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true - id : internet-01 name : Internet type : f0ba7722-39b6-4c81-8290-a30a248bb8d9 $source : { $singleton : { $type : \"aws_security_group\" , $props : \"egress[0].cidr_blocks\" } } [ ... ] Reduced for simplicity [...] Reduced for simplicity resource \"aws_security_group\" \"VPCssmSecurityGroup\" { vpc_id = aws_vpc.CustomVPC.id egress { from_port = 0 to_port = 0 protocol = \"-1\" cidr_blocks = [ \"0.0.0.0/0\" ] description = \"Allow all outbound traffic by default\" } } [...] Reduced for simplicity trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 - id : internet-01 name : Internet type : f0ba7722-39b6-4c81-8290-a30a248bb8d9 risk : trustRating : 10 [ ... ] Reduced for simplicity How To Map Components This section explains several ways of mapping a resource to an OTM component. Those components are retrieved by the Terraform Domain-Specific Language available functions configured in special mapping fields $source . We will use the $type Terraform DSL function in the following examples for simplicity. Mapping a component The easiest way to map a component is to define the output type value and the $source to specify the source of the object type Component Template Pattern To reduce the minimal amount of data needed for mapping files, a template pattern is used to set the common attributes. name : # (1)! { $numberOfSources : { # (2)! oneSource : { $path : \"resource_name\" }, multipleSource : { $format : \"{type} (grouped)\" }}} # parent : { $parent : $default_tz } # (3)! tags : # (4)! - { $numberOfSources : { # (5)! oneSource : { $path : \"resource_type\" }, multipleSource : { $format : \"{resource_name} ({resource_type})\" }}} set the component[name] value returns the value multipleSource in case ( $singleton && exists more than 1 resource), returns oneSource otherwise. set the component[parent] as the default configured TrustZone set the component[tags] value returns the value multipleSource in case ( $singleton && exists more than 1 resource), returns oneSource otherwise. The values provided in the mapping file have always priority over the template\u2019s ones. Example The following configuration: - type : CD-ACM $source : { $singleton : { $type : \"aws_acm_certificate\" }} would be internally converted to: - type : CD-ACM name : { $numberOfSources : { oneSource : { $path : \"resource_name\" }, multipleSource : { $format : \"{type} (grouped)\" }}} $source : { $singleton : { $type : \"aws_acm_certificate\" }} # note: the TZ id is the configured as default parent : { $parent : public-cloud-01 } tags : - { $numberOfSources : { oneSource : { $path : \"resource_type\" }, multipleSource : { $format : \"{resource_name} ({resource_type})\" }}} Mapping file Internal Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : vpc $source : { $type : \"aws_vpc\" } dataflows : [] trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : vpc name : { $numberOfSources : { oneSource : { $path : \"resource_name\" }, multipleSource : { $format : \"{type} (grouped)\" }}} $source : { $type : \"aws_vpc\" } parent : { $parent : public-cloud-01 } tags : - { $numberOfSources : { oneSource : { $path : \"resource_type\" }, multipleSource : { $format : \"{resource_name} ({resource_type})\" }}} dataflows : [] resource \"aws_vpc\" \"CustomVPC\" { cidr_block = var.vpcCidrblock } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_vpc-customvpc name : CustomVPC type : vpc parent : trustZone : public-cloud-01 tags : - aws_vpc dataflows : [] The component identifier is generated internally by the slp_tf . Mapping an AltSource $altsource is a special mapping field that specifies an alternative mapping when $source returns nothing. This is the minimal configuration needed to configure an $altsource, the following Example configures an altsource for aws_s3_bucket - type : s3 $source : { $type : \"aws_s3_bucket\" } $altsource : # (1)! - $mappingType : { $type : \"aws_vpc_endpoint\" } # (2)! $mappingPath : { $path : \"*.service_name | [0]\" } # (3)! $mappingLookups : # (4)! - regex : ^(.*)s3$ # (5)! special mapping fields specifies an alternative mapping when $source returns no object special mapping fields set the selected resources as the object to be mapped special mapping fields specifies the attribute over the one the $mappingLookups logic will be executed contains a set of regular expressions to search inside the string defined in $mappingType and $mappingPath. This field may be multiple because there may be more than one service to infer if regex match with the $mappingPath the component is created This configuration maps a s3 by the existence of a resource with resource_type == aws_vpc_endpoint and *.service_name[0] match regex ^(.*)s3$ but it is only executed in case none resource of aws_s3_bucket type exists . AltSource Template Pattern For reducing the minimal amount of data needed for mapping file, a template pattern is used to set the common attributes for the $mappingLookups attribute. $altsource : - $mappingLookups : - name : \"{mapping['type']} from altsource\" # (1)! type : \"{mapping['type']}\" # (2)! tags : # (3)! - { $numberOfSources : # (4)! { oneSource : { $path : \"resource_type\" }, # (5)! multipleSource : { $format : \"{resource_name} ({resource_type})\" }}} # (6)! set the component[name] value by type inheritance with the suffix from atlsource . set the component[type] value by type inheritance. set the component[tags] value returns the value multipleSource in case ( $singleton && exists more than 1 resource), returns oneSource otherwise. returns the resource_type as oneSource attribute returns the \" resource_name (resource_type) \" as multipleSource attribute The values provided in the mapping file are always preferred over the template\u2019s ones. Mapping file Internal Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : s3 $source : { $type : \"aws_s3_bucket\" } $altsource : - $mappingType : { $type : \"aws_vpc_endpoint\" } $mappingPath : { $path : \"*.service_name | [0]\" } $mappingLookups : - regex : ^(.*)s3$ name : S3 from VPCEndpoint dataflows : [] trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : s3 name : { $numberOfSources : { oneSource : { $path : \"resource_name\" }, multipleSource : { $format : \"{type} (grouped)\" }}} $source : { $type : \"aws_s3_bucket\" } $altsource : - $mappingType : { $type : \"aws_vpc_endpoint\" } $mappingPath : { $path : \"*.service_name | [0]\" } $mappingLookups : - regex : ^(.*)s3$ name : S3 from VPCEndpoint type : s3 tags : - { $numberOfSources : { oneSource : { $path : \"resource_type\" }, multipleSource : { $format : \"{resource_name} ({resource_type})\" }}} parent : { $parent : public-cloud-01 } tags : - { $numberOfSources : { oneSource : { $path : \"resource_type\" }, multipleSource : { $format : \"{resource_name} ({resource_type})\" }}} dataflows : [] resource \"aws_vpc_endpoint\" \"s3\" { vpc_id = data.aws_vpc.selected.id service_name = \"com.amazonaws.${var.region}.s3\" vpc_endpoint_type = \"Interface\" private_dns_enabled = true } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_vpc_endpoint-s3-altsource name : S3 from VPCEndpoint type : s3 parent : trustZone : public-cloud-01 tags : - aws_vpc_endpoint dataflows : [] Note that the template component name is override for $mappingLookups[].name on the Mapping File. Mapping a Parent The order of the components is important because parent components must be defined before child components. When mapping a component, the default TrustZone is set to the parent component value by the component template pattern, nevertheless, it can be modified to set other TrustZones or Component with the attribute component['parent'] in the mapping file. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : empty-component $source : { $type : \"aws_subnet\" } - type : load-balancer $source : { $type : [ \"aws_lb\" , \"aws_elb\" ]} parent : { $path : \"resource_properties.subnets\" } dataflows : [] resource \"aws_subnet\" \"PrivateSubnet1\" { vpc_id = aws_vpc.CustomVPC.id cidr_block = \"10.0.2.0/24\" } resource \"aws_subnet\" \"PrivateSubnet2\" { vpc_id = aws_vpc.CustomVPC.id cidr_block = \"10.0.3.0/24\" } resource \"aws_lb\" \"ServiceLB\" { subnets = [ aws_subnet.PrivateSubnet1.id , aws_subnet.PrivateSubnet2.id ] } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_subnet-privatesubnet1 name : PrivateSubnet1 type : empty-component parent : trustZone : public-cloud-01 tags : - aws_subnet - id : public-cloud-01.aws_subnet-privatesubnet2 name : PrivateSubnet2 type : empty-component parent : trustZone : public-cloud-01 tags : - aws_subnet - id : >- public-cloud-01.aws_subnet-privatesubnet1.aws_lb-servicelb name : ServiceLB type : load-balancer parent : component : public-cloud-01.aws_subnet-privatesubnet1 tags : - aws_lb - id : >- public-cloud-01.aws_subnet-privatesubnet2.aws_lb-servicelb name : ServiceLB type : load-balancer parent : component : public-cloud-01.aws_subnet-privatesubnet2 tags : - aws_lb dataflows : [] This mapper defines a load-balancer by resources of type aws_lb or aws_elb and sets its parent by its resource_properties.subnets value. This component will be created as many times as subnets exist . Mapping a Children The order of the components is important because parent components must be defined before child components. When mapping a component, it can define what components are their children on the OTM. $children will set the parent attribute of those components on the OTM. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : elastic-container-service $source : { $type : \"aws_ecs_service\" } parent : { $path : \"resource_properties.network_configuration[0].subnets\" } $children : { $path : \"resource_properties.task_definition|split(@, '.')[1]\" } - type : docker-container $source : { $type : \"aws_ecs_task_definition\" } dataflows : [] resource \"aws_ecs_task_definition\" \"service\" { } resource \"aws_ecs_service\" \"mongo\" { task_definition = aws_ecs_task_definition.service.arn } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_ecs_service-mongo name : mongo type : elastic-container-service parent : trustZone : public-cloud-01 tags : - aws_ecs_service - id : public-cloud-01.aws_ecs_service-mongo.aws_ecs_task_definition-service name : service type : docker-container parent : component : public-cloud-01.aws_ecs_service-mongo tags : - aws_ecs_task_definition dataflows : [] Mapping a Module The modules imported in a Terraform file can be mapped into OTM components using the special mapping field $module to match the module[].source value. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : rds $source : { $module : \"terraform-aws-modules/rds/aws\" } - type : vpc $source : { $module : \"terraform-aws-modules/vpc/aws\" } - type : load-balancer $source : { $module : \"terraform-aws-modules/alb/aws\" } dataflows : [] module \"db\" { source = \"terraform-aws-modules/rds/aws\" } module \"vpc\" { source = \"terraform-aws-modules/vpc/aws\" } module \"alb\" { source = \"terraform-aws-modules/alb/aws\" } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.db name : db type : rds parent : trustZone : public-cloud-01 tags : - terraform-aws-modules/rds/aws - id : public-cloud-01.vpc name : vpc type : vpc parent : trustZone : public-cloud-01 tags : - terraform-aws-modules/vpc/aws - id : public-cloud-01.alb name : alb type : load-balancer parent : trustZone : public-cloud-01 tags : - terraform-aws-modules/alb/aws dataflows : [] How To Map Dataflows The Dataflows is a Threat Modelling concept that will never be present as is in the Terraform source file. Thus, the slp_tf relies on the configuration defined in the dataflows section of the Mapping File. dataflows : # (1)! - name : { $format : \"S3 dataflow from {resource_type}\" } # (2)! $source : { $type : \"aws_s3_bucket_logging\" } # (3)! source : { $path : \"resource_properties.bucket\" } # (4)! destination : { $path : \"resource_properties.target_bucket\" } # (5)! tags : # (6)! - $format : \"Dataflow created by {resource_type}-{resource_name}\" dataflows section defines the Dataflows mapping behavior. set dataflow[name] value special mapping fields $source this attribute is used to configure the mapping behavior which will create a dataflow set dataflow[source] value using any attribute available at the $source set dataflow[destination] value using any attribute available at the $source Optional: set component[tag] value The mapping name attribute is optional, resource_name will use as default The creation of some dataflow may depend on the existence of some resources in the original file. To configure this behavior, the $source attribute is used. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : s3 $source : { $type : \"aws_s3_bucket\" } dataflows : - name : { $format : \"S3 dataflow from {resource_type}\" } $source : { $type : \"aws_s3_bucket_logging\" } source : { $path : \"resource_properties.bucket\" } destination : { $path : \"resource_properties.target_bucket\" } tags : - $format : \"Dataflow created by {resource_type}-{resource_name}\" resource \"aws_s3_bucket_logging\" \"logging\" { bucket = aws_s3_bucket.bucket.id target_bucket = aws_s3_bucket.log_bucket.id } resource \"aws_s3_bucket\" \"bucket\" { } resource \"aws_s3_bucket\" \"log_bucket\" { } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud risk : trustRating : 10 components : - id : public-cloud-01.aws_s3_bucket-bucket name : bucket type : s3 parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_s3_bucket - id : public-cloud-01.aws_s3_bucket-log_bucket name : log_bucket type : s3 parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_s3_bucket dataflows : - id : 591089c3-9dc1-42c0-a574-3674f2d9deaf name : S3 dataflow from aws_s3_bucket_logging source : public-cloud-01.aws_s3_bucket-bucket destination : public-cloud-01.aws_s3_bucket-log_bucket tags : - Dataflow created by aws_s3_bucket_logging-logging The dataflow identifier is generated internally by the slp_tf . As Terraform Dataflows may be a complicated concept, refer to the How Dataflow Mapping works section for deeper explanation.","title":"How Mapping File works"},{"location":"startleft-processors/iac/tf/Terraform-how-mapping-file-works/#loading-the-terraform-source-file","text":"In this step, the Terraform Loader receives a file written in the Terraform configuration language and generates a Terraform source dictionary with the internal data structure used by the Terraform Parser for compose the OTM.","title":"Loading the Terraform Source File"},{"location":"startleft-processors/iac/tf/Terraform-how-mapping-file-works/#what-is-a-terraform-configuration","text":"\"A Terraform configuration is a complete document in the Terraform language that tells Terraform how to manage a given collection of infrastructure. A configuration can consist of multiple files and directories.\" Terraform language Syntax The syntax of the Terraform language consists of only a few basic elements resource \"aws_vpc\" \"main\" { cidr_block = var.base_cidr_block } <BLOCK TYPE> \"<BLOCK LABEL>\" \"<BLOCK LABEL>\" { # Block body <IDENTIFIER> = <EXPRESSION> # Argument } Example for Network topology for Amazon Web Services The following example describes a simple network topology for Amazon Web Services, just to give you a sense of the overall structure and syntax of the Terraform language. Similar configurations can be created for other virtual network services, using resource types defined by other providers, and a practical network configuration will often contain additional elements not shown here. terraform { required_providers { aws = { source = \"hashicorp/aws\" version = \"~> 1.0.4\" } } } variable \"aws_region\" {} variable \"base_cidr_block\" { description = \"A /16 CIDR range definition, such as 10.1.0.0/16, that the VPC will use\" default = \"10.1.0.0/16\" } variable \"availability_zones\" { description = \"A list of availability zones in which to create subnets\" type = list ( string ) } provider \"aws\" { region = var.aws_region } resource \"aws_vpc\" \"main\" { # Referencing the base_cidr_block variable allows the network address # to be changed without modifying the configuration. cidr_block = var.base_cidr_block } resource \"aws_subnet\" \"az\" { # Create one subnet for each given availability zone. count = length ( var.availability_zones ) # For each subnet, use one of the specified availability zones. availability_zone = var.availability_zones[count.index ] # By referencing the aws_vpc.main object, Terraform knows that the subnet # must be created only after the VPC is created. vpc_id = aws_vpc.main.id # Built-in functions and operators can be used for simple transformations of # values, such as computing a subnet address. Here we create a /20 prefix for # each subnet, using consecutive addresses for each availability zone, # such as 10.1.16.0/20 . cidr_block = cidrsubnet ( aws_vpc.main.cidr_block , 4 , count.index + 1 ) }","title":"What is a Terraform Configuration"},{"location":"startleft-processors/iac/tf/Terraform-how-mapping-file-works/#terraform-source-dictionary","text":"The most important data for the TerraformParser is placed into the <BLOCK TYPE> : Resource Blocks and Module Blocks This TerraformLoader takes the Terraform Configuration files and generates the Terraform source dictionary used to build the OTM. It is important to notice that the mapping file works always against this data structure and not the against raw Terraform source.","title":"Terraform Source Dictionary"},{"location":"startleft-processors/iac/tf/Terraform-how-mapping-file-works/#terraform-source-dictionary-syntax","text":"This data structure is generated by post-processing the Terraform Configuration files for adding the values resource_type, resource_name and resource_properties which will be used to configure the mapping behavior. Some additional data may exist due to its existence in the original loaded file. The fields resource_* is used for matching and generating the OTM components. Terraform Configuration files Terraform source dictionary # [...] Reduced for simplicity resource \"aws_vpc\" \"main\" { cidr_block = var.base_cidr_block } resource \"aws_subnet\" \"az\" { count = length ( var.availability_zones ) availability_zone = var.availability_zones[count.index ] vpc_id = aws_vpc.main.id cidr_block = cidrsubnet ( aws_vpc.main.cidr_block , 4 , count.index + 1 ) } module \"vpc\" { source = \"terraform-aws-modules/vpc/aws\" } # [...] Reduced for simplicity # [...] Reduced for simplicity resource : - resource_type : aws_vpc resource_name : main resource_properties : cidr_block : '${var.base_cidr_block}' - resource_type : aws_subnet resource_name : az resource_properties : count : '${length(var.availability_zones)}' availability_zone : '${var.availability_zones[count.index]}' vpc_id : '${aws_vpc.main.id}' cidr_block : '${cidrsubnet(aws_vpc.main.cidr_block,4,count.index + 1)}' module : - vpc : source : terraform-aws-modules/vpc/aws # [...] Reduced for simplicity","title":"Terraform Source Dictionary Syntax"},{"location":"startleft-processors/iac/tf/Terraform-how-mapping-file-works/#creating-a-terraform-mapping-file","text":"This section will explain the three different sections into which a Mapping File is divided.","title":"Creating a Terraform Mapping File"},{"location":"startleft-processors/iac/tf/Terraform-how-mapping-file-works/#how-to-map-trustzones","text":"The TrustZone is a Threat Modelling concept that will never be present as is in the Terraform source file. Thus, the slp_tf relies on the configuration defined in the trustzones section of the Mapping File. trustzones : # (1)! - id : public-cloud-01 # (2)! name : Public Cloud # (3)! type : b61d6911-338d-46a8-9f39-8dcd24abfe91 # (5)! $default : true # (4)! trustzones section defines the TrustZone mapping behavior. At least one TrustZone is needed to be defined set trustzone[id] value, which also can be used as a reference when setting the parent of a component parent: public-cloud . The id field uniquely identifies a trustzone, and differentiates it from other trustzones of the same type. set trustzone[name] value Optional: default trustzone to be used if a component does not define its parent set trustzone[type] value. For mapping trustzones to IriusRisk trustzones, type field must take internal IriusRisk values depending on the type of trustzone. For the purpose of preserving backwards compatibility, StartLeft also accepts the legacy mapping file format. In this format, there is no type field and the id will be used as both, ID and type. It is not possible to have multiple trustzones of the same type when using this format. The creation of some TrustZone may depend on the existence of some resources in the original file. To configure this behavior, the $source attribute is used. trustzones : - id : internet-01 name : Internet type : f0ba7722-39b6-4c81-8290-a30a248bb8d9 $source : { # (1)! $singleton : # (2)! { $type : \"aws_security_group\" , # (3)! $props : \"egress[0].cidr_blocks\" } # (4)! } special mapping fields $source this attribute is used to configure the mapping behavior which will create a TrustZone All the matching resources will be unified under a single TrustZone which will be created in case the {$type: \"aws_security_group\", $props: \"egress[0].cidr_blocks\"} query returns any element mapping functions $type performs a search along the entire resource list to return the element with the matching type mapping functions $props performs a search along the entire resource list to return the element with the matching props Example for TrustZones Terraform Mapping In this example, two TrustZones are created: The Public Cloud is created as the default TrustZone. The Internet is created because a resource with resource_type == aws_security_group with resource_properties contains egress[0].cidr_blocks is present. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true - id : internet-01 name : Internet type : f0ba7722-39b6-4c81-8290-a30a248bb8d9 $source : { $singleton : { $type : \"aws_security_group\" , $props : \"egress[0].cidr_blocks\" } } [ ... ] Reduced for simplicity [...] Reduced for simplicity resource \"aws_security_group\" \"VPCssmSecurityGroup\" { vpc_id = aws_vpc.CustomVPC.id egress { from_port = 0 to_port = 0 protocol = \"-1\" cidr_blocks = [ \"0.0.0.0/0\" ] description = \"Allow all outbound traffic by default\" } } [...] Reduced for simplicity trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 - id : internet-01 name : Internet type : f0ba7722-39b6-4c81-8290-a30a248bb8d9 risk : trustRating : 10 [ ... ] Reduced for simplicity","title":"How To Map TrustZones"},{"location":"startleft-processors/iac/tf/Terraform-how-mapping-file-works/#how-to-map-components","text":"This section explains several ways of mapping a resource to an OTM component. Those components are retrieved by the Terraform Domain-Specific Language available functions configured in special mapping fields $source . We will use the $type Terraform DSL function in the following examples for simplicity.","title":"How To Map Components"},{"location":"startleft-processors/iac/tf/Terraform-how-mapping-file-works/#mapping-a-component","text":"The easiest way to map a component is to define the output type value and the $source to specify the source of the object type Component Template Pattern To reduce the minimal amount of data needed for mapping files, a template pattern is used to set the common attributes. name : # (1)! { $numberOfSources : { # (2)! oneSource : { $path : \"resource_name\" }, multipleSource : { $format : \"{type} (grouped)\" }}} # parent : { $parent : $default_tz } # (3)! tags : # (4)! - { $numberOfSources : { # (5)! oneSource : { $path : \"resource_type\" }, multipleSource : { $format : \"{resource_name} ({resource_type})\" }}} set the component[name] value returns the value multipleSource in case ( $singleton && exists more than 1 resource), returns oneSource otherwise. set the component[parent] as the default configured TrustZone set the component[tags] value returns the value multipleSource in case ( $singleton && exists more than 1 resource), returns oneSource otherwise. The values provided in the mapping file have always priority over the template\u2019s ones. Example The following configuration: - type : CD-ACM $source : { $singleton : { $type : \"aws_acm_certificate\" }} would be internally converted to: - type : CD-ACM name : { $numberOfSources : { oneSource : { $path : \"resource_name\" }, multipleSource : { $format : \"{type} (grouped)\" }}} $source : { $singleton : { $type : \"aws_acm_certificate\" }} # note: the TZ id is the configured as default parent : { $parent : public-cloud-01 } tags : - { $numberOfSources : { oneSource : { $path : \"resource_type\" }, multipleSource : { $format : \"{resource_name} ({resource_type})\" }}} Mapping file Internal Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : vpc $source : { $type : \"aws_vpc\" } dataflows : [] trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : vpc name : { $numberOfSources : { oneSource : { $path : \"resource_name\" }, multipleSource : { $format : \"{type} (grouped)\" }}} $source : { $type : \"aws_vpc\" } parent : { $parent : public-cloud-01 } tags : - { $numberOfSources : { oneSource : { $path : \"resource_type\" }, multipleSource : { $format : \"{resource_name} ({resource_type})\" }}} dataflows : [] resource \"aws_vpc\" \"CustomVPC\" { cidr_block = var.vpcCidrblock } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_vpc-customvpc name : CustomVPC type : vpc parent : trustZone : public-cloud-01 tags : - aws_vpc dataflows : [] The component identifier is generated internally by the slp_tf .","title":"Mapping a component"},{"location":"startleft-processors/iac/tf/Terraform-how-mapping-file-works/#mapping-an-altsource","text":"$altsource is a special mapping field that specifies an alternative mapping when $source returns nothing. This is the minimal configuration needed to configure an $altsource, the following Example configures an altsource for aws_s3_bucket - type : s3 $source : { $type : \"aws_s3_bucket\" } $altsource : # (1)! - $mappingType : { $type : \"aws_vpc_endpoint\" } # (2)! $mappingPath : { $path : \"*.service_name | [0]\" } # (3)! $mappingLookups : # (4)! - regex : ^(.*)s3$ # (5)! special mapping fields specifies an alternative mapping when $source returns no object special mapping fields set the selected resources as the object to be mapped special mapping fields specifies the attribute over the one the $mappingLookups logic will be executed contains a set of regular expressions to search inside the string defined in $mappingType and $mappingPath. This field may be multiple because there may be more than one service to infer if regex match with the $mappingPath the component is created This configuration maps a s3 by the existence of a resource with resource_type == aws_vpc_endpoint and *.service_name[0] match regex ^(.*)s3$ but it is only executed in case none resource of aws_s3_bucket type exists . AltSource Template Pattern For reducing the minimal amount of data needed for mapping file, a template pattern is used to set the common attributes for the $mappingLookups attribute. $altsource : - $mappingLookups : - name : \"{mapping['type']} from altsource\" # (1)! type : \"{mapping['type']}\" # (2)! tags : # (3)! - { $numberOfSources : # (4)! { oneSource : { $path : \"resource_type\" }, # (5)! multipleSource : { $format : \"{resource_name} ({resource_type})\" }}} # (6)! set the component[name] value by type inheritance with the suffix from atlsource . set the component[type] value by type inheritance. set the component[tags] value returns the value multipleSource in case ( $singleton && exists more than 1 resource), returns oneSource otherwise. returns the resource_type as oneSource attribute returns the \" resource_name (resource_type) \" as multipleSource attribute The values provided in the mapping file are always preferred over the template\u2019s ones. Mapping file Internal Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : s3 $source : { $type : \"aws_s3_bucket\" } $altsource : - $mappingType : { $type : \"aws_vpc_endpoint\" } $mappingPath : { $path : \"*.service_name | [0]\" } $mappingLookups : - regex : ^(.*)s3$ name : S3 from VPCEndpoint dataflows : [] trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : s3 name : { $numberOfSources : { oneSource : { $path : \"resource_name\" }, multipleSource : { $format : \"{type} (grouped)\" }}} $source : { $type : \"aws_s3_bucket\" } $altsource : - $mappingType : { $type : \"aws_vpc_endpoint\" } $mappingPath : { $path : \"*.service_name | [0]\" } $mappingLookups : - regex : ^(.*)s3$ name : S3 from VPCEndpoint type : s3 tags : - { $numberOfSources : { oneSource : { $path : \"resource_type\" }, multipleSource : { $format : \"{resource_name} ({resource_type})\" }}} parent : { $parent : public-cloud-01 } tags : - { $numberOfSources : { oneSource : { $path : \"resource_type\" }, multipleSource : { $format : \"{resource_name} ({resource_type})\" }}} dataflows : [] resource \"aws_vpc_endpoint\" \"s3\" { vpc_id = data.aws_vpc.selected.id service_name = \"com.amazonaws.${var.region}.s3\" vpc_endpoint_type = \"Interface\" private_dns_enabled = true } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_vpc_endpoint-s3-altsource name : S3 from VPCEndpoint type : s3 parent : trustZone : public-cloud-01 tags : - aws_vpc_endpoint dataflows : [] Note that the template component name is override for $mappingLookups[].name on the Mapping File.","title":"Mapping an AltSource"},{"location":"startleft-processors/iac/tf/Terraform-how-mapping-file-works/#mapping-a-parent","text":"The order of the components is important because parent components must be defined before child components. When mapping a component, the default TrustZone is set to the parent component value by the component template pattern, nevertheless, it can be modified to set other TrustZones or Component with the attribute component['parent'] in the mapping file. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : empty-component $source : { $type : \"aws_subnet\" } - type : load-balancer $source : { $type : [ \"aws_lb\" , \"aws_elb\" ]} parent : { $path : \"resource_properties.subnets\" } dataflows : [] resource \"aws_subnet\" \"PrivateSubnet1\" { vpc_id = aws_vpc.CustomVPC.id cidr_block = \"10.0.2.0/24\" } resource \"aws_subnet\" \"PrivateSubnet2\" { vpc_id = aws_vpc.CustomVPC.id cidr_block = \"10.0.3.0/24\" } resource \"aws_lb\" \"ServiceLB\" { subnets = [ aws_subnet.PrivateSubnet1.id , aws_subnet.PrivateSubnet2.id ] } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_subnet-privatesubnet1 name : PrivateSubnet1 type : empty-component parent : trustZone : public-cloud-01 tags : - aws_subnet - id : public-cloud-01.aws_subnet-privatesubnet2 name : PrivateSubnet2 type : empty-component parent : trustZone : public-cloud-01 tags : - aws_subnet - id : >- public-cloud-01.aws_subnet-privatesubnet1.aws_lb-servicelb name : ServiceLB type : load-balancer parent : component : public-cloud-01.aws_subnet-privatesubnet1 tags : - aws_lb - id : >- public-cloud-01.aws_subnet-privatesubnet2.aws_lb-servicelb name : ServiceLB type : load-balancer parent : component : public-cloud-01.aws_subnet-privatesubnet2 tags : - aws_lb dataflows : [] This mapper defines a load-balancer by resources of type aws_lb or aws_elb and sets its parent by its resource_properties.subnets value. This component will be created as many times as subnets exist .","title":"Mapping a Parent"},{"location":"startleft-processors/iac/tf/Terraform-how-mapping-file-works/#mapping-a-children","text":"The order of the components is important because parent components must be defined before child components. When mapping a component, it can define what components are their children on the OTM. $children will set the parent attribute of those components on the OTM. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : elastic-container-service $source : { $type : \"aws_ecs_service\" } parent : { $path : \"resource_properties.network_configuration[0].subnets\" } $children : { $path : \"resource_properties.task_definition|split(@, '.')[1]\" } - type : docker-container $source : { $type : \"aws_ecs_task_definition\" } dataflows : [] resource \"aws_ecs_task_definition\" \"service\" { } resource \"aws_ecs_service\" \"mongo\" { task_definition = aws_ecs_task_definition.service.arn } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.aws_ecs_service-mongo name : mongo type : elastic-container-service parent : trustZone : public-cloud-01 tags : - aws_ecs_service - id : public-cloud-01.aws_ecs_service-mongo.aws_ecs_task_definition-service name : service type : docker-container parent : component : public-cloud-01.aws_ecs_service-mongo tags : - aws_ecs_task_definition dataflows : []","title":"Mapping a Children"},{"location":"startleft-processors/iac/tf/Terraform-how-mapping-file-works/#mapping-a-module","text":"The modules imported in a Terraform file can be mapped into OTM components using the special mapping field $module to match the module[].source value. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : rds $source : { $module : \"terraform-aws-modules/rds/aws\" } - type : vpc $source : { $module : \"terraform-aws-modules/vpc/aws\" } - type : load-balancer $source : { $module : \"terraform-aws-modules/alb/aws\" } dataflows : [] module \"db\" { source = \"terraform-aws-modules/rds/aws\" } module \"vpc\" { source = \"terraform-aws-modules/vpc/aws\" } module \"alb\" { source = \"terraform-aws-modules/alb/aws\" } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 risk : trustRating : 10 components : - id : public-cloud-01.db name : db type : rds parent : trustZone : public-cloud-01 tags : - terraform-aws-modules/rds/aws - id : public-cloud-01.vpc name : vpc type : vpc parent : trustZone : public-cloud-01 tags : - terraform-aws-modules/vpc/aws - id : public-cloud-01.alb name : alb type : load-balancer parent : trustZone : public-cloud-01 tags : - terraform-aws-modules/alb/aws dataflows : []","title":"Mapping a Module"},{"location":"startleft-processors/iac/tf/Terraform-how-mapping-file-works/#how-to-map-dataflows","text":"The Dataflows is a Threat Modelling concept that will never be present as is in the Terraform source file. Thus, the slp_tf relies on the configuration defined in the dataflows section of the Mapping File. dataflows : # (1)! - name : { $format : \"S3 dataflow from {resource_type}\" } # (2)! $source : { $type : \"aws_s3_bucket_logging\" } # (3)! source : { $path : \"resource_properties.bucket\" } # (4)! destination : { $path : \"resource_properties.target_bucket\" } # (5)! tags : # (6)! - $format : \"Dataflow created by {resource_type}-{resource_name}\" dataflows section defines the Dataflows mapping behavior. set dataflow[name] value special mapping fields $source this attribute is used to configure the mapping behavior which will create a dataflow set dataflow[source] value using any attribute available at the $source set dataflow[destination] value using any attribute available at the $source Optional: set component[tag] value The mapping name attribute is optional, resource_name will use as default The creation of some dataflow may depend on the existence of some resources in the original file. To configure this behavior, the $source attribute is used. Mapping file Resource File OTM trustzones : - id : public-cloud-01 name : Public Cloud type : b61d6911-338d-46a8-9f39-8dcd24abfe91 $default : true components : - type : s3 $source : { $type : \"aws_s3_bucket\" } dataflows : - name : { $format : \"S3 dataflow from {resource_type}\" } $source : { $type : \"aws_s3_bucket_logging\" } source : { $path : \"resource_properties.bucket\" } destination : { $path : \"resource_properties.target_bucket\" } tags : - $format : \"Dataflow created by {resource_type}-{resource_name}\" resource \"aws_s3_bucket_logging\" \"logging\" { bucket = aws_s3_bucket.bucket.id target_bucket = aws_s3_bucket.log_bucket.id } resource \"aws_s3_bucket\" \"bucket\" { } resource \"aws_s3_bucket\" \"log_bucket\" { } otmVersion : 0.1.0 project : name : name id : id representations : - name : Terraform id : Terraform type : code trustZones : - id : b61d6911-338d-46a8-9f39-8dcd24abfe91 name : Public Cloud risk : trustRating : 10 components : - id : public-cloud-01.aws_s3_bucket-bucket name : bucket type : s3 parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_s3_bucket - id : public-cloud-01.aws_s3_bucket-log_bucket name : log_bucket type : s3 parent : trustZone : b61d6911-338d-46a8-9f39-8dcd24abfe91 tags : - aws_s3_bucket dataflows : - id : 591089c3-9dc1-42c0-a574-3674f2d9deaf name : S3 dataflow from aws_s3_bucket_logging source : public-cloud-01.aws_s3_bucket-bucket destination : public-cloud-01.aws_s3_bucket-log_bucket tags : - Dataflow created by aws_s3_bucket_logging-logging The dataflow identifier is generated internally by the slp_tf . As Terraform Dataflows may be a complicated concept, refer to the How Dataflow Mapping works section for deeper explanation.","title":"How To Map Dataflows"},{"location":"startleft-processors/iac/tf/Terraform-how-to-create-a-basic-mapping-file/","text":"How to Create a Terraform mapping A source mapping file (or 'mapping file' for short) describes how to find and map components, dataflows, and TrustZones in source file data structures. This mapping file is divided into three sections which correspond to the main sections in an OTM file: trustzones . components . dataflows . To define the mapping behavior, a Domain-Specific Language has been created to abstract the implementation details inside the slp_tf , providing a set of $functions containing the logic around a collection of JMESPath queries that are used. Take a look at the JSONSchema file and the Open Threat Model specification for more details. How to create a Basic Mapping File This section is a Getting Started Guide for a basic mapping file for Terraform. For a more in-deep explanation, there is available a How Mapping File works page and a complete guide about the Domain-Specific language . Minimal mapping file configuration Some boilerplate mapping configuration is included out-of-the-box, take a look to How Mapping File works to more details There is a set of easy-to-use functions that fulfill the most common mapping requirements. Here appear the minimal mapping configuration examples that include these functions with their explanation: trustzones : # (1)! - id : public-cloud-01 # (2)! name : Public Cloud # (3)! type : b61d6911-338d-46a8-9f39-8dcd24abfe91 # (16)! $default : true # (4)! - id : internet-01 name : Internet type : f0ba7722-39b6-4c81-8290-a30a248bb8d9 $source : { $singleton : # (5)! { $type : \"aws_security_group\" , # (6)! $props : \"egress[0].cidr_blocks\" } # (7)! } components : # (8)! - type : ec2 # (9)! $source : # (10)! { $type : \"aws_instance\" } # (11)! - type : generic-client $source : { $type : \"aws_security_group\" , # (12)! $props : \"egress[0].cidr_blocks\" } parent : internet-01 # (13)! tags : # (14)! - Outbound connection destination IP dataflows : [] # (15)! trustzones section defines the TrustZone mapping behavior. At least one TrustZone is needed to be defined set trustzone[id] value, which also can be used as a reference when setting the parent of a component parent: public-cloud . The id field uniquely identifies a trustzone, and differentiates it from other trustzones of the same type. set trustzone[name] value Optional: default trustzone to be used if a component does not define its parent All the matching resources will be unified under a single TrustZone which will be created in case the {$type: \"aws_security_group\", $props: \"egress[0].cidr_blocks\"} query returns any element mapping function $type performs a search along the entire resource list to return the element with the matching type mapping function $props performs a search along the entire resource list to return the element with the matching props components section defines the component mapping behavior set component[type] value special mapping field $source set the selected resources as the object to be mapped mapping function $type performs a search along the entire resource list to return the element with the matching type mapping function performs a query combining $type and $props functions returning a list of $source to be mapped into a component for each existing Terraform resource that matches those conditions Optional: set component[parent] as the Internet TrustZone Optional: set component[tag] value dataflows section is explained in detail on How Dataflow Mapping works set trustzone[type] value. For mapping trustzones to IriusRisk trustzones, type field must take internal IriusRisk values depending on the type of trustzone. Special mapping fields These functions begin with a dollar sign ($) and do not directly contribute to the OTM output. Instead, they specify an action or behavior used to process the source files or generate the OTM output. $functions Description Applies to $default Specifies the TrustZone as default TrustZones $source Specifies the source of the object type Components, TrustZones & Dataflows Here you can find the complete list of special mapping fields . Mapping functions These functions are used as parameters of the mapping attributes for configuring its behavior. $functions Type Description Consumes Produces $type filter Finds a resource by its type A list of resources A resources list filtered by type $props filter Finds a resource by its properties A list of resources A resources list filtered by the given props $singleton group Specific objects to be unified under a single component or TrustZone A list of resources A list of resources grouped by the given params Here you can find the complete list of Mapping functions .","title":"How To Create a Basic Mapping File"},{"location":"startleft-processors/iac/tf/Terraform-how-to-create-a-basic-mapping-file/#how-to-create-a-terraform-mapping","text":"A source mapping file (or 'mapping file' for short) describes how to find and map components, dataflows, and TrustZones in source file data structures. This mapping file is divided into three sections which correspond to the main sections in an OTM file: trustzones . components . dataflows . To define the mapping behavior, a Domain-Specific Language has been created to abstract the implementation details inside the slp_tf , providing a set of $functions containing the logic around a collection of JMESPath queries that are used. Take a look at the JSONSchema file and the Open Threat Model specification for more details.","title":"How to Create a Terraform mapping"},{"location":"startleft-processors/iac/tf/Terraform-how-to-create-a-basic-mapping-file/#how-to-create-a-basic-mapping-file","text":"This section is a Getting Started Guide for a basic mapping file for Terraform. For a more in-deep explanation, there is available a How Mapping File works page and a complete guide about the Domain-Specific language .","title":"How to create a Basic Mapping File"},{"location":"startleft-processors/iac/tf/Terraform-how-to-create-a-basic-mapping-file/#minimal-mapping-file-configuration","text":"Some boilerplate mapping configuration is included out-of-the-box, take a look to How Mapping File works to more details There is a set of easy-to-use functions that fulfill the most common mapping requirements. Here appear the minimal mapping configuration examples that include these functions with their explanation: trustzones : # (1)! - id : public-cloud-01 # (2)! name : Public Cloud # (3)! type : b61d6911-338d-46a8-9f39-8dcd24abfe91 # (16)! $default : true # (4)! - id : internet-01 name : Internet type : f0ba7722-39b6-4c81-8290-a30a248bb8d9 $source : { $singleton : # (5)! { $type : \"aws_security_group\" , # (6)! $props : \"egress[0].cidr_blocks\" } # (7)! } components : # (8)! - type : ec2 # (9)! $source : # (10)! { $type : \"aws_instance\" } # (11)! - type : generic-client $source : { $type : \"aws_security_group\" , # (12)! $props : \"egress[0].cidr_blocks\" } parent : internet-01 # (13)! tags : # (14)! - Outbound connection destination IP dataflows : [] # (15)! trustzones section defines the TrustZone mapping behavior. At least one TrustZone is needed to be defined set trustzone[id] value, which also can be used as a reference when setting the parent of a component parent: public-cloud . The id field uniquely identifies a trustzone, and differentiates it from other trustzones of the same type. set trustzone[name] value Optional: default trustzone to be used if a component does not define its parent All the matching resources will be unified under a single TrustZone which will be created in case the {$type: \"aws_security_group\", $props: \"egress[0].cidr_blocks\"} query returns any element mapping function $type performs a search along the entire resource list to return the element with the matching type mapping function $props performs a search along the entire resource list to return the element with the matching props components section defines the component mapping behavior set component[type] value special mapping field $source set the selected resources as the object to be mapped mapping function $type performs a search along the entire resource list to return the element with the matching type mapping function performs a query combining $type and $props functions returning a list of $source to be mapped into a component for each existing Terraform resource that matches those conditions Optional: set component[parent] as the Internet TrustZone Optional: set component[tag] value dataflows section is explained in detail on How Dataflow Mapping works set trustzone[type] value. For mapping trustzones to IriusRisk trustzones, type field must take internal IriusRisk values depending on the type of trustzone.","title":"Minimal mapping file configuration"},{"location":"startleft-processors/iac/tf/Terraform-how-to-create-a-basic-mapping-file/#special-mapping-fields","text":"These functions begin with a dollar sign ($) and do not directly contribute to the OTM output. Instead, they specify an action or behavior used to process the source files or generate the OTM output. $functions Description Applies to $default Specifies the TrustZone as default TrustZones $source Specifies the source of the object type Components, TrustZones & Dataflows Here you can find the complete list of special mapping fields .","title":"Special mapping fields"},{"location":"startleft-processors/iac/tf/Terraform-how-to-create-a-basic-mapping-file/#mapping-functions","text":"These functions are used as parameters of the mapping attributes for configuring its behavior. $functions Type Description Consumes Produces $type filter Finds a resource by its type A list of resources A resources list filtered by type $props filter Finds a resource by its properties A list of resources A resources list filtered by the given props $singleton group Specific objects to be unified under a single component or TrustZone A list of resources A list of resources grouped by the given params Here you can find the complete list of Mapping functions .","title":"Mapping functions"},{"location":"usage/Command-Line-Interface/","text":"Command Line Interface (CLI) Serverless CLI mode is the original Startleft operation mode where: Startleft runs as a standalone application. Execution is performed via CLI in local machine. Input files are in local machine. Mapping file may be Startleft default or another user-defined may be specified. Command Help For help, just run startleft without arguments: $ startleft Usage: startleft [ OPTIONS ] COMMAND [ ARGS ] ... Parse IaC and other files to the Open Threat Model format Options: -l, --log-level [ CRIT | ERROR | WARN | INFO | DEBUG | NONE ] Set the log level. -v, --verbose / -nv, --no-verbose Makes logging more verbose. --version Show the version and exit. --help Show this message and exit. Commands: parse Parses source files into Open Threat Model search Searches source files for the given query server Launches the REST server to generate OTMs from requests validate Validates a mapping or OTM file You can also get help for specific commands. Example for parse command help $ startleft parse --help Usage: startleft parse [ OPTIONS ] SOURCE_FILE... Parses source files into Open Threat Model Options: -t, --iac-type [ CLOUDFORMATION | TERRAFORM ] The IaC file type. NOTE: This argument is mutually exclusive with arguments: [ custom_mapping_file, etm_type, diagram_type, default_mapping_file ] . -g, --diagram-type [ VISIO | LUCID ] The diagram file type. NOTE: This argument is mutually exclusive with arguments: [ mapping_file, iac_type ] . -e, --etm-type [ MTMT ] The etm file type. NOTE: This argument is mutually exclusive with arguments: [ mapping_file, diagram_type, iac_type ] . -m, --mapping-file TEXT Mapping file to parse the IaC file. NOTE: This argument is mutually exclusive with arguments: [ etm_type, default_mapping_file, diagram_type, custom_mapping_file ] . -d, --default-mapping-file TEXT Default mapping file to parse the diagram file. NOTE: This argument is mutually exclusive with arguments: [ mapping_file, iac_type ] . -c, --custom-mapping-file TEXT Custom mapping file to parse the diagram file. -o, --output-file TEXT OTM output file. -n, --project-name TEXT Project name. [ required ] -i, --project-id TEXT Project id. [ required ] --help Show this message and exit. Command Summary The list of commands that can be used to work in CLI mode is detailed as follows: Command Description parse Parses source files into Open Threat Model. validate Validates a mapping or OTM file. search Searches source files for the given query. server Launches the REST server to generate OTMs from requests. Parse This command is used for parsing source files into the Open Threat Model format. The options that it supports are: -t, --iac-type [ CLOUDFORMATION | TERRAFORM ] The IaC file type. NOTE: This argument is mutually exclusive with arguments: [ custom_mapping_file, default_mapping_file, diagram_type ] . -g, --diagram-type [ VISIO | LUCID ] The diagram file type. NOTE: This argument is mutually exclusive with arguments: [ mapping_file, iac_type ] . -m, --mapping-file TEXT Mapping file to parse the IaC file. NOTE: This argument is mutually exclusive with arguments: [ custom_mapping_file, default_mapping_file, diagram_type ] . -d, --default-mapping-file TEXT Default mapping file to parse the diagram or ETM file. NOTE: This argument is mutually exclusive with arguments: [ mapping_file, iac_type ] . -c, --custom-mapping-file TEXT Custom mapping file to parse the diagram or ETM file. -o, --output-file TEXT OTM output file. -n, --project-name TEXT Project name. [ required ] -i, --project-id TEXT Project id. [ required ] --help Show this message and exit. Notice that the argument with the IaC or diagram file name to parse is not preceded by a parameter CLI execution Output File startleft parse \\ --iac-type TERRAFORM \\ --mapping-file iriusrisk-tf-aws-mapping.yaml \\ --output-file multinetwork_security_groups_with_lb.otm \\ --project-name \"Terraform MN Security Groups with LB\" \\ --project-id \"tf-mn-sg-lb\" \\ multinetwork_security_groups_with_lb.tf Parsing source files into OTM Parsing IaC source files into OTM Validating Terraform file Mapping file size is valid Loading schema file 'iac_tf_mapping_schema.json' Mapping files are valid Mapping files are valid Mapping file size is valid Loading mapping data Adding trustzones Added 2 trustzones successfully Adding components Added 22 components successfully Adding dataflows Added 22 dataflows successfully Loading schema file 'otm_schema.json' OTM file schema is valid OTM file has consistent IDs OTM file validated successfully Writing OTM file to 'multinetwork_security_groups_with_lb.otm' { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"Terraform MN Security Groups with LB\" , \"id\" : \"tf-mn-sg-lb\" }, \"representations\" : [ { \"name\" : \"Terraform\" , \"id\" : \"Terraform\" , \"type\" : \"code\" } ], \"trustZones\" : [ { \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"name\" : \"Public Cloud\" , \"risk\" : { \"trustRating\" : 10 } }, { \"id\" : \"f0ba7722-39b6-4c81-8290-a30a248bb8d9\" , \"name\" : \"Internet\" , \"risk\" : { \"trustRating\" : 10 } } ], \"components\" : [ { \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_vpc-customvpc\" , \"name\" : \"CustomVPC\" , \"type\" : \"vpc\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"tags\" : [ \"aws_vpc\" ] }, { \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_vpc-customvpc.aws_subnet-privatesubnet1\" , \"name\" : \"PrivateSubnet1\" , \"type\" : \"empty-component\" , \"parent\" : { \"component\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_vpc-customvpc\" }, \"tags\" : [ \"aws_subnet\" ] } [ ... ] Reduced f or simplici t y You can also parse more than one IaC file as in this other example: CLI execution Output File startleft parse \\ --iac-type CLOUDFORMATION \\ --project-name \"cft_multiple_files_project\" \\ --project-id cft_multiple_files_project_id \\ --mapping-file iriusrisk-cft-mapping.yaml \\ networks_cft_file.json \\ resources_cft_file.json Parsing source files into OTM Parsing IaC source files into OTM Validating CloudFormation file Mapping file size is valid Loading schema file 'iac_cft_mapping_schema.json' Mapping files are valid Mapping files are valid Mapping file size is valid Loading mapping data Adding trustzones Added 2 trustzones successfully Adding components Added 22 components successfully Adding dataflows Added 22 dataflows successfully Loading schema file 'otm_schema.json' OTM file schema is valid OTM file has consistent IDs OTM file validated successfully Writing OTM file to 'threatmodel.otm' { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"cft_multiple_files_project\" , \"id\" : \"cft_multiple_files_project_id\" }, \"representations\" : [ { \"name\" : \"CloudFormation\" , \"id\" : \"CloudFormation\" , \"type\" : \"code\" } ], \"trustZones\" : [ { \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"name\" : \"Public Cloud\" , \"risk\" : { \"trustRating\" : 10 } }, { \"id\" : \"f0ba7722-39b6-4c81-8290-a30a248bb8d9\" , \"name\" : \"Internet\" , \"risk\" : { \"trustRating\" : 10 } } ], \"components\" : [ { \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\" , \"name\" : \"CustomVPC\" , \"type\" : \"vpc\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"tags\" : [ \"AWS::EC2::VPC\" ] }, { \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1\" , \"name\" : \"PrivateSubnet1\" , \"type\" : \"empty-component\" , \"parent\" : { \"component\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\" }, \"tags\" : [ \"AWS::EC2::Subnet\" ] }, [ ... ] Reduced f or simplici t y There are different combinations that we can use, but we have to take into account the above required arguments. An example of a diagram parse is shown below. CLI execution Output File startleft parse \\ --diagram-type VISIO \\ --default-mapping-file iriusrisk-visio-aws-mapping.yaml \\ --output-file visio-basic-example.otm \\ --project-name \"VISIO Basic Example\" \\ --project-id \"vs-bs-ex\" \\ visio-basic-example.vsdx Parsing source files into OTM Parsing diagram source files into OTM Validating visio file Mapping file size is valid Loading schema file 'diagram_mapping_schema.json' Mapping files are valid Mapping files are valid Mapping file size is valid Loading mapping data Loading schema file 'otm_schema.json' OTM file schema is valid OTM file has consistent IDs OTM file validated successfully Writing OTM file to 'visio-basic-example.otm' { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"VISIO Basic Example\" , \"id\" : \"vs-bs-ex\" }, \"representations\" : [ { \"name\" : \"Visio\" , \"id\" : \"Visio\" , \"type\" : \"diagram\" , \"size\" : { \"width\" : 1000 , \"height\" : 1000 } } ], \"trustZones\" : [ { \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"name\" : \"Public Cloud\" , \"risk\" : { \"trustRating\" : 10 } }, { \"id\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" , \"name\" : \"Private Secured\" , \"risk\" : { \"trustRating\" : 10 } } ], \"components\" : [ { \"id\" : \"12\" , \"name\" : \"My EC2\" , \"type\" : \"ec2\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\" : \"30\" , \"name\" : \"Private Database\" , \"type\" : \"rds\" , \"parent\" : { \"trustZone\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" } } ], \"dataflows\" : [ { \"id\" : \"34\" , \"name\" : \"998dcc87-ab45-4ac5-9e6a-62d08ce73a20\" , \"source\" : \"12\" , \"destination\" : \"30\" } ] } Differences between parsing Diagram and IaC files We have seen that there are some differences when parsing diagram and IaC files. Here we will detail what they are and how to proceed. Option Description Diagram IaC Example None The IaC / diagram file to parse. Required Required multinetwork_security_groups_with_lb.tf -t, --iac-type The IaC file type. - Required TERRAFORM -g, --diagram-type The diagram file type. Required - VISIO -m, --mapping-file Mapping file to parse the IaC file. - Required iriusrisk-tf-aws-mapping.yaml -d, --default-mapping-file Default mapping file to parse the diagram file. Required - iriusrisk-visio-aws-mapping.yaml -c, --custom-mapping-file Custom mapping file to parse the diagram file. Optional - custom-visio-aws-mapping.yaml -o, --output-file OTM output file. Optional Optional visio-basic-example.otm -n, --project-name Project name. Required Required \"VISIO Basic Example\" -i, --project-id Project id. Required Required \"vs-bs-ex\" If we want to parse an IaC file, we should specify: The IaC file we want to parse. The IaC type. The mapping file we want to use to parse the IaC file. The project name. The project id. Optionally the name of the OTM output file. Correct example for IaC startleft parse \\ --iac-type TERRAFORM \\ --mapping-file iriusrisk-tf-aws-mapping.yaml \\ --output-file elb.otm \\ --project-name \"Terraform ELB example\" \\ --project-id \"tf-elb-ex\" \\ elb.tf Incorrect example for IaC startleft parse \\ --iac-type TERRAFORM \\ --default-mapping-file iriusrisk-tf-aws-mapping.yaml \\ --project-name \"Terraform ELB example\" \\ --project-id \"tf-elb-ex\" \\ elb.tf The --mapping-file option is missed and the diagram --default-mapping-file option is added to parse an IaC file. On the other hand, if we want to parse a diagram file, we should specify the following options: The diagram file we want to parse. The diagram's type. The default mapping file we want to use to parse the diagram file. Optionally, the custom mapping file that we have created to parse the diagram file. The project's name. The project id. Optionally the name of the OTM output file. Correct example for diagram startleft parse \\ --diagram-type VISIO \\ --default-mapping-file iriusrisk-visio-aws-mapping.yaml \\ --output-file aws-with-tz-and-vpc.otm \\ --project-name \"Aws with tz and vpt\" \\ --project-id \"vs-aws-tz-vpc\" \\ aws-with-tz-and-vpc.vsdx Incorrect example for diagram startleft parse \\ --diagram-type VISIO \\ --custom-mapping-file iriusrisk-visio-aws-mapping.yaml \\ --project-name \"Aws with tz and vpt\" \\ --project-id \"vs-aws-tz-vpc\" \\ aws-with-tz-and-vpc.vsdx The --default-mapping-file option is missed. Validate Validation is a CLI-specific feature and is used to validate both OTM and mapping files. The full set of options are: Usage: startleft validate [ OPTIONS ] Validates a mapping or OTM file Options: -m, --mapping-file TEXT Mapping file to validate. NOTE: This argument is mutually exclusive with arguments: [ otm_file ] . [ required ] -t, --mapping-type [ CLOUDFORMATION | TERRAFORM | VISIO | MTMT | LUCID ] Mapping file type to validate. NOTE: This argument is mutually exclusive with arguments: [ otm_file ] . [ required ] -o, --otm-file TEXT OTM input file. NOTE: This argument is mutually exclusive with arguments: [ mapping_file ] . [ required ] --help Show this message and exit. Validating Mapping files and OTM files If we want to validate a mapping file, we should indicate its type. So if we use the --mapping-file option with the file we want to check, we should use the mandatory --mapping-type parameter which indicates the specific type of the given mapping file. On the other hand, if we want to validate an otm file, we should use the --otm-file option without --mapping-type . Both --mapping-file and --otm-file are mutually exclusive. We can use this command only to validate one file at once OTM validation is a special feature of StartLeft, as it does not apply to any format and instead allows users to validate OTM files generated in any way, including manually. CLI execution Output OTM file startleft validate \\ --otm-file threatmodel.otm Validating OTM file Loading schema file '/otm/resources/schemas/otm_schema.json' OTM file schema is valid OTM file has consistent IDs OTM file validated successfully otmVersion : 0.1.0 project : name : Manual ThreatModel id : manual-threatmodel trustZones : - id : f0ba7722-39b6-4c81-8290-a30a248bb8d9 name : Internet risk : trustRating : 1 - id : 6376d53e-6461-412b-8e04-7b3fe2b397de name : Public risk : trustRating : 1 - id : 2ab4effa-40b7-4cd2-ba81-8247d29a6f2d name : Private Secured risk : trustRating : 100 components : - id : user name : User type : generic-client parent : trustZone : f0ba7722-39b6-4c81-8290-a30a248bb8d9 - id : web-server name : Web server type : web-application-server-side parent : trustZone : 6376d53e-6461-412b-8e04-7b3fe2b397de - id : database name : Database type : postgresql parent : trustZone : 2ab4effa-40b7-4cd2-ba81-8247d29a6f2d dataflows : - id : client-connection name : Client connection source : user destination : web-server - id : database-connection name : Database connection source : web-server destination : database An example with a mapping file: CLI execution Output startleft validate \\ --mapping-file iriusrisk-visio-aws-mapping.yaml \\ --mapping-type VISIO Validating: VISIO mapping files Loading schema file '/slp_visio/resources/schemas/diagram_mapping_schema.json' Mapping file size is valid Mapping files are valid Search This command runs a JMESPath search query against the provided source file and outputs the matching results. It is only available for IaC source files and the full set of options are: -t, --iac-type [ CLOUDFORMATION | TERRAFORM ] The IaC file type. [ required ] -q, --query TEXT JMESPath query to run against the IaC file. --help Show this message and exit. Notice that the argument with the IaC file name is not preceded by a parameter Terraform example CLI execution Output File startleft search \\ --iac-type TERRAFORM \\ --query \"resource|[?resource_type=='aws_vpc']\" \\ multinetwork_security_groups_with_lb.tf [ ... ] Reduced for simplicity --- Results --- [ { \"aws_vpc\" : { \"CustomVPC\" : { \"cidr_block\" : \" ${ var .vpcCidrblock } \" } } , \"resource_type\" : \"aws_vpc\" , \"resource_name\" : \"CustomVPC\" , \"resource_properties\" : { \"cidr_block\" : \" ${ var .vpcCidrblock } \" } , \"Type\" : \"aws_vpc\" , \"_key\" : \"CustomVPC\" , \"Properties\" : { \"cidr_block\" : \" ${ var .vpcCidrblock } \" } } ] variable \"vpcCidrblock\" { type = list default = [ \"10.0.0.0/16\" ] } variable \"ingressCidrblock\" { type = list default = [ \"0.0.0.0/0\" ] } resource \"aws_vpc\" \"CustomVPC\" { cidr_block = var.vpcCidrblock } resource \"aws_subnet\" \"PrivateSubnet1\" { vpc_id = aws_vpc.CustomVPC.id cidr_block = \"10.0.2.0/24\" } resource \"aws_subnet\" \"PrivateSubnet2\" { vpc_id = aws_vpc.CustomVPC.id cidr_block = \"10.0.3.0/24\" } [...] Reduced for simplicity Cluodformation example CLI execution Output File startleft search \\ --iac-type CLOUDFORMATION \\ --query \"Resources|squash(@)[?Type=='AWS::ElasticLoadBalancingV2::LoadBalancer']\" \\ multinetwork_security_groups_with_lb.json [ ... ] Reduced for simplicity --- Results --- [ { \"Type\" : \"AWS::ElasticLoadBalancingV2::LoadBalancer\" , \"Properties\" : { \"LoadBalancerAttributes\" : [ { \"Key\" : \"deletion_protection.enabled\" , \"Value\" : \"false\" } ] , \"Scheme\" : \"internal\" , \"SecurityGroups\" : [ { \"Fn::GetAtt\" : [ \"ServiceLBSecurityGroup\" , \"GroupId\" ] } ] , \"Subnets\" : [ { \"Fn::ImportValue\" : \"ECSFargateGoVPCStack:ExportsOutputRefVPCPrivateSubnet1SubnetXYZ\" } , { \"Fn::ImportValue\" : \"ECSFargateGoVPCStack:ExportsOutputRefVPCPrivateSubnet2SubnetABC\" } ] , \"Type\" : \"application\" } , \"_key\" : \"ServiceLB\" } ] [ ... ] Reduced f or simplici t y \"ServiceLB\" : { \"Type\" : \"AWS::ElasticLoadBalancingV2::LoadBalancer\" , \"Properties\" : { \"LoadBalancerAttributes\" : [ { \"Key\" : \"deletion_protection.enabled\" , \"Value\" : \"false\" } ], \"Scheme\" : \"internal\" , \"SecurityGroups\" : [ { \"Fn::GetAtt\" : [ \"ServiceLBSecurityGroup\" , \"GroupId\" ] } ], \"Subnets\" : [ { \"Fn::ImportValue\" : \"ECSFargateGoVPCStack:ExportsOutputRefVPCPrivateSubnet1SubnetXYZ\" }, { \"Fn::ImportValue\" : \"ECSFargateGoVPCStack:ExportsOutputRefVPCPrivateSubnet2SubnetABC\" } ], \"Type\" : \"application\" } }, Server This is the latest Startleft operation mode where it runs as a server with its own REST API endpoints that receive one or more IaC files, process them and give back the OTM file in the response. The available options are: -p, --port INTEGER Startleft deployment port. --help Show this message and exit. CLI execution Output startleft server \\ --port 5000 INFO cli - Startleft version: 1 .10.0 INFO server - Started server process [] INFO on - Waiting for application startup. INFO on - Application startup complete. INFO server - Uvicorn running on http://127.0.0.1:5000 ( Press CTRL+C to quit )","title":"Command Line Interface (CLI)"},{"location":"usage/Command-Line-Interface/#command-line-interface-cli","text":"Serverless CLI mode is the original Startleft operation mode where: Startleft runs as a standalone application. Execution is performed via CLI in local machine. Input files are in local machine. Mapping file may be Startleft default or another user-defined may be specified.","title":"Command Line Interface (CLI)"},{"location":"usage/Command-Line-Interface/#command-help","text":"For help, just run startleft without arguments: $ startleft Usage: startleft [ OPTIONS ] COMMAND [ ARGS ] ... Parse IaC and other files to the Open Threat Model format Options: -l, --log-level [ CRIT | ERROR | WARN | INFO | DEBUG | NONE ] Set the log level. -v, --verbose / -nv, --no-verbose Makes logging more verbose. --version Show the version and exit. --help Show this message and exit. Commands: parse Parses source files into Open Threat Model search Searches source files for the given query server Launches the REST server to generate OTMs from requests validate Validates a mapping or OTM file You can also get help for specific commands. Example for parse command help $ startleft parse --help Usage: startleft parse [ OPTIONS ] SOURCE_FILE... Parses source files into Open Threat Model Options: -t, --iac-type [ CLOUDFORMATION | TERRAFORM ] The IaC file type. NOTE: This argument is mutually exclusive with arguments: [ custom_mapping_file, etm_type, diagram_type, default_mapping_file ] . -g, --diagram-type [ VISIO | LUCID ] The diagram file type. NOTE: This argument is mutually exclusive with arguments: [ mapping_file, iac_type ] . -e, --etm-type [ MTMT ] The etm file type. NOTE: This argument is mutually exclusive with arguments: [ mapping_file, diagram_type, iac_type ] . -m, --mapping-file TEXT Mapping file to parse the IaC file. NOTE: This argument is mutually exclusive with arguments: [ etm_type, default_mapping_file, diagram_type, custom_mapping_file ] . -d, --default-mapping-file TEXT Default mapping file to parse the diagram file. NOTE: This argument is mutually exclusive with arguments: [ mapping_file, iac_type ] . -c, --custom-mapping-file TEXT Custom mapping file to parse the diagram file. -o, --output-file TEXT OTM output file. -n, --project-name TEXT Project name. [ required ] -i, --project-id TEXT Project id. [ required ] --help Show this message and exit.","title":"Command Help"},{"location":"usage/Command-Line-Interface/#command-summary","text":"The list of commands that can be used to work in CLI mode is detailed as follows: Command Description parse Parses source files into Open Threat Model. validate Validates a mapping or OTM file. search Searches source files for the given query. server Launches the REST server to generate OTMs from requests.","title":"Command Summary"},{"location":"usage/Command-Line-Interface/#parse","text":"This command is used for parsing source files into the Open Threat Model format. The options that it supports are: -t, --iac-type [ CLOUDFORMATION | TERRAFORM ] The IaC file type. NOTE: This argument is mutually exclusive with arguments: [ custom_mapping_file, default_mapping_file, diagram_type ] . -g, --diagram-type [ VISIO | LUCID ] The diagram file type. NOTE: This argument is mutually exclusive with arguments: [ mapping_file, iac_type ] . -m, --mapping-file TEXT Mapping file to parse the IaC file. NOTE: This argument is mutually exclusive with arguments: [ custom_mapping_file, default_mapping_file, diagram_type ] . -d, --default-mapping-file TEXT Default mapping file to parse the diagram or ETM file. NOTE: This argument is mutually exclusive with arguments: [ mapping_file, iac_type ] . -c, --custom-mapping-file TEXT Custom mapping file to parse the diagram or ETM file. -o, --output-file TEXT OTM output file. -n, --project-name TEXT Project name. [ required ] -i, --project-id TEXT Project id. [ required ] --help Show this message and exit. Notice that the argument with the IaC or diagram file name to parse is not preceded by a parameter CLI execution Output File startleft parse \\ --iac-type TERRAFORM \\ --mapping-file iriusrisk-tf-aws-mapping.yaml \\ --output-file multinetwork_security_groups_with_lb.otm \\ --project-name \"Terraform MN Security Groups with LB\" \\ --project-id \"tf-mn-sg-lb\" \\ multinetwork_security_groups_with_lb.tf Parsing source files into OTM Parsing IaC source files into OTM Validating Terraform file Mapping file size is valid Loading schema file 'iac_tf_mapping_schema.json' Mapping files are valid Mapping files are valid Mapping file size is valid Loading mapping data Adding trustzones Added 2 trustzones successfully Adding components Added 22 components successfully Adding dataflows Added 22 dataflows successfully Loading schema file 'otm_schema.json' OTM file schema is valid OTM file has consistent IDs OTM file validated successfully Writing OTM file to 'multinetwork_security_groups_with_lb.otm' { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"Terraform MN Security Groups with LB\" , \"id\" : \"tf-mn-sg-lb\" }, \"representations\" : [ { \"name\" : \"Terraform\" , \"id\" : \"Terraform\" , \"type\" : \"code\" } ], \"trustZones\" : [ { \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"name\" : \"Public Cloud\" , \"risk\" : { \"trustRating\" : 10 } }, { \"id\" : \"f0ba7722-39b6-4c81-8290-a30a248bb8d9\" , \"name\" : \"Internet\" , \"risk\" : { \"trustRating\" : 10 } } ], \"components\" : [ { \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_vpc-customvpc\" , \"name\" : \"CustomVPC\" , \"type\" : \"vpc\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"tags\" : [ \"aws_vpc\" ] }, { \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_vpc-customvpc.aws_subnet-privatesubnet1\" , \"name\" : \"PrivateSubnet1\" , \"type\" : \"empty-component\" , \"parent\" : { \"component\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91.aws_vpc-customvpc\" }, \"tags\" : [ \"aws_subnet\" ] } [ ... ] Reduced f or simplici t y You can also parse more than one IaC file as in this other example: CLI execution Output File startleft parse \\ --iac-type CLOUDFORMATION \\ --project-name \"cft_multiple_files_project\" \\ --project-id cft_multiple_files_project_id \\ --mapping-file iriusrisk-cft-mapping.yaml \\ networks_cft_file.json \\ resources_cft_file.json Parsing source files into OTM Parsing IaC source files into OTM Validating CloudFormation file Mapping file size is valid Loading schema file 'iac_cft_mapping_schema.json' Mapping files are valid Mapping files are valid Mapping file size is valid Loading mapping data Adding trustzones Added 2 trustzones successfully Adding components Added 22 components successfully Adding dataflows Added 22 dataflows successfully Loading schema file 'otm_schema.json' OTM file schema is valid OTM file has consistent IDs OTM file validated successfully Writing OTM file to 'threatmodel.otm' { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"cft_multiple_files_project\" , \"id\" : \"cft_multiple_files_project_id\" }, \"representations\" : [ { \"name\" : \"CloudFormation\" , \"id\" : \"CloudFormation\" , \"type\" : \"code\" } ], \"trustZones\" : [ { \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"name\" : \"Public Cloud\" , \"risk\" : { \"trustRating\" : 10 } }, { \"id\" : \"f0ba7722-39b6-4c81-8290-a30a248bb8d9\" , \"name\" : \"Internet\" , \"risk\" : { \"trustRating\" : 10 } } ], \"components\" : [ { \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\" , \"name\" : \"CustomVPC\" , \"type\" : \"vpc\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" }, \"tags\" : [ \"AWS::EC2::VPC\" ] }, { \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc.privatesubnet1\" , \"name\" : \"PrivateSubnet1\" , \"type\" : \"empty-component\" , \"parent\" : { \"component\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91.customvpc\" }, \"tags\" : [ \"AWS::EC2::Subnet\" ] }, [ ... ] Reduced f or simplici t y There are different combinations that we can use, but we have to take into account the above required arguments. An example of a diagram parse is shown below. CLI execution Output File startleft parse \\ --diagram-type VISIO \\ --default-mapping-file iriusrisk-visio-aws-mapping.yaml \\ --output-file visio-basic-example.otm \\ --project-name \"VISIO Basic Example\" \\ --project-id \"vs-bs-ex\" \\ visio-basic-example.vsdx Parsing source files into OTM Parsing diagram source files into OTM Validating visio file Mapping file size is valid Loading schema file 'diagram_mapping_schema.json' Mapping files are valid Mapping files are valid Mapping file size is valid Loading mapping data Loading schema file 'otm_schema.json' OTM file schema is valid OTM file has consistent IDs OTM file validated successfully Writing OTM file to 'visio-basic-example.otm' { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"VISIO Basic Example\" , \"id\" : \"vs-bs-ex\" }, \"representations\" : [ { \"name\" : \"Visio\" , \"id\" : \"Visio\" , \"type\" : \"diagram\" , \"size\" : { \"width\" : 1000 , \"height\" : 1000 } } ], \"trustZones\" : [ { \"id\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" , \"name\" : \"Public Cloud\" , \"risk\" : { \"trustRating\" : 10 } }, { \"id\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" , \"name\" : \"Private Secured\" , \"risk\" : { \"trustRating\" : 10 } } ], \"components\" : [ { \"id\" : \"12\" , \"name\" : \"My EC2\" , \"type\" : \"ec2\" , \"parent\" : { \"trustZone\" : \"b61d6911-338d-46a8-9f39-8dcd24abfe91\" } }, { \"id\" : \"30\" , \"name\" : \"Private Database\" , \"type\" : \"rds\" , \"parent\" : { \"trustZone\" : \"2ab4effa-40b7-4cd2-ba81-8247d29a6f2d\" } } ], \"dataflows\" : [ { \"id\" : \"34\" , \"name\" : \"998dcc87-ab45-4ac5-9e6a-62d08ce73a20\" , \"source\" : \"12\" , \"destination\" : \"30\" } ] }","title":"Parse"},{"location":"usage/Command-Line-Interface/#differences-between-parsing-diagram-and-iac-files","text":"We have seen that there are some differences when parsing diagram and IaC files. Here we will detail what they are and how to proceed. Option Description Diagram IaC Example None The IaC / diagram file to parse. Required Required multinetwork_security_groups_with_lb.tf -t, --iac-type The IaC file type. - Required TERRAFORM -g, --diagram-type The diagram file type. Required - VISIO -m, --mapping-file Mapping file to parse the IaC file. - Required iriusrisk-tf-aws-mapping.yaml -d, --default-mapping-file Default mapping file to parse the diagram file. Required - iriusrisk-visio-aws-mapping.yaml -c, --custom-mapping-file Custom mapping file to parse the diagram file. Optional - custom-visio-aws-mapping.yaml -o, --output-file OTM output file. Optional Optional visio-basic-example.otm -n, --project-name Project name. Required Required \"VISIO Basic Example\" -i, --project-id Project id. Required Required \"vs-bs-ex\" If we want to parse an IaC file, we should specify: The IaC file we want to parse. The IaC type. The mapping file we want to use to parse the IaC file. The project name. The project id. Optionally the name of the OTM output file. Correct example for IaC startleft parse \\ --iac-type TERRAFORM \\ --mapping-file iriusrisk-tf-aws-mapping.yaml \\ --output-file elb.otm \\ --project-name \"Terraform ELB example\" \\ --project-id \"tf-elb-ex\" \\ elb.tf Incorrect example for IaC startleft parse \\ --iac-type TERRAFORM \\ --default-mapping-file iriusrisk-tf-aws-mapping.yaml \\ --project-name \"Terraform ELB example\" \\ --project-id \"tf-elb-ex\" \\ elb.tf The --mapping-file option is missed and the diagram --default-mapping-file option is added to parse an IaC file. On the other hand, if we want to parse a diagram file, we should specify the following options: The diagram file we want to parse. The diagram's type. The default mapping file we want to use to parse the diagram file. Optionally, the custom mapping file that we have created to parse the diagram file. The project's name. The project id. Optionally the name of the OTM output file. Correct example for diagram startleft parse \\ --diagram-type VISIO \\ --default-mapping-file iriusrisk-visio-aws-mapping.yaml \\ --output-file aws-with-tz-and-vpc.otm \\ --project-name \"Aws with tz and vpt\" \\ --project-id \"vs-aws-tz-vpc\" \\ aws-with-tz-and-vpc.vsdx Incorrect example for diagram startleft parse \\ --diagram-type VISIO \\ --custom-mapping-file iriusrisk-visio-aws-mapping.yaml \\ --project-name \"Aws with tz and vpt\" \\ --project-id \"vs-aws-tz-vpc\" \\ aws-with-tz-and-vpc.vsdx The --default-mapping-file option is missed.","title":"Differences between parsing Diagram and IaC files"},{"location":"usage/Command-Line-Interface/#validate","text":"Validation is a CLI-specific feature and is used to validate both OTM and mapping files. The full set of options are: Usage: startleft validate [ OPTIONS ] Validates a mapping or OTM file Options: -m, --mapping-file TEXT Mapping file to validate. NOTE: This argument is mutually exclusive with arguments: [ otm_file ] . [ required ] -t, --mapping-type [ CLOUDFORMATION | TERRAFORM | VISIO | MTMT | LUCID ] Mapping file type to validate. NOTE: This argument is mutually exclusive with arguments: [ otm_file ] . [ required ] -o, --otm-file TEXT OTM input file. NOTE: This argument is mutually exclusive with arguments: [ mapping_file ] . [ required ] --help Show this message and exit. Validating Mapping files and OTM files If we want to validate a mapping file, we should indicate its type. So if we use the --mapping-file option with the file we want to check, we should use the mandatory --mapping-type parameter which indicates the specific type of the given mapping file. On the other hand, if we want to validate an otm file, we should use the --otm-file option without --mapping-type . Both --mapping-file and --otm-file are mutually exclusive. We can use this command only to validate one file at once OTM validation is a special feature of StartLeft, as it does not apply to any format and instead allows users to validate OTM files generated in any way, including manually. CLI execution Output OTM file startleft validate \\ --otm-file threatmodel.otm Validating OTM file Loading schema file '/otm/resources/schemas/otm_schema.json' OTM file schema is valid OTM file has consistent IDs OTM file validated successfully otmVersion : 0.1.0 project : name : Manual ThreatModel id : manual-threatmodel trustZones : - id : f0ba7722-39b6-4c81-8290-a30a248bb8d9 name : Internet risk : trustRating : 1 - id : 6376d53e-6461-412b-8e04-7b3fe2b397de name : Public risk : trustRating : 1 - id : 2ab4effa-40b7-4cd2-ba81-8247d29a6f2d name : Private Secured risk : trustRating : 100 components : - id : user name : User type : generic-client parent : trustZone : f0ba7722-39b6-4c81-8290-a30a248bb8d9 - id : web-server name : Web server type : web-application-server-side parent : trustZone : 6376d53e-6461-412b-8e04-7b3fe2b397de - id : database name : Database type : postgresql parent : trustZone : 2ab4effa-40b7-4cd2-ba81-8247d29a6f2d dataflows : - id : client-connection name : Client connection source : user destination : web-server - id : database-connection name : Database connection source : web-server destination : database An example with a mapping file: CLI execution Output startleft validate \\ --mapping-file iriusrisk-visio-aws-mapping.yaml \\ --mapping-type VISIO Validating: VISIO mapping files Loading schema file '/slp_visio/resources/schemas/diagram_mapping_schema.json' Mapping file size is valid Mapping files are valid","title":"Validate"},{"location":"usage/Command-Line-Interface/#search","text":"This command runs a JMESPath search query against the provided source file and outputs the matching results. It is only available for IaC source files and the full set of options are: -t, --iac-type [ CLOUDFORMATION | TERRAFORM ] The IaC file type. [ required ] -q, --query TEXT JMESPath query to run against the IaC file. --help Show this message and exit. Notice that the argument with the IaC file name is not preceded by a parameter Terraform example CLI execution Output File startleft search \\ --iac-type TERRAFORM \\ --query \"resource|[?resource_type=='aws_vpc']\" \\ multinetwork_security_groups_with_lb.tf [ ... ] Reduced for simplicity --- Results --- [ { \"aws_vpc\" : { \"CustomVPC\" : { \"cidr_block\" : \" ${ var .vpcCidrblock } \" } } , \"resource_type\" : \"aws_vpc\" , \"resource_name\" : \"CustomVPC\" , \"resource_properties\" : { \"cidr_block\" : \" ${ var .vpcCidrblock } \" } , \"Type\" : \"aws_vpc\" , \"_key\" : \"CustomVPC\" , \"Properties\" : { \"cidr_block\" : \" ${ var .vpcCidrblock } \" } } ] variable \"vpcCidrblock\" { type = list default = [ \"10.0.0.0/16\" ] } variable \"ingressCidrblock\" { type = list default = [ \"0.0.0.0/0\" ] } resource \"aws_vpc\" \"CustomVPC\" { cidr_block = var.vpcCidrblock } resource \"aws_subnet\" \"PrivateSubnet1\" { vpc_id = aws_vpc.CustomVPC.id cidr_block = \"10.0.2.0/24\" } resource \"aws_subnet\" \"PrivateSubnet2\" { vpc_id = aws_vpc.CustomVPC.id cidr_block = \"10.0.3.0/24\" } [...] Reduced for simplicity Cluodformation example CLI execution Output File startleft search \\ --iac-type CLOUDFORMATION \\ --query \"Resources|squash(@)[?Type=='AWS::ElasticLoadBalancingV2::LoadBalancer']\" \\ multinetwork_security_groups_with_lb.json [ ... ] Reduced for simplicity --- Results --- [ { \"Type\" : \"AWS::ElasticLoadBalancingV2::LoadBalancer\" , \"Properties\" : { \"LoadBalancerAttributes\" : [ { \"Key\" : \"deletion_protection.enabled\" , \"Value\" : \"false\" } ] , \"Scheme\" : \"internal\" , \"SecurityGroups\" : [ { \"Fn::GetAtt\" : [ \"ServiceLBSecurityGroup\" , \"GroupId\" ] } ] , \"Subnets\" : [ { \"Fn::ImportValue\" : \"ECSFargateGoVPCStack:ExportsOutputRefVPCPrivateSubnet1SubnetXYZ\" } , { \"Fn::ImportValue\" : \"ECSFargateGoVPCStack:ExportsOutputRefVPCPrivateSubnet2SubnetABC\" } ] , \"Type\" : \"application\" } , \"_key\" : \"ServiceLB\" } ] [ ... ] Reduced f or simplici t y \"ServiceLB\" : { \"Type\" : \"AWS::ElasticLoadBalancingV2::LoadBalancer\" , \"Properties\" : { \"LoadBalancerAttributes\" : [ { \"Key\" : \"deletion_protection.enabled\" , \"Value\" : \"false\" } ], \"Scheme\" : \"internal\" , \"SecurityGroups\" : [ { \"Fn::GetAtt\" : [ \"ServiceLBSecurityGroup\" , \"GroupId\" ] } ], \"Subnets\" : [ { \"Fn::ImportValue\" : \"ECSFargateGoVPCStack:ExportsOutputRefVPCPrivateSubnet1SubnetXYZ\" }, { \"Fn::ImportValue\" : \"ECSFargateGoVPCStack:ExportsOutputRefVPCPrivateSubnet2SubnetABC\" } ], \"Type\" : \"application\" } },","title":"Search"},{"location":"usage/Command-Line-Interface/#server","text":"This is the latest Startleft operation mode where it runs as a server with its own REST API endpoints that receive one or more IaC files, process them and give back the OTM file in the response. The available options are: -p, --port INTEGER Startleft deployment port. --help Show this message and exit. CLI execution Output startleft server \\ --port 5000 INFO cli - Startleft version: 1 .10.0 INFO server - Started server process [] INFO on - Waiting for application startup. INFO on - Application startup complete. INFO server - Uvicorn running on http://127.0.0.1:5000 ( Press CTRL+C to quit )","title":"Server"},{"location":"usage/REST-API/","text":"REST API Usage StartLeft can also be deployed as a standalone REST server if you prefer to communicate via API. In this operation mode, StartLeft returns the OTM file in the HTTP response. You can launch the application as a server with the following command: startleft server The --help option provides more details about the usage: startleft server --help Usage: startleft server [ OPTIONS ] ... Launches the REST server to generate OTMs from requests Options: -p, --port INTEGER StartLeft deployment port. --help Show this message and exit. If not specified, port 5000 will be used by default. You can see and try the endpoints provided by opening the following URL in a web browser: http://localhost:5000/docs Note When executing startleft server the following command-line message indicates that StartLeft's REST API is ready: Uvicorn running on http://127.0.0.1:5000 (Press CTRL+C to quit) Additional options You can also set general StartLeft options when using the API mode. More information on the Command Line Interface page or with the command startleft --help server . For example, to launch the server with a log level of DEBUG for testing purposes you can use the following command: startleft --log-level DEBUG server Endpoints This section describes all the available endpoints, their parameters, and example requests and responses. Example files Refer to each specific format section for example files to use. Health GET /health This endpoint can be used to check the status of the application and its version . Example Request Response curl localhost:5000/health { \"status\" : \"OK\" , \"version\" : \"1.10.0\" , \"components\" : { \"StartLeft\" : \"OK\" } } IaC POST /api/v1/startleft/iac Request Body: iac_file: Required. File that contains the IaC definition. If you want to add more than one IaC file, you need to duplicate this tag as many times as files you want to upload. iac_type: Required. Type of the IaC file: [CLOUDFORMATION, TERRAFORM] id Required. ID of the new project name Required. Name of the new project mapping_file Required. File that contains the mapping between IaC resources and threat model resources. This endpoint accepts one or more IaC source files (currently Cloudformation or Terraform ) and a mapping file, and generates an OTM with the resulting threat modeling content. Example Request Response (reduced for simplicity) Files curl --location \\ --request POST localhost:5000/api/v1/startleft/iac \\ --header \"Content-Type: multipart/form-data\" \\ --header \"Accept: application/json\" \\ --form iac_type = \"CLOUDFORMATION\" \\ --form iac_file = @ \"./resources_cft_file.json\" \\ --form iac_file = @ \"./networks_cft_file.json\" \\ --form mapping_file = @ \"./iriusrisk-cft-mapping.yaml\" \\ --form id = \"cft-to-otm-example\" \\ --form name = \"CFT to OTM example\" { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"CFT to OTM example\" , \"id\" : \"cft-to-otm-example\" }, \"representations\" : [ { \"name\" : \"CloudFormation\" , \"id\" : \"CloudFormation\" , \"type\" : \"code\" } ], \"trustZones\" : [ ... ], \"components\" : [ ... ], \"dataflows\" : [ ... ] } You can download the example files from the examples directory. Diagram POST /api/v1/startleft/diagram Request Body: diag_file: Required. File that contains the diagram diag_type: Required. Type of the diagram file: [VISIO, LUCID] id Required. ID of the new project name Required. Name of the new project default_mapping_file Required. File that contains the default mapping file between the diagram resources and threat model resources custom_mapping_file Optional. File that contains the custom user mapping file between the diagram resources and threat model resources This endpoint accepts one diagram source file (currently only in Visio format, including diagrams exported from Lucidchart ), a mapping file, and an optional custom mapping file, and generates an OTM with the resulting threat modeling content. Example Request Response (reduced for simplicity) visio-basic-example.vsdx default-mapping.yaml custom-mapping.yaml curl --location \\ --request POST localhost:5000/api/v1/startleft/diagram \\ --header \"Content-Type: multipart/form-data\" \\ --header \"Accept: application/json\" \\ --form diag_type = \"VISIO\" \\ --form diag_file = @ \"./visio-basic-example.vsdx\" \\ --form default_mapping_file = @ \"./default-mapping.yaml\" \\ --form custom_mapping_file = @ \"./custom-mapping.yaml\" \\ --form id = \"vsdx-to-otm-example\" \\ --form name = \"VSDX to OTM example\" { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"VSDX to OTM example\" , \"id\" : \"vsdx-to-otm-example\" }, \"representations\" : [ { \"name\" : \"Visio\" , \"id\" : \"Visio\" , \"type\" : \"diagram\" , \"size\" : { \"width\" : 1000 , \"height\" : 1000 } } ], \"trustZones\" : [ ... ], \"components\" : [ ... ], \"dataflows\" : [ ... ] } You can download the visio-basic-example.vsdx from here . trustzones : - label : Public Cloud type : Public Cloud id : b61d6911-338d-46a8-9f39-8dcd24abfe91 components : - label : Amazon EC2 type : ec2 - label : Database type : rds dataflows : [] trustzones : - label : Private Secured Cloud type : Private Secured id : 2ab4effa-40b7-4cd2-ba81-8247d29a6f2d components : - label : My Custom Machine type : empty-component - label : My Custom VPC type : empty-component dataflows : [] External threat model POST /api/v1/startleft/external-threat-model Request Body: source_file: Required. File that contains the threat model source_type: Required. Type of the threat model file: MTMT id Required. ID of the new project name Required. Name of the new project default_mapping_file Required. File that contains the default mapping file between the source threat model resources and the resulting threat model resources This endpoint accepts one threat modeling source file (currently only Microsoft Threat Modeling Tool ) and a mapping file, and generates an OTM with the resulting threat modeling content. Example Request Response (reduced for simplicity) Files curl --location \\ --request POST localhost:5000/api/v1/startleft/external-threat-model \\ --header \"Content-Type: multipart/form-data\" \\ --header \"Accept: application/json\" \\ --form source_type = \"MTMT\" \\ --form source_file = @ \"./MTMT_example.tm7\" \\ --form default_mapping_file = @ \"./mtmt_default_mapping_example.yaml\" \\ --form id = \"tm7-to-otm-example\" \\ --form name = \"TM7 to OTM example\" { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"TM7 to OTM example\" , \"id\" : \"tm7-to-otm-example\" }, \"representations\" : [ { \"name\" : \"Microsoft Threat Modeling Tool\" , \"id\" : \"Microsoft Threat Modeling Tool\" , \"type\" : \"threat-model\" }, { \"name\" : \"tm7-to-otm-example Diagram Representation\" , \"id\" : \"tm7-to-otm-example-diagram\" , \"type\" : \"diagram\" , \"size\" : { \"width\" : 2000 , \"height\" : 2000 } } ], \"trustZones\" : [ ... ], \"components\" : [ ... ], \"dataflows\" : [ ... ], \"threats\" : [ ... ], \"mitigations\" : [ ... ] } You can download the example files from the examples directory. Error management Refer to the Errors Management page to learn about the different error responses when StartLeft is operating in API mode. Uvicorn It is also possible to launch StartLeft's server directly through Uvicorn . This could be useful, for example, to deploy it in a container. Example command: uvicorn startleft.startleft.api.fastapi_server:webapp --host 0 .0.0.0 --port 5000 --log-level critical","title":"REST API"},{"location":"usage/REST-API/#rest-api","text":"","title":"REST API"},{"location":"usage/REST-API/#usage","text":"StartLeft can also be deployed as a standalone REST server if you prefer to communicate via API. In this operation mode, StartLeft returns the OTM file in the HTTP response. You can launch the application as a server with the following command: startleft server The --help option provides more details about the usage: startleft server --help Usage: startleft server [ OPTIONS ] ... Launches the REST server to generate OTMs from requests Options: -p, --port INTEGER StartLeft deployment port. --help Show this message and exit. If not specified, port 5000 will be used by default. You can see and try the endpoints provided by opening the following URL in a web browser: http://localhost:5000/docs Note When executing startleft server the following command-line message indicates that StartLeft's REST API is ready: Uvicorn running on http://127.0.0.1:5000 (Press CTRL+C to quit)","title":"Usage"},{"location":"usage/REST-API/#additional-options","text":"You can also set general StartLeft options when using the API mode. More information on the Command Line Interface page or with the command startleft --help server . For example, to launch the server with a log level of DEBUG for testing purposes you can use the following command: startleft --log-level DEBUG server","title":"Additional options"},{"location":"usage/REST-API/#endpoints","text":"This section describes all the available endpoints, their parameters, and example requests and responses. Example files Refer to each specific format section for example files to use.","title":"Endpoints"},{"location":"usage/REST-API/#health","text":"GET /health This endpoint can be used to check the status of the application and its version . Example Request Response curl localhost:5000/health { \"status\" : \"OK\" , \"version\" : \"1.10.0\" , \"components\" : { \"StartLeft\" : \"OK\" } }","title":"Health"},{"location":"usage/REST-API/#iac","text":"POST /api/v1/startleft/iac Request Body: iac_file: Required. File that contains the IaC definition. If you want to add more than one IaC file, you need to duplicate this tag as many times as files you want to upload. iac_type: Required. Type of the IaC file: [CLOUDFORMATION, TERRAFORM] id Required. ID of the new project name Required. Name of the new project mapping_file Required. File that contains the mapping between IaC resources and threat model resources. This endpoint accepts one or more IaC source files (currently Cloudformation or Terraform ) and a mapping file, and generates an OTM with the resulting threat modeling content. Example Request Response (reduced for simplicity) Files curl --location \\ --request POST localhost:5000/api/v1/startleft/iac \\ --header \"Content-Type: multipart/form-data\" \\ --header \"Accept: application/json\" \\ --form iac_type = \"CLOUDFORMATION\" \\ --form iac_file = @ \"./resources_cft_file.json\" \\ --form iac_file = @ \"./networks_cft_file.json\" \\ --form mapping_file = @ \"./iriusrisk-cft-mapping.yaml\" \\ --form id = \"cft-to-otm-example\" \\ --form name = \"CFT to OTM example\" { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"CFT to OTM example\" , \"id\" : \"cft-to-otm-example\" }, \"representations\" : [ { \"name\" : \"CloudFormation\" , \"id\" : \"CloudFormation\" , \"type\" : \"code\" } ], \"trustZones\" : [ ... ], \"components\" : [ ... ], \"dataflows\" : [ ... ] } You can download the example files from the examples directory.","title":"IaC"},{"location":"usage/REST-API/#diagram","text":"POST /api/v1/startleft/diagram Request Body: diag_file: Required. File that contains the diagram diag_type: Required. Type of the diagram file: [VISIO, LUCID] id Required. ID of the new project name Required. Name of the new project default_mapping_file Required. File that contains the default mapping file between the diagram resources and threat model resources custom_mapping_file Optional. File that contains the custom user mapping file between the diagram resources and threat model resources This endpoint accepts one diagram source file (currently only in Visio format, including diagrams exported from Lucidchart ), a mapping file, and an optional custom mapping file, and generates an OTM with the resulting threat modeling content. Example Request Response (reduced for simplicity) visio-basic-example.vsdx default-mapping.yaml custom-mapping.yaml curl --location \\ --request POST localhost:5000/api/v1/startleft/diagram \\ --header \"Content-Type: multipart/form-data\" \\ --header \"Accept: application/json\" \\ --form diag_type = \"VISIO\" \\ --form diag_file = @ \"./visio-basic-example.vsdx\" \\ --form default_mapping_file = @ \"./default-mapping.yaml\" \\ --form custom_mapping_file = @ \"./custom-mapping.yaml\" \\ --form id = \"vsdx-to-otm-example\" \\ --form name = \"VSDX to OTM example\" { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"VSDX to OTM example\" , \"id\" : \"vsdx-to-otm-example\" }, \"representations\" : [ { \"name\" : \"Visio\" , \"id\" : \"Visio\" , \"type\" : \"diagram\" , \"size\" : { \"width\" : 1000 , \"height\" : 1000 } } ], \"trustZones\" : [ ... ], \"components\" : [ ... ], \"dataflows\" : [ ... ] } You can download the visio-basic-example.vsdx from here . trustzones : - label : Public Cloud type : Public Cloud id : b61d6911-338d-46a8-9f39-8dcd24abfe91 components : - label : Amazon EC2 type : ec2 - label : Database type : rds dataflows : [] trustzones : - label : Private Secured Cloud type : Private Secured id : 2ab4effa-40b7-4cd2-ba81-8247d29a6f2d components : - label : My Custom Machine type : empty-component - label : My Custom VPC type : empty-component dataflows : []","title":"Diagram"},{"location":"usage/REST-API/#external-threat-model","text":"POST /api/v1/startleft/external-threat-model Request Body: source_file: Required. File that contains the threat model source_type: Required. Type of the threat model file: MTMT id Required. ID of the new project name Required. Name of the new project default_mapping_file Required. File that contains the default mapping file between the source threat model resources and the resulting threat model resources This endpoint accepts one threat modeling source file (currently only Microsoft Threat Modeling Tool ) and a mapping file, and generates an OTM with the resulting threat modeling content. Example Request Response (reduced for simplicity) Files curl --location \\ --request POST localhost:5000/api/v1/startleft/external-threat-model \\ --header \"Content-Type: multipart/form-data\" \\ --header \"Accept: application/json\" \\ --form source_type = \"MTMT\" \\ --form source_file = @ \"./MTMT_example.tm7\" \\ --form default_mapping_file = @ \"./mtmt_default_mapping_example.yaml\" \\ --form id = \"tm7-to-otm-example\" \\ --form name = \"TM7 to OTM example\" { \"otmVersion\" : \"0.1.0\" , \"project\" : { \"name\" : \"TM7 to OTM example\" , \"id\" : \"tm7-to-otm-example\" }, \"representations\" : [ { \"name\" : \"Microsoft Threat Modeling Tool\" , \"id\" : \"Microsoft Threat Modeling Tool\" , \"type\" : \"threat-model\" }, { \"name\" : \"tm7-to-otm-example Diagram Representation\" , \"id\" : \"tm7-to-otm-example-diagram\" , \"type\" : \"diagram\" , \"size\" : { \"width\" : 2000 , \"height\" : 2000 } } ], \"trustZones\" : [ ... ], \"components\" : [ ... ], \"dataflows\" : [ ... ], \"threats\" : [ ... ], \"mitigations\" : [ ... ] } You can download the example files from the examples directory.","title":"External threat model"},{"location":"usage/REST-API/#error-management","text":"Refer to the Errors Management page to learn about the different error responses when StartLeft is operating in API mode.","title":"Error management"},{"location":"usage/REST-API/#uvicorn","text":"It is also possible to launch StartLeft's server directly through Uvicorn . This could be useful, for example, to deploy it in a container. Example command: uvicorn startleft.startleft.api.fastapi_server:webapp --host 0 .0.0.0 --port 5000 --log-level critical","title":"Uvicorn"}]}